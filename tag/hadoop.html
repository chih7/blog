
<!DOCTYPE html>
<html lang="zh">
<head>
  <link href='//fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700,400italic' rel='stylesheet' type='text/css'>

    <link rel="stylesheet" type="text/css" href="https://blog.chih.me/theme/stylesheet/style.min.css">

  <link rel="stylesheet" type="text/css" href="https://blog.chih.me/theme/pygments/github.min.css">
  <link rel="stylesheet" type="text/css" href="https://blog.chih.me/theme/font-awesome/css/font-awesome.min.css">


    <link href="https://blog.chih.me/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="chih's blog Atom">


    <link rel="shortcut icon" href="favicon.ico" type="image/x-icon">
    <link rel="icon" href="favicon.ico" type="image/x-icon">

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="robots" content="" />


    <meta name="author" content="chih" />
    <meta name="description" content="" />
<meta property="og:site_name" content="chih's blog"/>
<meta property="og:type" content="blog"/>
<meta property="og:title" content="chih's blog"/>
<meta property="og:description" content=""/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="https://blog.chih.me"/>

  <title>chih's blog &ndash;     Tag hadoop
</title>

</head>
<body>
  <aside>
    <div>
      <a href="https://blog.chih.me">
        <img src="https://blog.chih.me/theme/img/profile.png" alt="" title="">
      </a>
      <h1><a href="https://blog.chih.me"></a></h1>


      <nav>
        <ul class="list">
          <li><a href="https://blog.chih.me/pages/about-me.html#about-me">About Me</a></li>

          <li><a href="http://www.hjk.im/" target="_blank">HJK</a></li>
          <li><a href="http://imis.me/" target="_blank">记忆反射弧</a></li>
          <li><a href="http://mijack.github.io/" target="_blank">mijack</a></li>
          <li><a href="http://datahcong.cn/" target="_blank">whl的博客园</a></li>
        </ul>
      </nav>

      <ul class="social">
      </ul>
    </div>


  </aside>
  <main>




<article>
  <header>
    <h2><a href="https://blog.chih.me/spark-sql.html#spark-sql">Spark SQL</a></h2>
    <p>
          Posted on Sat 24 June 2017 in <a href="https://blog.chih.me/category/tech.html">Tech</a>


          &#8226;     Tagged with

              <a href="https://blog.chih.me/tag/spark.html">spark</a>,              <a href="https://blog.chih.me/tag/big-data.html">big data</a>,              <a href="https://blog.chih.me/tag/sql.html">SQL</a>,              <a href="https://blog.chih.me/tag/sql-on-hadoop.html">SQL on Hadoop</a>,              <a href="https://blog.chih.me/tag/spark-sql.html">Spark SQL</a>,              <a href="https://blog.chih.me/tag/hadoop.html">hadoop</a>
    </p>
  </header>
  <div>
      <h1>Spark 简介</h1>
<p>Hadoop 伴随着大数据的兴起已有十年时间，被认为是大数据处理的首选解决方案， 它分别提供HDFS和MapReduce解决了大数据（无法在单台机器上存储与处理的数据）的可靠存储和处理，但对于一些场景， MapReduce并不是十分高效，其一，MapReduce的抽象层次低，仅提供了map和reduce两个操作，对于应用需要编写大量代码；其二，一个job只包括了map和reduce两个阶段，想要完成复杂的工作，就必须串联一系列MapReduce作业，但每一步的输出数据必须存储到HDFS，导致io操作繁重，时延较高，只适合批处理，不适合实时处理和迭代计算。</p>
<p>Apache Spark是一个新兴的大数据处理引擎，它允许开发者使用有向无环图 (DAG) 开发复杂的数据操作，内部使用一个集群上的分布式内存抽象 (RDD) ，简化了对分布式数据的编程复杂性。RDD 提供了两类操作，转换和动作，转换在原有 RDD 上通过一些操作定义了一个新的 RDD ，包括map, flatMap, filter, union, sample, join, groupByKey, cogroup, ReduceByKey, cros, sortByKey, mapValues等 …</p>
      <br>
      <a class="btn" href="https://blog.chih.me/spark-sql.html#spark-sql">    Continue reading
</a>
  </div>
  <hr />
</article>
<article>
  <header>
    <h2><a href="https://blog.chih.me/shark-ppt.html#shark-ppt">Shark</a></h2>
    <p>
          Posted on Fri 23 June 2017 in <a href="https://blog.chih.me/category/tech.html">Tech</a>


          &#8226;     Tagged with

              <a href="https://blog.chih.me/tag/spark.html">spark</a>,              <a href="https://blog.chih.me/tag/big-data.html">big data</a>,              <a href="https://blog.chih.me/tag/sql.html">SQL</a>,              <a href="https://blog.chih.me/tag/sql-on-hadoop.html">SQL on Hadoop</a>,              <a href="https://blog.chih.me/tag/shark.html">shark</a>,              <a href="https://blog.chih.me/tag/hadoop.html">hadoop</a>
    </p>
  </header>
  <div>
      <h1>Shark Overview</h1>
<p>一个独立，快速，类MapReduce的SQL引擎</p>
<ul>
<li>基于内存存储数据，适合交互式查询</li>
<li>优秀的查询优化</li>
<li>比Hadoop快40倍以上</li>
</ul>
<p>完全兼容Hadoop存储接口</p>
<ul>
<li>可以读取或写入任何支持Hadoop的系统</li>
<li>包括HDFS，Hbase，SequenceFiles</li>
</ul>
<hr>
<h1>Shark Overview</h1>
<ul>
<li>
<p>Shark即Hive on Spark，本质上是通过Hive的HQL解析，把HQL翻译成Spark上的RDD操作，然后通过Hive的metadata获取数据库里的表信息，实际HDFS上的数据和文件，会由Shark获取并放到Spark上运算。</p>
</li>
<li>
<p>Shark建立在Hive的代码基础上，并通过将Hive的部分物理执行计划交换出来（by swapping out the physical execution engine part of Hive）。这个方法使得Shark的用户可以加速Hive的查询</p>
</li>
<li>
<p>Shark在HQL方面重用了Hive中HQL的解析、逻辑执行计划翻译、执行计划优化等逻辑，完全兼容已有的Hive数据，metastores 和 查询( HiveQL，UDFs )</p>
</li>
</ul>
<hr>
<h1>Project History</h1>
<ul>
<li>
<p>Spark project …</p></li></ul>
      <br>
      <a class="btn" href="https://blog.chih.me/shark-ppt.html#shark-ppt">    Continue reading
</a>
  </div>
  <hr />
</article>
<article>
  <header>
    <h2><a href="https://blog.chih.me/hadoop-install.html#hadoop-install">Hadoop 安装笔记</a></h2>
    <p>
          Posted on Thu 17 November 2016 in <a href="https://blog.chih.me/category/tech.html">Tech</a>


          &#8226;     Tagged with

              <a href="https://blog.chih.me/tag/linux.html">linux</a>,              <a href="https://blog.chih.me/tag/hadoop.html">Hadoop</a>,              <a href="https://blog.chih.me/tag/java-big-data.html">Java， Big Data</a>
    </p>
  </header>
  <div>
      <h2>The building blocks of Hadoop</h2>
<ul>
<li>NameNode</li>
<li>DataNode</li>
<li>Secondary NameNode</li>
<li>~~JobTracker~~</li>
<li>~~TaskTracker~~</li>
<li>ResourceManager</li>
<li>NodeManager</li>
</ul>
<p><img alt="Screenshot_20161117_185744" src="images/Screenshot_20161117_185744.png"></p>
<p><img alt="Screenshot_20161117_190357" src="images/Screenshot_20161117_190357.png"></p>
<h3>NameNode</h3>
<p>NameNode主要是用来保存HDFS的<strong>元数据</strong>信息，比如命名空间信息，块信息等。当它运行的时候，这些信息是存在内存中的。但是这些信息也可以持久化到磁盘上。没有Namenode，HDFS就不能工作。事实上，如果运行namenode的机器坏掉的话，系统中的文件将会完全丢失，因为没有其他方法能够将位于不同datanode上的文件块(blocks)重建文件。因此，Hadoop存在单点故障。为了解决单点故障，Hadoop提供了两套机制：</p>
<ol>
<li>第一种方式是将持久化存 储在本地硬盘的文件系统元数据备份。Hadoop可以通过配置来让Namenode将他的持久化状态文件写到不同的文件系统中。一般是镜像到网络文件系统或单独的磁盘中。</li>
<li>第二种方式是运行一个辅助的Namenode(Secondary Namenode)。下面会具体说明。</li>
</ol>
<h3>DataNode</h3>
<p>Datanode是文件系统的工作节点，他们根据客户端或者是namenode的调度存储和检索数据，并且定期向namenode发送他们所存储的块(block)的<strong>列表</strong>。</p>
<p>集群中的每个服务器都运 …</p>
      <br>
      <a class="btn" href="https://blog.chih.me/hadoop-install.html#hadoop-install">    Continue reading
</a>
  </div>
</article>

  <div class="pagination">
  </div>




    <footer>
<p>&copy; chih </p>
<p>    Powered by <a href="http://getpelican.com" target="_blank">Pelican</a> - <a href="https://github.com/alexandrevicenzi/flex" target="_blank">Flex</a> theme by <a href="http://alexandrevicenzi.com" target="_blank">Alexandre Vicenzi</a>
</p>    </footer>
  </main>

<!-- Google Analytics -->
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-61054351-1', 'auto');
  ga('send', 'pageview');
</script>
<!-- End Google Analytics -->



<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " chih's blog ",
  "url" : "https://blog.chih.me",
  "image": "",
  "description": ""
}
</script>
  
</body>
</html>