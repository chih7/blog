<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>chih's blog</title><link href="https://blog.chih.me/" rel="alternate"></link><link href="https://blog.chih.me/feeds/all.atom.xml" rel="self"></link><id>https://blog.chih.me/</id><updated>2018-01-14T00:00:00+08:00</updated><entry><title>离群点挖掘简述</title><link href="https://blog.chih.me/Outlier-mining-review.html" rel="alternate"></link><published>2018-01-14T00:00:00+08:00</published><updated>2018-01-14T00:00:00+08:00</updated><author><name>chih</name></author><id>tag:blog.chih.me,2018-01-14:/Outlier-mining-review.html</id><summary type="html">&lt;h2&gt;引言&lt;/h2&gt;
&lt;p&gt;离群点是一个或一组明显不同于其他数据的数据点。Hawkins把离群点定义为“离群点是在数据集中偏离大部分数据的数据，使人怀疑这些数据的偏离并非由随机因素产生，而是产生于完全不同的机制。”&lt;/p&gt;
&lt;p&gt;在大多数应用中，数据由一到多个程序产生，这些数据可以反映出系统的运行状态和被监测客体的相关数值。当测量、输入错误或系统运行错误时，或者客体出现异常行为，离群点就会产生。因此，离群点经常包含关于系统与实体异常特征的有效信息。现有数据挖掘研究大多集中于发现适用于大部分数据的常规模式,在许多应用领域中，离群点通常作为噪音而忽略，许多数据挖掘算法试图降低或消除离群点的影响。而在有些应用领域识别离群点是许多工作的基础和前提，离群点会带给我们新的视角。如在欺诈检测中，离群点可能意味欺诈行为的发生，在入侵检测中离群点可能意味入侵行为的发生。其他的一些应用场景包括信用卡诈骗、医疗诊断、执法、地球科学……&lt;/p&gt;
&lt;p&gt;离群点的检测算法输出可以是两种类型之一：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;大多数离群点检测算法，输出一个关于数据点的“离群性”得分。这个得分可以用于分析数据点的离群趋势。&lt;/li&gt;
&lt;li&gt;第二种类型的输出是表示一个数据点是否离群的二进制标签。一些算法可能直接返回二进制标签，但离群得分也可转换成二进制标签。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;早期对离群点研究的主要目的是消除离群点，那时离群点一般被视为“噪音”，但随着离群点分析的流行，发现“噪声”中存在有趣的数据。在真实的应用中，数据可能嵌入了大量的噪音，但大部分噪音对于分析是无趣的。&lt;/p&gt;
&lt;p&gt;如下图所示，在(a …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;引言&lt;/h2&gt;
&lt;p&gt;离群点是一个或一组明显不同于其他数据的数据点。Hawkins把离群点定义为“离群点是在数据集中偏离大部分数据的数据，使人怀疑这些数据的偏离并非由随机因素产生，而是产生于完全不同的机制。”&lt;/p&gt;
&lt;p&gt;在大多数应用中，数据由一到多个程序产生，这些数据可以反映出系统的运行状态和被监测客体的相关数值。当测量、输入错误或系统运行错误时，或者客体出现异常行为，离群点就会产生。因此，离群点经常包含关于系统与实体异常特征的有效信息。现有数据挖掘研究大多集中于发现适用于大部分数据的常规模式,在许多应用领域中，离群点通常作为噪音而忽略，许多数据挖掘算法试图降低或消除离群点的影响。而在有些应用领域识别离群点是许多工作的基础和前提，离群点会带给我们新的视角。如在欺诈检测中，离群点可能意味欺诈行为的发生，在入侵检测中离群点可能意味入侵行为的发生。其他的一些应用场景包括信用卡诈骗、医疗诊断、执法、地球科学……&lt;/p&gt;
&lt;p&gt;离群点的检测算法输出可以是两种类型之一：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;大多数离群点检测算法，输出一个关于数据点的“离群性”得分。这个得分可以用于分析数据点的离群趋势。&lt;/li&gt;
&lt;li&gt;第二种类型的输出是表示一个数据点是否离群的二进制标签。一些算法可能直接返回二进制标签，但离群得分也可转换成二进制标签。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;早期对离群点研究的主要目的是消除离群点，那时离群点一般被视为“噪音”，但随着离群点分析的流行，发现“噪声”中存在有趣的数据。在真实的应用中，数据可能嵌入了大量的噪音，但大部分噪音对于分析是无趣的。&lt;/p&gt;
&lt;p&gt;如下图所示，在(a)中，A点明显不同于其余聚集的点，显然可以把A视为离群点，(b)中的A点也是数据中的稀疏点，但并不孤立。因此，术语“离群点”指的是一个数据点，这可以被认为是一个异常或是噪音，而一个“异常”指的是一种特殊的感兴趣的离群点。通常噪声和异常之间并不存在一个明显的界限。&lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170102_141443" src="images/Screenshot_20170102_141443.png"&gt;&lt;/p&gt;
&lt;p&gt;本文在充分调研国内外离群点挖掘研究成果的基础上，介绍了离群点挖掘的研究进展，并概要地总结和比较了已有的各种离群点挖掘方法，展望了离群点挖掘研究的未来发展方向和面临的挑战。余下内容组织如下：第2节讨论典型的离群点分类；第3节；第4节；最后给出结论。&lt;/p&gt;
&lt;h2&gt;离群点的表示&lt;/h2&gt;
&lt;p&gt;由于应用的不同，数据表示也各不相同，可以是互不相关的高维数据，也可以是时间序列数据，或者是以图或网络形式存在的数据，数据本身也可以是数值形式、离散形式。几乎所有的离群点检测算法都是基于已有数据建立一个代表一般模式的模型，然后计算给定的数据点和一般模式的偏差，得出这个数据点的离群情况。而偏差的计算，与数据本身的数据表示密切相关。在一些情况下，离群点就是和大多数点距离比较大的点。&lt;/p&gt;
&lt;p&gt;模型的选择至关重要，一旦模型选择有误，就可能导致对数据的理解出现误解。以Z值测试为例，给出一系列一维数值 &lt;span class="math"&gt;\(X_{1}, X_{2},...,X_{n}\)&lt;/span&gt; ，它们的平均值 &lt;span class="math"&gt;\(\mu\)&lt;/span&gt; 它们的标准差 &lt;span class="math"&gt;\(\sigma\)&lt;/span&gt; 。与 &lt;span class="math"&gt;\(X_{i}\)&lt;/span&gt; 相关的 Z 值的定义如下所示&lt;/p&gt;
&lt;div class="math"&gt;$$
Z_{i} = \frac{X_{i}-\mu}{\sigma}
$$&lt;/div&gt;
&lt;p&gt;Z 值测试计算了一个数和平均的偏离情况。当我们把 Z 值测试应用在图 (a)的一个维度上，我们发现Z值测试的结果是离群点A的偏差最小，这显然有问题，错误的模型选择将得到无效或错误的结果。在实践中，模型的选择通常是由对特定应用程序的理解所决定的。在选择模型之前，需要对数据有足够的了解。&lt;/p&gt;
&lt;p&gt;下面将列举一些基本的模型，分别为极值分析、统计概率分析、线性模型、基于邻近的模型、信息论模型与高维离群点挖掘。&lt;/p&gt;
&lt;h3&gt;极值分析&lt;/h3&gt;
&lt;p&gt;极值分析是一维数据分析中最基本的离群点检测形式。规定值过大或过小的点为离群点。极值分析符合人们对离群点的传统认知，在一个一维数据集{1, 2, 2,  50, 98, 98, 99}中，1和99会被认为是离群点。为了解决冲突，极限值模型同时也使用概率模型量化生成概率为极限值。虽然极限分析是基于一维数据提出的，但也可以在多维数据上使用。在图 (b)中，B点可以被认为是极限值，因为它在多维数据集的外围区域，但a与b中的A点就不能认为是极限值，虽然它是离群点。&lt;/p&gt;
&lt;p&gt;极值分析在离群点分析中扮演这重要的角色，在大多数离群点检测算法的最后一步得到广泛使用。大多数离群点检测算法用数值衡量离群程度，一些离群点检测算法会产出一系列离群得分，使用极限分析方法就可以统一成一个单一的值，或者产生一个二进制标签。&lt;/p&gt;
&lt;h3&gt;统计概率分析&lt;/h3&gt;
&lt;p&gt;这类方法大部分是从针对不同分布的离群点检验方法发展起来的，通常用户使用概率分布来拟合数据集，或者通过学习来获得模型的参数，比如可以使用Expectation-Maximization (EM)算法计算出分布的参数，关键在于选择出一个最贴近数据的分布。假定所给定的数据集存在一个分布或概率模型(例如，正态分布或泊松分布)，然后将与模型不一致(即分布不符合)的数据标识为离群数据，在早期也可以使用极限值分析选出概率模型中的离群点。&lt;/p&gt;
&lt;p&gt;离群点检测的统计学方法具有坚实的基础，建立在标准的统计学技术(如分布参数的估计)之上，当存在充分的数据和所用的检验类型的知识时，这些检验可能非常有效。同时，各种不同的数据类型均可以统计概率进行建模。而统计概率分析的缺点就在于它试图把所有数据拟合到一个特定的分布，随着模型参数的增加，容易产生过拟合现象。基于分布的方法是假设数据符合某种分布规律，因而不适合分布未知的情形。同时，对于高维数据，很难估计真实的分布。&lt;/p&gt;
&lt;h3&gt;线性模型&lt;/h3&gt;
&lt;p&gt;线性模型使用线性关系将数据建模到低维嵌入子空间，在图(a)中，二维空间上的点可以看作沿一条斜线分布。&lt;img alt="Screenshot_20170102_184751" src="images/Screenshot_20170102_184751.png"&gt;&lt;/p&gt;
&lt;p&gt;在图中，使用回归分析把二维空间对齐到一维的线上
&lt;/p&gt;
&lt;div class="math"&gt;$$
y_{i} = a \cdot x_{i} + b + \epsilon_{i}     \   \   \     \    \forall_{i} \in  \{1...N\}
$$&lt;/div&gt;
&lt;p&gt;
公式中 &lt;span class="math"&gt;\(\epsilon_{i}\)&lt;/span&gt; 代表余数，系数 a, b 需要从数据中学习得到，可以使用最小二乘法找出。获得的余数可以结合极值分析计算出离群点。线性模型处理的过程与 Principal component analysis (PCA) 相似，PCA 提供了一种降低数据维度的有效办法，如果分析者在原数据中除掉最小的特征值所对应的成分，那么所得的低维度数据必定是最优化的（也即，这样降低维度必定是失去讯息最少的方法）。因此，PCA可以用于噪声移除。&lt;/p&gt;
&lt;p&gt;线性模型的缺点在于当数据维度很高时， 使用降维或回归模型会增加对数据原有属性的理解难度。&lt;/p&gt;
&lt;h3&gt;基于邻近的模型&lt;/h3&gt;
&lt;p&gt;基于邻近的模型就是评估点与其他点的孤立情况的模型，主要分为三类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;聚类分析&lt;/li&gt;
&lt;li&gt;基于密度的分析&lt;/li&gt;
&lt;li&gt;最近邻分析&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在聚类分析和基于密度的分析中，密度大的点聚合作为常规数据点，而其余的数据点成为离群点。但两者的不同在于聚类算法分割点，而基于密度的算法分割区域。聚类分析中簇的定义通常是离群点的补，因此可同时发现簇和离群点。基于密度的离群点检测给出了对象离群程度的定量度量，对不同密度区域中的数据也能够很好地处理，解决了局部离群点的离群程度的度量和挖掘问题。&lt;/p&gt;
&lt;p&gt;在最近邻算法中，有两种不同的策略：第一种策略是采用给定邻域半径，依据点的邻域中包含的对象多少来判定离群点如果一个点的邻域内包含的对象少于整个数据集的一定比例则标识它为离群点，也就是将没有足够邻居的对象看成是基于距离的离群点。第二种利用k最近邻距离的大小来判定离群使用k-最近邻的距离度量一个对象是否远离大部分点，一个对象的离群程度由到它的k-最近邻的距离给定 。这种方法对k的取值比较敏感。k太小(例如1)，则少量的邻近离群点可能导致较低的离群程度。k太大，则点数少于k的簇中所有的对象可能都成了离群点。&lt;/p&gt;
&lt;h3&gt;信息论模型&lt;/h3&gt;
&lt;p&gt;信息论模型提供了一种数据摘要的方法，在其中，离群点被定义为增加了描述数据的语言的最小长度，以下面的两个字符串为例&lt;/p&gt;
&lt;div class="math"&gt;$$
ABABABABABABABABABABABABABABABABABABABAB \\
ABABABCBABABABABABABABABABABABABABABABAB
$$&lt;/div&gt;
&lt;p&gt;第二个字符串和第一个字符串的长度相同，唯一的不同点在于出现了一个单独的字符C，第一个字符串可以被简单描述为“AB重复了20次”，但第二个字符串就不能被这么简明的描述了，因为它出现了其他的字符C。字符C增加了描述数据语言的最小长度，因此可以把C作为离群点。&lt;/p&gt;
&lt;p&gt;使用信息论方法挖掘离群点的基本方法为构造一本可以代表数据的字典，当一个数据点被移除后发现剩余数据的描述减少最多，那这个点可以被视为离群点。&lt;/p&gt;
&lt;h2&gt;典型的离群点分析方法&lt;/h2&gt;
&lt;p&gt;一般，无监督方法用于噪声移除或异常检测，有监督方法用于特定场景的异常检测&lt;/p&gt;
&lt;h2&gt;离群点分析现状&lt;/h2&gt;
&lt;p&gt;当前离群点研究的重点是高维大数据，时序数据……&lt;/p&gt;
&lt;h3&gt;高维数据中的离群点挖掘&lt;/h3&gt;
&lt;p&gt;高维空间中的离群点挖掘是离群点挖掘的一大挑战，从密度的角度考虑，在高维空间，数据变得稀疏，真正的离群点被淹没在大量的噪音之中。当数据维数增加时，常规的离群点检测算法的性能也会迅速下降。由于高维空间中数据的稀疏性，数据点之间几乎是等距离的，每个点在密度或距离的意义上都可以看作是一个离群点，对高维数据聚类几乎不可能，通常定义的离群点的概念也失去意义。&lt;/p&gt;
&lt;p&gt;为了解决高维数据离群点挖掘问题，一种重要的方法是降维到低维子空间进行离群点挖掘。离群点通常隐藏在低维子空间的异常局部行为中，因此，需要寻找合适的子空间。降低维度产生子空间的技术主要包括投影变换和属性提取等方法。投影变换是将数据集从原 &lt;span class="math"&gt;\(\delta\)&lt;/span&gt; 维投影到 &lt;span class="math"&gt;\(d\)&lt;/span&gt; 维空间,其中 &lt;span class="math"&gt;\(d\ll \delta\)&lt;/span&gt; ，并且每个新维是原始维的线性组合,然后在d维空间上利用传统的挖掘算法进行挖掘。如果高维数据向低维投影，离群点信息会丢失。在下图中，(a)(b)是高维空间的两个不同低维投影，可以看到，(a)中离群点A到(b)中就不再成为离群点。同时，高维向低维的投影数目和维数是指数相关的，计算复杂度非常高。所以说，无论是直接在高维进行离群点挖掘还是投影到低维进行离群点挖掘，都将变得十分困难。由于不同的子空间包含不同的离群点，因此可以使用一种集成的方法，同时进行数据特征选取和子空间探索，这将大大降低计算复杂度。&lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170102_214113" src="images/Screenshot_20170102_214113.png"&gt;&lt;/p&gt;
&lt;p&gt;另一种减少维度的方法是特征选取方法。这种方法不用变换,而是从维度中启发式地选取一部分维,删除不相关或冗余的属性(维),目标是找出最小属性集,使得数据类的概率分布尽可能接近使用所有属性得到的原分布。这种方法避免了挖掘结果难以解释问题,并且由于属性数目的减少,使得模式更易于理解。&lt;/p&gt;
&lt;h3&gt;时序数据中的离群点挖掘&lt;/h3&gt;
&lt;p&gt;时序数据包含一系列按时间连续生成的值。因此，时序数据在相邻的两个时间点上一般不会出现很大的差别，总体呈现出连续光滑趋势。时序数据中的离群点可能就是一些突然出现巨大改变的值。&lt;/p&gt;
&lt;p&gt;考虑以下如图的时序数据，明显有两个突然的跳变，一个是从3一下子变到87，另一个是86到3，然后又回到84，这两处即可视为离群点。&lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170102_221320" src="images/Screenshot_20170102_221320.png"&gt;&lt;/p&gt;
&lt;p&gt;传统的时间序列离群模式挖掘一般有两种方法：一种是将时间序列分成等长的子序列,并将子序列映射为d维空间中的点,然后采用基于距离的挖掘算法发现离群点。这种方法的一个缺点是序列中的点一般较多，距离的计算和检测的时间消耗是相当可观的。另一种方法是从时间序列中抽取特征,通过计算特征序列间的距离来发现异常。&lt;/p&gt;
&lt;h2&gt;结束语&lt;/h2&gt;
&lt;p&gt;离群点挖掘可以应用在许多领域，比如兴趣发现，异常检测。本文在充分调研国内外离群点挖掘研究成果的基础上，介绍了离群点挖掘的研究进展，并概要地总结和比较了已有的各种离群点挖掘方法，展望了离群点挖掘研究的未来发展方向和面临的挑战。&lt;/p&gt;
&lt;h2&gt;参考文献&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;薛安荣, 姚林, 鞠时光, 陈伟鹤, 马汉达. 离群点挖掘方法综述. 计算机科学. 2008;35(11):13-8.&lt;/li&gt;
&lt;li&gt;Aggarwal CC, Yu PS. Outlier detection for high dimensional data. InACM Sigmod Record 2001 May 1 (Vol. 30, No. 2, pp. 37-46). &lt;/li&gt;
&lt;li&gt;Han Jiawei。Micheline K.Data mining:concepts and techniques.3th edition.San Francisco..Morgan Kaufmann Publishers,2012&lt;/li&gt;
&lt;li&gt;魏藜, 宫学庆, 钱卫宁, 周傲英. 高维空间中的离群点发现. 软件学报. 2002;13(2):280-90.&lt;/li&gt;
&lt;li&gt;Aggarwal CC, Yu PS. Outlier detection for high dimensional data. InACM Sigmod Record 2001 May 1 (Vol. 30, No. 2, pp. 37-46). &lt;/li&gt;
&lt;li&gt;WU, Shu, WANG, Shengrui. Information-theoretic outlier detection for large-scale categorical data. &lt;em&gt;IEEE transactions on knowledge and data engineering&lt;/em&gt;, 2013, 25.3: 589-602.&lt;/li&gt;
&lt;li&gt;张净, 孙志挥, 宋余庆, 倪巍伟, &amp;amp; 晏燕华. (2011). 基于信息论的高维海量数据离群点挖掘. &lt;em&gt;计算机科学&lt;/em&gt;, &lt;em&gt;38&lt;/em&gt;(7), 148-151. &lt;/li&gt;
&lt;/ol&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="big data"></category><category term="data mining"></category><category term="Outlier"></category><category term="异常检测"></category><category term="时序数据"></category></entry><entry><title>基于SPARK的分布式网页近似度检测</title><link href="https://blog.chih.me/simjoin-on-spark.html" rel="alternate"></link><published>2017-07-09T00:00:00+08:00</published><updated>2017-07-09T00:00:00+08:00</updated><author><name>chih</name></author><id>tag:blog.chih.me,2017-07-09:/simjoin-on-spark.html</id><summary type="html">&lt;h1&gt;前言&lt;/h1&gt;
&lt;p&gt;随着Web上数量的急剧增长，近似镜像网页的数量也在不断增加。近似镜像网页的存在，严重影响了搜索引擎的检索结果。如果我们能将搜集到的网页中的近似镜像网页去掉，可以提高搜集系统和索引系统效率，用户查询时也不会出现大量内容重复的网页。去除镜像网页即需要网页近似度检测算法。实验基于相似性连接实现了基于SPARK的分布式网页近似度检测，对5000个网页进行了相似度检测，试图找出所有相似的网页。实验使用的网页来源与人才招聘网站的电子简历，共有5000份，由于我们只关心其中的简历内容，因此需要去除简历内容外的HTML标签，网页样式、代码。在去除了无关内容后，即可进行近似检测，大数据环境下，数据量巨大，运用传统的方式进行相似性连接效率极低，实验选择了相似性连接查询作为底层的算法实现，作为一种分布式算法，实验选择了Spark作为分布式计算框架。&lt;/p&gt;
&lt;p&gt;相似性连接查询，即查找相似的数据对象对，具有广泛的应用领域，例如相似网页检、实体解析、数据清洗和相似图像检索等。 在相似网页检测中，使用相似性连接等技术识别相似的网页，不但可以帮助网页搜索引擎执行聚焦爬行，提高搜索结果的质量和多样性，还可以识别垃圾邮件。在实体解析中，使用相似性连接技术，可以找到企业数据库里相似的顾客，匹配产品报价等。在数据清洗中，使用相似性连接技术，可以为不同数 据源集成提供一致、准确的数据。在相似图像检索 中，使用相似性连接技术检索出相似的图像，可以分析图像的来源 …&lt;/p&gt;</summary><content type="html">&lt;h1&gt;前言&lt;/h1&gt;
&lt;p&gt;随着Web上数量的急剧增长，近似镜像网页的数量也在不断增加。近似镜像网页的存在，严重影响了搜索引擎的检索结果。如果我们能将搜集到的网页中的近似镜像网页去掉，可以提高搜集系统和索引系统效率，用户查询时也不会出现大量内容重复的网页。去除镜像网页即需要网页近似度检测算法。实验基于相似性连接实现了基于SPARK的分布式网页近似度检测，对5000个网页进行了相似度检测，试图找出所有相似的网页。实验使用的网页来源与人才招聘网站的电子简历，共有5000份，由于我们只关心其中的简历内容，因此需要去除简历内容外的HTML标签，网页样式、代码。在去除了无关内容后，即可进行近似检测，大数据环境下，数据量巨大，运用传统的方式进行相似性连接效率极低，实验选择了相似性连接查询作为底层的算法实现，作为一种分布式算法，实验选择了Spark作为分布式计算框架。&lt;/p&gt;
&lt;p&gt;相似性连接查询，即查找相似的数据对象对，具有广泛的应用领域，例如相似网页检、实体解析、数据清洗和相似图像检索等。 在相似网页检测中，使用相似性连接等技术识别相似的网页，不但可以帮助网页搜索引擎执行聚焦爬行，提高搜索结果的质量和多样性，还可以识别垃圾邮件。在实体解析中，使用相似性连接技术，可以找到企业数据库里相似的顾客，匹配产品报价等。在数据清洗中，使用相似性连接技术，可以为不同数 据源集成提供一致、准确的数据。在相似图像检索 中，使用相似性连接技术检索出相似的图像，可以分析图像的来源，查找高清图像等，当前比较常用的有字符串、集合和向量的相似性连接算法。&lt;/p&gt;
&lt;h1&gt;选用平台描述&lt;/h1&gt;
&lt;p&gt;实验运用的是spark平台，选择的编程语言是scala中，操作系统是ubuntu。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;spark：2.1.0&lt;/li&gt;
&lt;li&gt;Scala：2.10.6&lt;/li&gt;
&lt;li&gt;Ubuntu 16.04.2 LTS&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;数据集描述&lt;/h1&gt;
&lt;p&gt;原始数据集为5000个左右的简历网页， 大致格式如下：&lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170611_195353" src="images/Screenshot_20170611_195353.png" width="70%"&gt;&lt;/p&gt;
&lt;p&gt;经过分词，去除重复词，HTML标签，停用词后，输出如下，作为Spark文档近似度检测的输入源。&lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170611_195748" src="images/Screenshot_20170611_195748.png" width="80%"&gt;&lt;/p&gt;
&lt;h1&gt;设计逻辑&lt;/h1&gt;
&lt;h2&gt;数据清洗与中文分词&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#! /bin/python&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pyquery&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;PyQuery&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;jieba&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;

&lt;span class="n"&gt;STOP_WORDS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;frozenset&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;a&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;an&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;and&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;are&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;as&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;at&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;be&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;by&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="s1"&gt;&amp;#39;for&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;from&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;have&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;if&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;in&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;is&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;it&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;may&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="s1"&gt;&amp;#39;not&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;of&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;on&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;or&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;tbd&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;that&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;the&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;this&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="s1"&gt;&amp;#39;to&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;us&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;we&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;when&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;will&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;with&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;yet&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="s1"&gt;&amp;#39;you&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;your&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;的&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;了&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;和&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;


&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dirs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;files&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;walk&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;webResume&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;files&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;web_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;root&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;doc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PyQuery&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;web_file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
        &lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;style&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;remove&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;script&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;remove&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;doc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;seg_list&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;jieba&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cut&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;seg_list&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;STOP_WORDS&lt;/span&gt;
        &lt;span class="n"&gt;write_file&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;./jiebafiles/&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;.txt&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;w&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;write_file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;遍历目录下的所有html文件，去除html文件中的所有标签、样式、代码。使用中文分词对过滤后的HTML文件进行分词，同时过滤掉重复的词、停用词，留下这份简历网页的关键词，写入另一份文件，作为近似度检测的输入。&lt;/p&gt;
&lt;h2&gt;近似度检测&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.spark.SparkContext&lt;/span&gt;
&lt;span class="k"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;org.apache.spark.SparkConf&lt;/span&gt;


&lt;span class="k"&gt;object&lt;/span&gt; &lt;span class="nc"&gt;SimJoin&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;

  &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="k"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;Array&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="kt"&gt;String&lt;/span&gt;&lt;span class="o"&gt;])&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;

    &lt;span class="k"&gt;val&lt;/span&gt; &lt;span class="n"&gt;conf&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nc"&gt;SparkConf&lt;/span&gt;&lt;span class="o"&gt;().&lt;/span&gt;&lt;span class="n"&gt;setAppName&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;SimJion&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;).&lt;/span&gt;&lt;span class="n"&gt;setMaster&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;master&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;var&lt;/span&gt; &lt;span class="n"&gt;sc&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="k"&gt;new&lt;/span&gt; &lt;span class="nc"&gt;SparkContext&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;var&lt;/span&gt; &lt;span class="n"&gt;files&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;wholeTextFiles&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;
      &lt;span class="s"&gt;&amp;quot;/home/chih/BD/spark-2.1.1-bin-hadoop2.7/jiebafiles/*.txt&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;var&lt;/span&gt; &lt;span class="n"&gt;pairs&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="n"&gt;files&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;flatMap&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt;
      &lt;span class="k"&gt;val&lt;/span&gt; &lt;span class="n"&gt;rid&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_1&lt;/span&gt; &lt;span class="c1"&gt;// 文件名&lt;/span&gt;
      &lt;span class="k"&gt;val&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_2&lt;/span&gt; &lt;span class="c1"&gt;// 文件内容&lt;/span&gt;
      &lt;span class="k"&gt;val&lt;/span&gt; &lt;span class="n"&gt;tokens&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;\t&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;// 分割&lt;/span&gt;
        &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;isEmpty&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;// 移除空token&lt;/span&gt;
      &lt;span class="k"&gt;var&lt;/span&gt; &lt;span class="n"&gt;map&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;groupBy&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;identity&lt;/span&gt;&lt;span class="o"&gt;).&lt;/span&gt;&lt;span class="n"&gt;mapValues&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="k"&gt;_&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
      &lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="o"&gt;({&lt;/span&gt; &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;rid&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;length&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;))&lt;/span&gt; &lt;span class="o"&gt;})&lt;/span&gt;
    &lt;span class="o"&gt;})&lt;/span&gt;
    &lt;span class="k"&gt;var&lt;/span&gt; &lt;span class="n"&gt;groups&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pairs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;groupByKey&lt;/span&gt;&lt;span class="o"&gt;().&lt;/span&gt;&lt;span class="n"&gt;flatMap&lt;/span&gt;&lt;span class="o"&gt;({&lt;/span&gt; &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;u&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="k"&gt;=&amp;gt;&lt;/span&gt;
      &lt;span class="n"&gt;u&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;toList&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;combinations&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
        &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;(((&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_2&lt;/span&gt;&lt;span class="o"&gt;),&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;).&lt;/span&gt;&lt;span class="n"&gt;_1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;).&lt;/span&gt;&lt;span class="n"&gt;_2&lt;/span&gt;&lt;span class="o"&gt;)),&lt;/span&gt; 
                   &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nc"&gt;Math&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;min&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_3&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;).&lt;/span&gt;&lt;span class="n"&gt;_3&lt;/span&gt;&lt;span class="o"&gt;))))&lt;/span&gt;
    &lt;span class="o"&gt;})&lt;/span&gt;
    &lt;span class="k"&gt;var&lt;/span&gt; &lt;span class="n"&gt;grouped&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="n"&gt;groups&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reduceByKey&lt;/span&gt;&lt;span class="o"&gt;((&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_2&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_2&lt;/span&gt;&lt;span class="o"&gt;))&lt;/span&gt;
    &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_2&lt;/span&gt;&lt;span class="o"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;val&lt;/span&gt; &lt;span class="n"&gt;min_t&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.4&lt;/span&gt;
    &lt;span class="k"&gt;val&lt;/span&gt; &lt;span class="n"&gt;max_t&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.99&lt;/span&gt;
    &lt;span class="k"&gt;var&lt;/span&gt; &lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="n"&gt;grouped&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_1&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;toDouble&lt;/span&gt; 
                                    &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_2&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_2&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_2&lt;/span&gt;&lt;span class="o"&gt;)))&lt;/span&gt;
      &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;filter&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_3&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;=&lt;/span&gt; &lt;span class="n"&gt;min_t&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_3&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;max_t&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;take&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="o"&gt;).&lt;/span&gt;&lt;span class="n"&gt;foreach&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;println&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;sc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;stop&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt;
  &lt;span class="o"&gt;}&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;从目录中读取所有已经经过分词的简介文档，生成文件名、文件内容的对，供后续处理。建立倒排索引，将记录的RID插入到其项目的倒排索引中的对应Item中。生成候选集，通过倒排索引的item两两配对生成候选对，并记录相同候选对的数量，从而最终生成最终的候选集。
从候选集中找出符合要求的结果，通过Jaccard 系数阈值计算出对应的相似度阈值，从而在候选集中找出相应的结果。&lt;/p&gt;
&lt;h1&gt;运行部署描述&lt;/h1&gt;
&lt;p&gt;Spark 官方提供了三种集群部署方案： Standalone, Mesos, YARN。在试验环境下，Standalone 模式就足够了，因此本实验选用Standalone 模式。如果如果已经有 Yarn 或者 Mesos 环境，也是很方便地迁移到新的资源调度框架上的。&lt;/p&gt;
&lt;h2&gt;注意&lt;/h2&gt;
&lt;p&gt;为了避免权限问题影响实验，本例中的演示均为 root 权限，当然在生产环境中，为了安全起见，需要使用单独的用户启动运行Spark。注意，除非特别说明，所有的操作需要在每台机器上都操作一遍，你可以使用Xshell，ansible简化操作。&lt;/p&gt;
&lt;h2&gt;环境准备&lt;/h2&gt;
&lt;h3&gt;安装系统&lt;/h3&gt;
&lt;p&gt;我使用VirtualBox虚拟机软件创建三台Ubuntu服务器，均使用纯净安装，集群准备为1个master，2个slave。每台的均配置两张网卡，其中一张nat网络，用于连接外网，更新安装软件包用，另一张使用host-only模式，用于宿主机和虚拟机、 虚拟机直接通讯使用。如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170611_190618" src="images/Screenshot_20170611_190618.png" width="80%"&gt;&lt;/p&gt;
&lt;h3&gt;配置hosts&lt;/h3&gt;
&lt;p&gt;Host-Only网卡的IP地址是顺序分配的，在这里，三台虚拟机Host-Only网卡的IP地址分别为 192.168.56.101、 192.168.56.102、 192.168.56.103 。&lt;/p&gt;
&lt;p&gt;在每台主机上修改host文件，在文件末尾添加以下三行。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;vim /etc/hosts

&lt;span class="m"&gt;192&lt;/span&gt;.168.56.101    master
&lt;span class="m"&gt;192&lt;/span&gt;.168.56.102    slave1
&lt;span class="m"&gt;192&lt;/span&gt;.168.56.103    slave2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;配置之后相互ping一下看是否生效。&lt;/p&gt;
&lt;h3&gt;配置SSH 免密码登录&lt;/h3&gt;
&lt;p&gt;安装Openssh server&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo apt install openssh-server
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;在所有机器上都生成私钥和公钥&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ssh-keygen -t rsa   &lt;span class="c1"&gt;#一路回车&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;需要让机器间都能相互访问，就把每个机子上的id_rsa.pub发给master节点，传输公钥可以用scp来传输。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;scp ~/.ssh/id_rsa.pub spark@master:~/.ssh/id_rsa.pub.slave1
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;在master上，将所有公钥加到用于认证的公钥文件authorized_keys中&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;cat ~/.ssh/id_rsa.pub* &amp;gt;&amp;gt; ~/.ssh/authorized_keys
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;将公钥文件authorized_keys分发给每台slave&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;scp ~/.ssh/authorized_keys spark@slave1:~/.ssh/
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;在每台机子上验证SSH无密码通信&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ssh master
ssh slave1
ssh slave2
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;安装JDK&lt;/h3&gt;
&lt;p&gt;直接通过包管理安装openJDK 8.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo apt install openjdk-8-jdk
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;使用以下命令配置环境变量并使之生效：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;
&lt;span class="s2"&gt;# set environment variable&lt;/span&gt;
&lt;span class="s2"&gt;export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64&lt;/span&gt;
&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;   &amp;gt;&amp;gt; /etc/profile.d/spark.sh

    &lt;span class="nb"&gt;source&lt;/span&gt; /etc/profile.d/spark.sh &lt;span class="c1"&gt;#使之生效&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;验证 Java 是否安装成功&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;java -version         &lt;span class="c1"&gt;#如果打印出版本信息，则说明安装成功&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;安装Spark&lt;/h2&gt;
&lt;p&gt;使用以下命令下载并安装Spark：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;wget &lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;mirror&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;/apache/spark/spark-2.1.0/ &lt;span class="se"&gt;\&lt;/span&gt;
    spark-&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;spark_pkgver&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;-bin-hadoop&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;hadoop_pkgver&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;.tgz

tar -xzvf spark-&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;spark_pkgver&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;-bin-hadoop&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;hadoop_pkgver&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;.tgz
mv spark-&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;spark_pkgver&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;-bin-hadoop&lt;span class="si"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;hadoop_pkgver&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt; /usr/local/spark
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;配置 Spark&lt;/h2&gt;
&lt;p&gt;进入配置目录 &lt;code&gt;/usr/local/spark/conf&lt;/code&gt; 准备修改配置文件。&lt;/p&gt;
&lt;p&gt;在&lt;code&gt;slaves&lt;/code&gt;中配置slave节点的ip或者host，&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;vim ./slaves

spark-slave1
spark-slave2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;配置&lt;code&gt;spark-env.sh&lt;/code&gt; &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;cp /usr/local/spark/conf/spark-env.sh.template /usr/local/spark/conf/spark-env.sh
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;SPARK_MASTER_HOST=master&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; /usr/local/spark/conf/spark-env.sh
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;SPARK_LOCAL_IP={修改为每台机器对应的名称}&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; /usr/local/spark/conf/spark-env.sh
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;启动Spark&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo -s
su -
sbin/start-all.sh
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;如果没有问题，进入Spark的Web管理页面： &lt;a href="http://master:8080/"&gt;http://master:8080&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170611_193731" src="images/Screenshot_20170611_193731.png" width="80%"&gt;&lt;/p&gt;
&lt;h2&gt;脚本安装Spark&lt;/h2&gt;
&lt;p&gt;为了方便部署Spark，我简单写了一个Shell脚本，可以方便地几步搭建一个3节点的Spark集群。脚本地址为：&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/chih7/spark-install/"&gt;https://github.com/chih7/spark-install/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;脚本只在Ubuntu 16.04下进行了测试，但其他版本的Ubuntu和debian应该也是可以使用。&lt;/p&gt;
&lt;p&gt;首先使用VirtualBox安装一台Ubuntu服务器，在里面执行以下命令：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo -s
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;su -
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git clone https://github.com/chih7/spark-install.git
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; ./spark_install
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;./install-spark.sh
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;reboot
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;重启完成后，&lt;/p&gt;
&lt;p&gt;克隆这个虚拟机到两台虚拟机，记得修改克隆机的配置文件&lt;code&gt;/usr/local/spark/conf/spark-env.sh&lt;/code&gt;中的&lt;code&gt;SPARK_LOCAL_IP&lt;/code&gt;，之后就可以启动Spark集群了。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo -s
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;su -
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;vim  /usr/local/spark/conf/spark-env.sh &lt;span class="c1"&gt;# change  SPARK_LOCAL_IP=spark-xxxx&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/usr/local/spark/sbin/start-all.sh
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;实验结果描述&lt;/h1&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170611_122340" src="images/Screenshot_20170611_122340.png" width="80%"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170611_182331" src="images/Screenshot_20170611_182331.png" width="80%"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170611_182331" src="images/Screenshot_20170611_195236.png" width="80%"&gt;&lt;/p&gt;
&lt;p&gt;运行代码后，可以看到生成了一个DAG图，即为Spark的计算路径，其中有三个stage。最后输出了超出一定阈值的所有相似的文档对，同时给出了相似度系数。&lt;/p&gt;
&lt;h1&gt;出现的问题&lt;/h1&gt;
&lt;p&gt;在运行中出现&lt;code&gt;java.io.IOException: No space left on device&lt;/code&gt;错误，经过Google搜索，发现Spark默认使用 &lt;code&gt;/tmp&lt;/code&gt;目录存储中间结果，而&lt;code&gt;/tmp&lt;/code&gt;目录为tmpfs目录，出于内存文件系统，默认大小仅为内存大小的一半。&lt;/p&gt;
&lt;p&gt;为了解决这个问题，需要自定义&lt;code&gt;SPARK_LOCAL_DIRS&lt;/code&gt;环境变量到一个足够大的目录下，我这里把它改到了Spark的安装目录。&lt;/p&gt;</content><category term="linux"></category><category term="Spark"></category><category term="scala"></category><category term="SimJion"></category><category term="相似度检测"></category></entry><entry><title>抓取网页中所有PDF链接并下载的Python脚本</title><link href="https://blog.chih.me/vldb-downloader.html" rel="alternate"></link><published>2017-07-05T00:00:00+08:00</published><updated>2017-07-05T00:00:00+08:00</updated><author><name>chih</name></author><id>tag:blog.chih.me,2017-07-05:/vldb-downloader.html</id><summary type="html">&lt;h3&gt;说点什么&lt;/h3&gt;
&lt;p&gt;没什么好说的，工具脚本，代码都在下面，可能改一下后可以适用于其他地方。&lt;/p&gt;
&lt;h3&gt;代码&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/usr/bin/env python3&lt;/span&gt;
&lt;span class="c1"&gt;# -*- coding: utf-8 -*-&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;Created on Thu Jul  6 11:04:53 2017&lt;/span&gt;

&lt;span class="sd"&gt;@author: chih&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;bs4&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;requests&lt;/span&gt;

&lt;span class="n"&gt;BASE_URL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;http://www.vldb.org/pvldb/vol10.html&amp;#39;&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;VldbCrawler&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;base_url&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;BASE_URL&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;base_url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;base_url&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;fetch_download_link&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self …&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;h3&gt;说点什么&lt;/h3&gt;
&lt;p&gt;没什么好说的，工具脚本，代码都在下面，可能改一下后可以适用于其他地方。&lt;/p&gt;
&lt;h3&gt;代码&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/usr/bin/env python3&lt;/span&gt;
&lt;span class="c1"&gt;# -*- coding: utf-8 -*-&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class="sd"&gt;Created on Thu Jul  6 11:04:53 2017&lt;/span&gt;

&lt;span class="sd"&gt;@author: chih&lt;/span&gt;
&lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;bs4&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;requests&lt;/span&gt;

&lt;span class="n"&gt;BASE_URL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;http://www.vldb.org/pvldb/vol10.html&amp;#39;&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;VldbCrawler&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;base_url&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;BASE_URL&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;base_url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;base_url&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;fetch_download_link&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;page&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;BASE_URL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;page&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;lxml&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;findAll&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;a&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;pdf_map&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;attrs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;href&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]},&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;item&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;pdf_map&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;.pdf&amp;quot;&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;pdf_map&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;www.vldb.org&amp;quot;&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;pdf_map&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
                &lt;span class="n"&gt;pdf_r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pdf_map&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
                &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;item&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;.pdf&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;wb&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;pdf_file&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="n"&gt;pdf_file&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pdf_r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;content&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;run&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fetch_download_link&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;


&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="vm"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;vc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;VldbCrawler&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;vc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</content><category term="linux"></category><category term="python"></category><category term="crawler"></category></entry><entry><title>Spark SQL 笔记</title><link href="https://blog.chih.me/spark-sql-ppt.html" rel="alternate"></link><published>2017-06-25T00:00:00+08:00</published><updated>2017-06-25T00:00:00+08:00</updated><author><name>chih</name></author><id>tag:blog.chih.me,2017-06-25:/spark-sql-ppt.html</id><summary type="html">&lt;h1&gt;Spark SQL Overview&lt;/h1&gt;
&lt;p&gt;特性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spark SQL是Apache Spark中的一个新模块&lt;/li&gt;
&lt;li&gt;将关系处理（tables with rows/columns）与Spark的功能编程API相集成&lt;/li&gt;
&lt;li&gt;通过 SQL 操作 RDDs， 同时提供多种语言绑定&lt;/li&gt;
&lt;li&gt;数据源集成：Hive, Parquet, JSON,and more&lt;/li&gt;
&lt;li&gt;提供 JDBC/ODBC 接口供外部程序调用（商业智能、olap分析）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;目标：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;写更少的代码&lt;/li&gt;
&lt;li&gt;读更少的数据&lt;/li&gt;
&lt;li&gt;获得更高的性能&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;Spark SQL in Spark&lt;/h1&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170522_193655" src="images/Screenshot_20170522_193655.png" width="80%"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spark SQL was first released in Spark 1.0 (May, 2014)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;Relationship …&lt;/h1&gt;</summary><content type="html">&lt;h1&gt;Spark SQL Overview&lt;/h1&gt;
&lt;p&gt;特性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spark SQL是Apache Spark中的一个新模块&lt;/li&gt;
&lt;li&gt;将关系处理（tables with rows/columns）与Spark的功能编程API相集成&lt;/li&gt;
&lt;li&gt;通过 SQL 操作 RDDs， 同时提供多种语言绑定&lt;/li&gt;
&lt;li&gt;数据源集成：Hive, Parquet, JSON,and more&lt;/li&gt;
&lt;li&gt;提供 JDBC/ODBC 接口供外部程序调用（商业智能、olap分析）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;目标：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;写更少的代码&lt;/li&gt;
&lt;li&gt;读更少的数据&lt;/li&gt;
&lt;li&gt;获得更高的性能&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;Spark SQL in Spark&lt;/h1&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170522_193655" src="images/Screenshot_20170522_193655.png" width="80%"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spark SQL was first released in Spark 1.0 (May, 2014)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;Relationship to Shark&lt;/h1&gt;
&lt;p&gt;Spark上的第一个关系数据库是Shark，它修改了Apache Hive系统，使之能在Spark上运行，并通过Spark引擎实现了传统的RDBMS优化。&lt;/p&gt;
&lt;p&gt;虽然Shark表现出良好的表现和与Spark计划融合的良好机会，但它有三个重要挑战：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Shark只能用于查询存储在Hive目录中的外部数据&lt;/li&gt;
&lt;li&gt;Spark程序调用Shark的唯一方法是组合一个SQL字符串&lt;/li&gt;
&lt;li&gt;Hive优化器是针对MapReduce量身定制的，难以扩展，难以构建新功能&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;Relationship to Shark&lt;/h1&gt;
&lt;p&gt;借鉴：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;hive 数据源的加载&lt;/li&gt;
&lt;li&gt;使用列存储实现内存中的“缓存”&lt;/li&gt;
&lt;li&gt;UDFs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;新增：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;支持Spark程序（本地RDD），新的外部数据源的关系处理。&lt;/li&gt;
&lt;li&gt;高级分析算法（如图形处理和机器学习）扩展。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;Programming Interface&lt;/h1&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170523_103741" src="images/Screenshot_20170523_103741.png" width="80%"&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h1&gt;DataFrame&lt;/h1&gt;
&lt;p&gt;Spark SQL API中的主要抽象方法是DataFrame&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;取代了以前的（Spark &amp;lt; 1.3）SchemaRDD。&lt;/li&gt;
&lt;li&gt;类似与R和pandas中的DataFrame，DataFrame等价于关系数据库中的表，每一列都有命名。但Spark SQL中的DataFrame基于RDD，是分布式的。RDD可以转换为DataFrame。&lt;/li&gt;
&lt;li&gt;DataFrame 支持多种数据类型与所有常见的关系运算符。&lt;/li&gt;
&lt;li&gt;Spark DataFrames是懒惰的，每个DataFrame对象都代表一个用于计算数据集的逻辑计划，但是直到用户调用特定的“输出操作”（如保存）才会执行任何执行。&lt;/li&gt;
&lt;li&gt;DataFrames提供与关系查询语言（如SQL和Pig）相同的操作。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;Getting Started: Spark SQL&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Import Spark SQL&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pyspark.sql&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;HiveContext&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Row&lt;/span&gt;
&lt;span class="c1"&gt;# Or if you can&amp;#39;t include the hive requirements&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pyspark.sql&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;SQLContext&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Row&lt;/span&gt;

&lt;span class="n"&gt;hiveCtx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;HiveContext&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;sqlCtx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;SQLContext&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;As of Spark 2.0, HiveContext and SQLContext are replaced by SparkSession. However, we are keeping the class here for backward compatibility.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h1&gt;Getting Started: Spark SQL&lt;/h1&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pyspark.sql&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;HiveContext&lt;/span&gt;
&lt;span class="n"&gt;hiveCtx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;HiveContext&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sc&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;rows&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hiveCtx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;SELECT key, value FROM mytable&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;keys&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;rows&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;lambda&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;input&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hiveCtx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jsonFile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;inputFile&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;happyPeopleRDD&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;sc&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parallelize&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;Row&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;holden&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;favouriteBeverage&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;coffee&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;
&lt;span class="n"&gt;happyPeopleSchemaRDD&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hiveCtx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;inferSchema&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;happyPeopleRDD&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;happyPeopleSchemaRDD&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;registerTempTable&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;happy_people&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;hr&gt;
&lt;h1&gt;Catalyst Optimizer&lt;/h1&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170523_111752" src="images/Screenshot_20170523_111752.png" width="90%"&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h1&gt;Performance&lt;/h1&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170522_195943" src="images/Screenshot_20170522_195943.png" width="90%"&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h1&gt;Performance&lt;/h1&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170522_200157" src="images/Screenshot_20170522_200157.png" width="60%"&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h1&gt;参考&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;ARMBRUST M, GHODSI A, ZAHARIA M. Spark SQL: Relational Data Processing in Spark[C]//ACM Press, 2015: 1383–1394.&lt;/li&gt;
&lt;li&gt;Spark快速大数据分析[M]. 人民邮电出版社, 2015.&lt;/li&gt;
&lt;li&gt;https://pandas.pydata.org/pandas-docs/stable/dsintro.html&lt;/li&gt;
&lt;/ol&gt;</content><category term="spark"></category><category term="big data"></category><category term="SQL"></category><category term="SQL on Hadoop，hadoop"></category></entry><entry><title>Spark SQL</title><link href="https://blog.chih.me/spark-sql.html" rel="alternate"></link><published>2017-06-24T00:00:00+08:00</published><updated>2017-06-24T00:00:00+08:00</updated><author><name>chih</name></author><id>tag:blog.chih.me,2017-06-24:/spark-sql.html</id><summary type="html">&lt;h1&gt;Spark 简介&lt;/h1&gt;
&lt;p&gt;Hadoop 伴随着大数据的兴起已有十年时间，被认为是大数据处理的首选解决方案， 它分别提供HDFS和MapReduce解决了大数据（无法在单台机器上存储与处理的数据）的可靠存储和处理，但对于一些场景， MapReduce并不是十分高效，其一，MapReduce的抽象层次低，仅提供了map和reduce两个操作，对于应用需要编写大量代码；其二，一个job只包括了map和reduce两个阶段，想要完成复杂的工作，就必须串联一系列MapReduce作业，但每一步的输出数据必须存储到HDFS，导致io操作繁重，时延较高，只适合批处理，不适合实时处理和迭代计算。&lt;/p&gt;
&lt;p&gt;Apache Spark是一个新兴的大数据处理引擎，它允许开发者使用有向无环图 (DAG) 开发复杂的数据操作，内部使用一个集群上的分布式内存抽象 (RDD) ，简化了对分布式数据的编程复杂性。RDD 提供了两类操作，转换和动作，转换在原有 RDD 上通过一些操作定义了一个新的 RDD ，包括map, flatMap, filter, union, sample, join, groupByKey, cogroup, ReduceByKey, cros, sortByKey, mapValues等 …&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Spark 简介&lt;/h1&gt;
&lt;p&gt;Hadoop 伴随着大数据的兴起已有十年时间，被认为是大数据处理的首选解决方案， 它分别提供HDFS和MapReduce解决了大数据（无法在单台机器上存储与处理的数据）的可靠存储和处理，但对于一些场景， MapReduce并不是十分高效，其一，MapReduce的抽象层次低，仅提供了map和reduce两个操作，对于应用需要编写大量代码；其二，一个job只包括了map和reduce两个阶段，想要完成复杂的工作，就必须串联一系列MapReduce作业，但每一步的输出数据必须存储到HDFS，导致io操作繁重，时延较高，只适合批处理，不适合实时处理和迭代计算。&lt;/p&gt;
&lt;p&gt;Apache Spark是一个新兴的大数据处理引擎，它允许开发者使用有向无环图 (DAG) 开发复杂的数据操作，内部使用一个集群上的分布式内存抽象 (RDD) ，简化了对分布式数据的编程复杂性。RDD 提供了两类操作，转换和动作，转换在原有 RDD 上通过一些操作定义了一个新的 RDD ，包括map, flatMap, filter, union, sample, join, groupByKey, cogroup, ReduceByKey, cros, sortByKey, mapValues等，动作是返回一个结果，包括collect, reduce, count, save, lookupKey。在这里，所有的转换操作都是惰性求值的，只有执行到动作操作才会真正进行数据处理。即，RDD的转换操作会生成新的RDD，新的RDD的数据依赖于原来的RDD的数据，每个RDD又包含多个分区。那么一段程序实际上就构造了一个由相互依赖的多个RDD组成的 DAG， 并通过在RDD上执行动作将这个有向无环图作为一个Job提交给Spark执行。通过RDD的惰性计算，减少了数据的传输和写磁盘操作，在某些情景下，可以将spark的速度提高到Hadoop的100倍。同时，RDD是容错的，系统可以使用RDD的谱系图恢复丢失的数据。&lt;/p&gt;
&lt;p&gt;Spark  支持 Hadoop 的分布式文件系统 HDFS，也可以将 Spark 部署到 Hadoop 的资源调度框架 Yarn 之上， 因此，可以将Spark 看作 Hadoop MapReduce 的一个替代品。Spark和Hadoop的差别不仅仅在增强了MapReduce上，Spark还提供高级的(Scala，Java和Python)API以提升开发者的生产力，此外，Spark框架为批处理（Spark Core），交互式（Spark SQL），流式（Spark Streaming），机器学习（MLlib），图计算（GraphX）提供一个统一的数据处理平台，这相对于使用Hadoop有很大优势。&lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170522_193655" src="images/Screenshot_20170522_193655.png" width="80%"&gt;&lt;/p&gt;
&lt;h1&gt;Spark SQL&lt;/h1&gt;
&lt;p&gt;对大数据的处理方式早期有MapReduce，在Spark出现后多了对RDD的转换和动作API，对这些强大但低级的编程接口进行编程是十分繁重的，需要用户手动优化以实现高性能和数据分布均衡。因此，目前多个系统旨在向大数据提供关系接口(SQL)来提供更高效的用户体验，诸如Pig，Hive，Dremel和Shark之类的系统都利用声明式查询来提供更丰富的自动优化。特别是，SQL由于其简单的特点，被广泛使用，同时，传统数据库有着几十年的SQL优化经验，如果SQL优化策略合入大数据处理中，这将大大简化大数据的处理过程，降低对用户的要求，也可以自动提高处理效率。&lt;/p&gt;
&lt;p&gt;Spark SQL的前身是Shark，Shark 基本上就是把Hive移植到了Spark，使用Spark作为执行引擎后，Shark确实比Hive的执行效率有了极大提升，但由于Hive的优化器是针对MapReduce量身定制的，难以扩展，难以构建新功能，例如机器学习的数据类型或支持除Hive外的新数据源。因此在2014年6月1日Shark项目和Spark SQL项目的主持人Reynold Xin宣布：停止对Shark的开发，团队将所有资源放Spark SQL项目上。Spark SQL是Apache Spark中的一个新模块，它将关系处理与Spark的功能编程API相集成。基于Shark上的经验，Spark SQL允许Spark程序员利用关系处理（例如声明式查询和优化存储）的优势，并允许SQL用户在Spark中调用复杂的分析库（例如机器学习）。&lt;/p&gt;
&lt;p&gt;SparkSQL体系结构如下图所示，整体由上到下分为三层：编程模型层、执行任务优化层以及任务执行引擎层，其中SparkSQL编程模型可以分为SQL和DataFrame两种；执行计划优化又称为Catalyst，该模块负责将SQL语句解析成AST（逻辑执行计划），并对原始逻辑执行计划进行优化，最终输出优化后的物理执行计划；任务执行引擎就是Spark内核，负责根据物理执行计划生成DAG，在任务调度系统的管理下分解为任务集并分发到集群节点上加载数据运行。&lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170523_103741" src="images/Screenshot_20170523_103741.png" width="80%"&gt;&lt;/p&gt;
&lt;h1&gt;DataFrame&lt;/h1&gt;
&lt;p&gt;Spark SQL API 中的主要抽象方法是 DataFrame，DataFrame类似于R 和 Python pandas 中的 DataFrame , 与关系型数据库中的数据库表类似，每一列都有命名。但 Spark SQL 中的 DataFrame 基于RDD，是分布式的。在Spark 1.3之前， 它被称为SchemaRDD。RDD 可以转换为 DataFrame，但与RDD不同，DataFrames跟踪其模式并支持各种关系操作以得到更优化的执行。即，RDD是不知道内部数据的结构的，而使用DataFrame可以让框架了解RDD内部的数据结构，便于引擎进行优化。&lt;/p&gt;
&lt;p&gt;可以根据下图对比RDD与DataFrame数据结构的差别：&lt;/p&gt;
&lt;p&gt;&lt;img alt="12" src="images/12.png"&gt;&lt;/p&gt;
&lt;p&gt;从图上看，DataFrame相比RDD多了一个表头，同时每列的数据类型也被规定了。DataFrame将一行切分了多个列，每个列都有一定的数据格式，数据粒度相比更细，因此就能支持更多更细粒度的算子，比如select算子、groupby算子、where算子。由于每列的数据类型被规定了，数据项的转换也都将是类型安全的，这对于较为复杂的数据计算程序的调试是十分有利的，很多数据类型不匹配的问题都可以在编译阶段就被检查出来。&lt;/p&gt;
&lt;p&gt;DataFrames可以从系统目录中的表（基于外部数据源）构建，也允许程序通过JDBC / ODBC访问数据集。一旦DataFrame构建完成，它们可以用各种关系运算符来处理，例如where和groupBy，它们类似于与R和Python中的数据帧域特定语言（DSL）表达式。与RDD类似，Spark DataFrames是懒惰的，因为每个DataFrame对象都代表一个用于计算数据集的逻辑计划，但是直到用户调用特定的“输出操作”（如保存）才会执行任何执行。用户可以使用类似于R数据帧和Python Pandas的域特定语言（DSL）来对DataFrames执行关系操作。DataFrames支持所有常见的关系运算符，包括投影（选择），过滤器（where），连接和聚合（groupBy）。&lt;/p&gt;
&lt;h1&gt;Catalyst 优化器&lt;/h1&gt;
&lt;p&gt;Scala的一些特性使得它非常适合开发优化编译器，为了实现Spark SQL，Spark开发者基于Scala中的功能编程结构设计了一个新的可扩展优化器Catalyst。Catalyst的核心包含一个用于表示树并应用规则来操纵树的通用库，在此之上，构建了专用于关系查询处理（例如表达式，逻辑查询计划）执行不同阶段的规则：分析，逻辑优化，物理规划和代码生成。Catalyst是可扩展的，其目的在于能够轻松地向Spark SQL添加新的优化技术和功能，特别是为了解决我们特别使用“大数据”（例如，半结构化数据和高级分析）所遇到的各种问题，同时，使外部开发人员能够扩展优化器，例如，通过添加可将过滤或聚合推送到外部存储系统的数据源特定规则，或支持新的数据类型。&lt;/p&gt;
&lt;p&gt;SQL优化器核心执行策略主要分为两个大的方向：基于规则优化（RBO）以及基于代价优化(CBO)，Catalyst支持基于规则和基于成本的优化，通过使用规则生成多个计划，然后计算其成本来执行基于代价的优化。Catalyst的大致流程为：SQL语句首先通过Parser模块被解析为语法树，此棵树称为Unresolved Logical Plan；Unresolved Logical Plan通过Analyzer模块借助于数据元数据解析为Logical Plan；此时再通过各种基于规则的优化策略进行深入优化，得到Optimized Logical Plan；优化后的逻辑执行计划依然是逻辑的，并不能被Spark系统理解，此时需要将此逻辑执行计划转换为Physical Plan。&lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170523_111752" src="images/Screenshot_20170523_111752.png" width="90%"&gt;&lt;/p&gt;
&lt;h2&gt;分析&lt;/h2&gt;
&lt;p&gt;Spark SQL从SQL解析器返回的抽象语法树（AST）或使用API构造的DataFrame对象中计算出的关系开始。在这两种情况下，关系可能包含未解析的属性引用或关系：例如，在SQL查询&lt;code&gt;SELECT col FROM sales&lt;/code&gt;中，col的类型，或者是否是有效的列名称，直到我们查找才会知道。如果我们不知道它的类型或者没有将它与输入表（或者别名）匹配，那么这个属性称为未解析。Spark SQL遍历整个语法树，使用Catalyst规则和Catalog对象来跟踪所有数据源中的表以解析这些属性。它首先构建一个具有未绑定属性和数据类型的“未解决的逻辑计划”树，然后应用执行以下操作的规则：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;从目录中按名称查找关系。&lt;/li&gt;
&lt;li&gt;将命名属性（例如col）映射到给定运算符的子节点的输入。&lt;/li&gt;
&lt;li&gt;确定哪些属性引用相同的值以给它们一个唯一的ID（稍后可以优化，如col = col）。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;逻辑优化&lt;/h2&gt;
&lt;p&gt;逻辑优化阶段将基于规则的优化应用于逻辑计划。基于规则的优化策略实际上就是对语法树进行一次遍历，模式匹配能够满足特定规则的节点，再进行相应的等价转换。因此，基于规则优化说到底就是一棵树等价地转换为另一棵树。SQL中经典的优化规则有很多，三种比较常见的规则有：谓词下推（Predicate Pushdown）、常量累加（Constant Folding）和列值裁剪（Column Pruning&lt;/p&gt;
&lt;h2&gt;物理规划&lt;/h2&gt;
&lt;p&gt;在物理规划阶段，Spark SQL采用逻辑计划，并使用与Spark执行引擎匹配的物理运算符生成一个或多个物理计划。然后使用成本模型选择一个计划。目前，SparkSQL没有很好的支持基于代价优化，基于成本的优化仅用于选择连接算法。物理计划员还可以执行基于规则的物理优化。&lt;/p&gt;
&lt;h2&gt;代码生成&lt;/h2&gt;
&lt;p&gt;查询优化的最后阶段包括生成Java字节码以在每台机器上运行。因为Spark SQL通常在内存数据集中运行，因为处理是CPU限制的，因此我们希望支持代码生成以加快执行速度。尽管如此，代码生成引擎通常很难构建，实际上与构建编译器相当。Catalyst依靠Scala语言的一个特殊功能，quasiquotes ，使代码生成更简单。Quasiquotes允许以Scala语言编程构建抽象语法树（AST），然后可以在运行时将其提供给Scala编译器以生成字节码。我们使用Catalyst将表示SQL中的表达式的树转换为用于Scala代码的AST，以评估该表达式，然后编译并运行生成的代码。&lt;/p&gt;</content><category term="spark"></category><category term="big data"></category><category term="SQL"></category><category term="SQL on Hadoop"></category><category term="Spark SQL"></category><category term="hadoop"></category></entry><entry><title>Shark</title><link href="https://blog.chih.me/shark-ppt.html" rel="alternate"></link><published>2017-06-23T00:00:00+08:00</published><updated>2017-06-23T00:00:00+08:00</updated><author><name>chih</name></author><id>tag:blog.chih.me,2017-06-23:/shark-ppt.html</id><summary type="html">&lt;h1&gt;Shark Overview&lt;/h1&gt;
&lt;p&gt;一个独立，快速，类MapReduce的SQL引擎&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基于内存存储数据，适合交互式查询&lt;/li&gt;
&lt;li&gt;优秀的查询优化&lt;/li&gt;
&lt;li&gt;比Hadoop快40倍以上&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;完全兼容Hadoop存储接口&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可以读取或写入任何支持Hadoop的系统&lt;/li&gt;
&lt;li&gt;包括HDFS，Hbase，SequenceFiles&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;Shark Overview&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Shark即Hive on Spark，本质上是通过Hive的HQL解析，把HQL翻译成Spark上的RDD操作，然后通过Hive的metadata获取数据库里的表信息，实际HDFS上的数据和文件，会由Shark获取并放到Spark上运算。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Shark建立在Hive的代码基础上，并通过将Hive的部分物理执行计划交换出来（by swapping out the physical execution engine part of Hive）。这个方法使得Shark的用户可以加速Hive的查询&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Shark在HQL方面重用了Hive中HQL的解析、逻辑执行计划翻译、执行计划优化等逻辑，完全兼容已有的Hive数据，metastores 和 查询( HiveQL，UDFs )&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;Project History&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Spark project …&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;h1&gt;Shark Overview&lt;/h1&gt;
&lt;p&gt;一个独立，快速，类MapReduce的SQL引擎&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基于内存存储数据，适合交互式查询&lt;/li&gt;
&lt;li&gt;优秀的查询优化&lt;/li&gt;
&lt;li&gt;比Hadoop快40倍以上&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;完全兼容Hadoop存储接口&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可以读取或写入任何支持Hadoop的系统&lt;/li&gt;
&lt;li&gt;包括HDFS，Hbase，SequenceFiles&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;Shark Overview&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Shark即Hive on Spark，本质上是通过Hive的HQL解析，把HQL翻译成Spark上的RDD操作，然后通过Hive的metadata获取数据库里的表信息，实际HDFS上的数据和文件，会由Shark获取并放到Spark上运算。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Shark建立在Hive的代码基础上，并通过将Hive的部分物理执行计划交换出来（by swapping out the physical execution engine part of Hive）。这个方法使得Shark的用户可以加速Hive的查询&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Shark在HQL方面重用了Hive中HQL的解析、逻辑执行计划翻译、执行计划优化等逻辑，完全兼容已有的Hive数据，metastores 和 查询( HiveQL，UDFs )&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;Project History&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Spark project started in 2009, open sourced 2010&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Shark项目开始时，Hive（MapReduce）是Hadoop上SQL的唯一选择。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Shark started summer 2011, alpha April 2012&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Shark has been subsumed by Spark SQL 2014&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;动机&lt;/h1&gt;
&lt;p&gt;数据仓库&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;难以横向扩展&lt;/li&gt;
&lt;li&gt;需要有错误恢复，任务迁移的机制&lt;/li&gt;
&lt;li&gt;传统的OLAP操作无法应对日益复杂，多样的数据，需要嵌入机器学习算法等现代数据分析算法&lt;/li&gt;
&lt;li&gt;处理时间长，无法做到即时交互&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一些解决途径&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tenzing，  HadoopDB (基于MapReduce， 细粒度)&lt;/li&gt;
&lt;li&gt;Google F1，  Impala (粗粒度)&lt;/li&gt;
&lt;li&gt;Apache Hive&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;Hive Architecture&lt;/h1&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170702_210019" src="images/Screenshot_20170702_210019.png" width="80%"&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h1&gt;Shark Architecture&lt;/h1&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170702_210127" src="images/Screenshot_20170702_210127.png" width="80%"&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h1&gt;为什么需要一个新的编程模型&lt;/h1&gt;
&lt;p&gt;MapReduce 编程模型被提出后被广泛使用，简化了大数据的编程&lt;/p&gt;
&lt;p&gt;但它在一些特殊场景下表现不佳：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;许多复杂分析的函数是迭代的，比如说机器学习和图算法。&lt;/li&gt;
&lt;li&gt;实时性要求比较高的场景，要求和用户交互。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;即使传统 SQL 仓库的工作负载也表现出很强的时间和空间局部性，这是因为最近的事实表数据和小维度表数据经常频繁地被读取。&lt;/p&gt;
&lt;hr&gt;
&lt;h1&gt;Shark速度快的原因&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Spark平台提供的基于内存迭代计算(RDD)&lt;/li&gt;
&lt;li&gt;partial DAG execution：在一个DAG 任务运行了前几个阶段之后，Spark 可以基于观测到的统计数据，选择一个更好的连接策略或者更合适的并发度，从而能够重新优化正在运行的查询。&lt;/li&gt;
&lt;li&gt;基于列的存储和压缩：把HQL表数据按列存，每列是一个array，存在JVM上，避免了序列化和反序列带来的低效，同时，也避免了JVM GC低效。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170702_210324" src="images/Screenshot_20170702_210324.png" width="60%"&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h1&gt;Shark速度快的原因&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;传统的MapReduce系统，就比如Hadoop，是为了运行长达数小时的批量作业而设计的，而组成作业的每个任务其运行时间则有数分钟之久，他们会在独立的系统进程中执行任务，在某些极端情况下提交一个任务的延迟非常之高。&lt;/li&gt;
&lt;li&gt;Spark采用了事件驱动的RPC类库来启动任务，通过复用工作进程来避免系统进程开销。它能够在一秒钟内启动上千个任务，任务之间的延时小于5毫秒，从而使得50-100毫秒的任务，500毫秒的作业变得可能。&lt;/li&gt;
&lt;li&gt;亚秒级的任务使得引擎能够更好地在工作节点之间平衡任务的分配，甚至在某些节点遇到了不可预知的延迟(网络延迟或是JVM垃圾回收)的情况下面也能较好地平衡。同时对于数据倾斜也有巨大的帮助，&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;为什么之前的MapReduce系统比较慢&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;容错所引入的昂贵数据实体化(data materialization)开销。&lt;/li&gt;
&lt;li&gt;孱弱的数据布局(data layout)，比如缺少索引。&lt;/li&gt;
&lt;li&gt;执行策略的开销。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面针对这三点说明Shark的优化。&lt;/p&gt;
&lt;hr&gt;
&lt;h1&gt;中间结果输出&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;在MapReduce任务内部，为了防止Reduce任务的失败，Map通常会把结果存储在磁盘上(materialize)。&lt;/li&gt;
&lt;li&gt;通常一些查询在翻译到MapReduce任务的时候，往往会产生多个stage，而这些串联的stage则又依赖于底层文件系统(如HDFS)来存储每一个stage的输出结果。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170702_193250" src="images/Screenshot_20170702_193250.png"&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170702_193305" src="images/Screenshot_20170702_193305.png"&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h1&gt;中间结果输出&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Map的输出结果存储在磁盘上是为了确保能够有足够的空间来存储这些大数据批量任务的输出。而Map的输出并不会复制到不同的节点上去，因此如果执行Map任务的节点失效的话仍会造成数据丢失。由此可以推出，如果将这部分输出数据缓存在内存中，而不是全部输出到磁盘上面也是合理的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Shark内部的Spark引擎扩展了MapReduce的执行模型，将MapReduce的执行模型泛化成更为通用的执行计划图(task DAG)，可以将多stage的任务串联执行而无需将stage中间结果输出到HDFS中去。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h1&gt;列式内存存储&lt;/h1&gt;
&lt;p&gt;内存中数据表示的3种方法:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;内存中直接缓存磁盘上序列化后的数据. 在查询时根据需求进行反序列化, 反序列化是瓶颈.&lt;/li&gt;
&lt;li&gt;将数据分区作为 JVM 对象集合存储, 可以避免反序列化, 但占用空间较大. 大量的 JVM 对象同时会导致 JVM 的垃圾收集耗时严重.&lt;/li&gt;
&lt;li&gt;列示内存存储, 每一列仅创建一个 JVM 对象, 可以带来快速访问, 垃圾收集和紧凑的数据表示。&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h1&gt;数据格式和布局&lt;/h1&gt;
&lt;p&gt;列式内存存储&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;反序列化成为了很大的瓶颈，在现代的商业CPUs 单核的序列化速率仅仅在 200MB/秒。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;在Shark中采用了基于内存的列式存储结构，Shark简单地将一组列式元组存储为Spark内的一条记录，而对于列式元组内的结构则有Shark负责解析。&lt;/li&gt;
&lt;li&gt;每一列仅创建一个 JVM 对象，可以带来快速的 GCs 和紧凑的数据表示。通过廉价的几乎不需要 CPU 成本的压缩技术，可以将列数据的空间占用进一步减少。&lt;/li&gt;
&lt;li&gt;列式数据带来了更好的缓存行为，特别是对那些在特定列上频繁进行聚合计算的分析查询。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;数据格式和布局&lt;/h1&gt;
&lt;p&gt;联合分区&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;另一个Spark独有的特性是能够控制数据在不同节点上的分区，这为Shark带来了一种新的功能：对表进行联合分区(co-partition)。&lt;/li&gt;
&lt;li&gt;Shark 允许两个表基于公共键进行协同分区，从而可以在后续的查询中提供快速的连接操作。它在表的创建声明中增加了 DISTRIBUTE BY 语法，用来指定对某个列进行分区。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;执行策略&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;partial DAG execution (PDE)，这使得Spark能够在基于数据统计的基础上改变后续执行计划。&lt;/li&gt;
&lt;li&gt;PDE与其他系统(DryadLINQ)的运行时执行计划图重写的不同在于：它能够收集键值范围内的细粒度统计数据；能够完全重新选择join的执行策略，如broadcast join，而不仅仅是选择Reduce任务的个数。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;分区统计和映射修剪&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;为了利用列（column）在自然聚合的优势，Shark 在每一个工作节点上的的内存存储会在数据加载过程中附带收集统计信息。&lt;/li&gt;
&lt;li&gt;每个分区收集来的统计信息包含了每一个列的范围, 当不同值的个数较少的时候, 会包含所有不同的值。所收集到的统计信息会被发送回驱动节点并存储在内存中, 在查询执行过程中用于修剪分区.&lt;/li&gt;
&lt;li&gt;当发出一个查询后，Shark 会针对查询的目标评估所有的分区统计信息，然后修剪掉没有匹配到目标的分区。&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;Performance&lt;/h1&gt;
&lt;p&gt;使用了四个数据集对 Shark 进行了评估：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Pavlo 等人的基准测试：用 2.1TB 的数据重现了 Pavlo 等人对 MapReduce 和分析数据库管理系统的比较&lt;/li&gt;
&lt;li&gt;TPC-H 数据集:由 DBGEN 程序产生了 100G 和 1TB 的数据集&lt;/li&gt;
&lt;li&gt;1.7TB的真实的 Hive 仓库&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;100GB的机器学习数据集&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;实验显示同时使用 RDD 和上面提到的优化方法，在 SQL 查询方面，Spark 的速度可以达到Hive 的 100 倍；在运行迭代的机器学习算法方面，Spark 的速度可以达到 Hadoop 的 100 倍&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;可以在几秒钟内从查询错误中恢复&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h1&gt;Pavlo 等人的基准测试&lt;/h1&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170702_193839" src="images/Screenshot_20170702_193839.png" width="50%"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170702_211547" src="images/Screenshot_20170702_211547.png" width="50%"&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h1&gt;微基准测试&lt;/h1&gt;
&lt;p&gt;&lt;img alt="" src="images/Screenshot_20170702_194031.png" width="40%"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="images/Screenshot_20170702_194038.png" width="40%"&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h1&gt;容错&lt;/h1&gt;
&lt;p&gt;在出现节点错误的情况下，对 100GB lineitem 表使用 group by 查询来测试查询性能。在将 lineitem 的数据加载到 shark 的内存后，我们切断了一台工作的机器并重新运行该查询。 Shark 能完美地从故障中恢复，并以并行的方式在其他 49 个节点上重新构建丢失的数据分区。这个恢复过程对性能有小许的影响，但比重新加载整个数据集并重新进行查询的成本 要低很多 (14 vs 34 秒)。&lt;/p&gt;
&lt;hr&gt;
&lt;h1&gt;真实的 Hive 数据仓库查询&lt;/h1&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170702_212039" src="images/Screenshot_20170702_212039.png" width="60%"&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h1&gt;机器学习&lt;/h1&gt;
&lt;p&gt;&lt;img alt="Screenshot_20170702_194105" src="images/Screenshot_20170702_194105.png" width="60%"&gt;&lt;/p&gt;</content><category term="spark"></category><category term="big data"></category><category term="SQL"></category><category term="SQL on Hadoop"></category><category term="shark"></category><category term="hadoop"></category></entry><entry><title>Energy measurements in Linux</title><link href="https://blog.chih.me/read-cpu-power-with-RAPL.html" rel="alternate"></link><published>2017-01-31T00:00:00+08:00</published><updated>2017-01-31T00:00:00+08:00</updated><author><name>chih</name></author><id>tag:blog.chih.me,2017-01-31:/read-cpu-power-with-RAPL.html</id><summary type="html">&lt;h3&gt;RAPL&lt;/h3&gt;
&lt;p&gt;RAPL provides a set of counters providing energy and power consumption information. RAPL is not an analog power meter, but rather uses a software power model. This software power model estimates energy usage by using hardware performance counters and I/O models. Based on our measurements, they match actual …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;RAPL&lt;/h3&gt;
&lt;p&gt;RAPL provides a set of counters providing energy and power consumption information. RAPL is not an analog power meter, but rather uses a software power model. This software power model estimates energy usage by using hardware performance counters and I/O models. Based on our measurements, they match actual power measurements.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The processor has one or more &lt;em&gt;packages&lt;/em&gt;. These are part of the actual processor that you buy from Intel. Client processors (e.g. Core i3/i5/i7) have one package. Server processors (e.g. Xeon) typically have two or more packages.&lt;/li&gt;
&lt;li&gt;Each package contains multiple &lt;em&gt;cores&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Each core typically has hyper-threading, which means it contains two logical &lt;em&gt;CPUs&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;The part of the package outside the cores is called the &lt;em&gt;uncore&lt;/em&gt; our &lt;em&gt;system agent&lt;/em&gt;. It includes various components including the L3 cache, memory controller, and, for processors that have one, the integrated GPU.&lt;/li&gt;
&lt;li&gt;RAM is separate from the processor.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="power-planes" src="images/power-planes.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Recent (Sandy Bridge and later) Intel processors that implement the &lt;em&gt;RAPL&lt;/em&gt; (Running Average Power Limit) interface that provides MSRs containing energy consumption estimates for up to four &lt;em&gt;power planes&lt;/em&gt; or &lt;em&gt;domains&lt;/em&gt; of a machine, as seen in the diagram above.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PKG: The entire package.&lt;/li&gt;
&lt;li&gt;PP0: The cores.&lt;/li&gt;
&lt;li&gt;PP1: An uncore device, usually the GPU (not available on all processor models.)&lt;/li&gt;
&lt;li&gt;DRAM: main memory (not available on all processor models.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The following relationship holds: PP0 + PP1 &amp;lt;= PKG. DRAM is independent of the other three domains.&lt;/p&gt;
&lt;p&gt;Tools that can take RAPL readings include the following.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;mozilla_rapl&lt;/code&gt;: all planes; Linux and Mac.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Intel Power Gadget&lt;/code&gt;: PKG and PP0 planes; Windows, Mac and Linux.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;perf&lt;/code&gt;: all planes; Linux.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;turbostat&lt;/code&gt;: PKG, PP0 and PP1 planes; Linux.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;PAPI&lt;/code&gt;: read RAPL events&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;MSR&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A model-specific register (MSR) is any of various control registers in the x86 instruction set used for debugging, program execution tracing, computer performance monitoring, and toggling certain CPU features.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;https://lwn.net/Articles/545745/&lt;/p&gt;
&lt;p&gt;https://01.org/blogs/2014/running-average-power-limit-%E2%80%93-rapl&lt;/p&gt;
&lt;p&gt;https://developer.mozilla.org/en-US/docs/Mozilla/Performance/Power_profiling_overview&lt;/p&gt;
&lt;p&gt;https://access.redhat.com/documentation/zh-CN/Red_Hat_Enterprise_Linux/7/html/Power_Management_Guide/Core_Infrastructure.html&lt;/p&gt;
&lt;h3&gt;mozilla_rapl&lt;/h3&gt;
&lt;p&gt;原先是firefox中的一个性能、功耗分析软件，我去除了与Linux无关的代码，添加了编译脚本，现在可以独立于firefox编译运行。&lt;/p&gt;
&lt;p&gt;https://github.com/chih7/rapl&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# chih @ archlinux in ~/PMU/firefox_power [18:08:31] C:1&lt;/span&gt;
$ sudo ./rapl
&lt;span class="o"&gt;[&lt;/span&gt;sudo&lt;span class="o"&gt;]&lt;/span&gt; password &lt;span class="k"&gt;for&lt;/span&gt; chih: 
    total &lt;span class="nv"&gt;W&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; _pkg_ &lt;span class="o"&gt;(&lt;/span&gt;cores + _gpu_ + other&lt;span class="o"&gt;)&lt;/span&gt; + _ram_ W
&lt;span class="c1"&gt;#01  1.90 W =  1.45 ( 0.20 +  0.02 +  1.22) +  0.45 W&lt;/span&gt;
&lt;span class="c1"&gt;#02  1.77 W =  1.35 ( 0.11 +  0.03 +  1.21) +  0.42 W&lt;/span&gt;
&lt;span class="c1"&gt;#03  1.80 W =  1.39 ( 0.17 +  0.02 +  1.19) +  0.41 W&lt;/span&gt;
&lt;span class="c1"&gt;#04  1.87 W =  1.42 ( 0.17 +  0.02 +  1.23) +  0.45 W&lt;/span&gt;
&lt;span class="c1"&gt;#05  1.77 W =  1.36 ( 0.16 +  0.02 +  1.19) +  0.41 W&lt;/span&gt;
^C
&lt;span class="m"&gt;13&lt;/span&gt; samples taken over a period of &lt;span class="m"&gt;13&lt;/span&gt;.000 seconds

Distribution of &lt;span class="s1"&gt;&amp;#39;total&amp;#39;&lt;/span&gt; values:
            &lt;span class="nv"&gt;mean&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;.83 W
         std &lt;span class="nv"&gt;dev&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="m"&gt;0&lt;/span&gt;.04 W
  0th &lt;span class="nv"&gt;percentile&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;.77 W &lt;span class="o"&gt;(&lt;/span&gt;min&lt;span class="o"&gt;)&lt;/span&gt;
  5th &lt;span class="nv"&gt;percentile&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;.77 W
 25th &lt;span class="nv"&gt;percentile&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;.78 W
 50th &lt;span class="nv"&gt;percentile&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;.82 W
 75th &lt;span class="nv"&gt;percentile&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;.86 W
 95th &lt;span class="nv"&gt;percentile&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;.90 W
100th &lt;span class="nv"&gt;percentile&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="m"&gt;1&lt;/span&gt;.90 W &lt;span class="o"&gt;(&lt;/span&gt;max&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;intel power gadget&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo ./power_gadget -e &lt;span class="m"&gt;1000&lt;/span&gt; -d &lt;span class="m"&gt;10&lt;/span&gt; 
&lt;span class="o"&gt;[&lt;/span&gt;sudo&lt;span class="o"&gt;]&lt;/span&gt; password &lt;span class="k"&gt;for&lt;/span&gt; chih: 
RAPL not supported, or machine model 406e3 not recognized.
Init failed!
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;The power gadget doesn't support your CPU though: the RAPL initialisation code is table-driven, and it doesn't know about Skylake CPUs (or even Broadwell). It only knows about Sandy Bridge, Ivy Bridge and Haswell (and even then, not all Haswell CPUs)...&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;由于linux下的intel power gadget版本未及时更新，对于新cpu，比如我使用的Skylake架构的cpu，需要打一个补丁。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="c1"&gt;//chih&lt;/span&gt;
    &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="mh"&gt;0x406e0&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="cm"&gt;/* Skylake */&lt;/span&gt;
    &lt;span class="c1"&gt;//end&lt;/span&gt;
    &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="mh"&gt;0x40660&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="cm"&gt;/* Haswell:            0x4066X (Tables 35:11,12,14,17,19) */&lt;/span&gt;
    &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="mh"&gt;0x40650&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="cm"&gt;/* Haswell:            0x4065X (Tables 35:11,12,14,17,18,19) */&lt;/span&gt;
    &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="mh"&gt;0x306c0&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="cm"&gt;/* Haswell:            0x306cX (Tables 35:11,12,14,17,19) */&lt;/span&gt;
    &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="mh"&gt;0x306a0&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="cm"&gt;/* IvyBridge client:   0x306aX (Tables 35:11,12,14) */&lt;/span&gt;
    &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="mh"&gt;0x206a0&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="cm"&gt;/* SandyBridge client: 0x206aX (Tables 35:11,12) */&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# chih @ archlinux in ~/PMU/power_gadget [14:38:42] &lt;/span&gt;
$ sudo ./power_gadget -e &lt;span class="m"&gt;1000&lt;/span&gt; -d &lt;span class="m"&gt;10&lt;/span&gt; 
System Time,RDTSC,Elapsed Time &lt;span class="o"&gt;(&lt;/span&gt;sec&lt;span class="o"&gt;)&lt;/span&gt;,IA Frequency_0 &lt;span class="o"&gt;(&lt;/span&gt;MHz&lt;span class="o"&gt;)&lt;/span&gt;,Processor Power_0 &lt;span class="o"&gt;(&lt;/span&gt;Watt&lt;span class="o"&gt;)&lt;/span&gt;,Cumulative Processor Energy_0 &lt;span class="o"&gt;(&lt;/span&gt;Joules&lt;span class="o"&gt;)&lt;/span&gt;,Cumulative Processor Energy_0 &lt;span class="o"&gt;(&lt;/span&gt;mWh&lt;span class="o"&gt;)&lt;/span&gt;,IA Power_0 &lt;span class="o"&gt;(&lt;/span&gt;Watt&lt;span class="o"&gt;)&lt;/span&gt;,Cumulative IA Energy_0 &lt;span class="o"&gt;(&lt;/span&gt;Joules&lt;span class="o"&gt;)&lt;/span&gt;,Cumulative IA Energy_0&lt;span class="o"&gt;(&lt;/span&gt;mWh&lt;span class="o"&gt;)&lt;/span&gt;,GT Power_0 &lt;span class="o"&gt;(&lt;/span&gt;Watt&lt;span class="o"&gt;)&lt;/span&gt;,Cumulative GT Energy_0 &lt;span class="o"&gt;(&lt;/span&gt;Joules&lt;span class="o"&gt;)&lt;/span&gt;,Cumulative GT Energy_0&lt;span class="o"&gt;(&lt;/span&gt;mWh&lt;span class="o"&gt;)&lt;/span&gt;

......

Total Elapsed Time&lt;span class="o"&gt;(&lt;/span&gt;sec&lt;span class="o"&gt;)=&lt;/span&gt;&lt;span class="m"&gt;10&lt;/span&gt;.0297

Total Processor Energy_0&lt;span class="o"&gt;(&lt;/span&gt;Joules&lt;span class="o"&gt;)=&lt;/span&gt;&lt;span class="m"&gt;17&lt;/span&gt;.8525
Total Processor Energy_0&lt;span class="o"&gt;(&lt;/span&gt;mWh&lt;span class="o"&gt;)=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;.9590
Average Processor Power_0&lt;span class="o"&gt;(&lt;/span&gt;Watt&lt;span class="o"&gt;)=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;.7800

Total IA Energy_0&lt;span class="o"&gt;(&lt;/span&gt;Joules&lt;span class="o"&gt;)=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;.7968
Total IA Energy_0&lt;span class="o"&gt;(&lt;/span&gt;mWh&lt;span class="o"&gt;)=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;.0547
Average IA Power_0&lt;span class="o"&gt;(&lt;/span&gt;Watt&lt;span class="o"&gt;)=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;.3786

Total GT Energy_0&lt;span class="o"&gt;(&lt;/span&gt;Joules&lt;span class="o"&gt;)=&lt;/span&gt;&lt;span class="m"&gt;40348802750122148682202448929579954083587538418336263106019013328588433891916342955629569820500905624381003637605195948399507838978513675817091564240213448540197430240015810560&lt;/span&gt;.0000
Total GT Energy_0&lt;span class="o"&gt;(&lt;/span&gt;mWh&lt;span class="o"&gt;)=&lt;/span&gt;&lt;span class="m"&gt;11208000763922819273654924813042885804926161178964146820669218906461918837197055882285886611228023711591975233705039549465180590407264871893995315391999381929938313125054906368&lt;/span&gt;.0000
Average GT Power_0&lt;span class="o"&gt;(&lt;/span&gt;Watt&lt;span class="o"&gt;)=&lt;/span&gt;&lt;span class="m"&gt;4022936931619314615522564571277674057729988879436087598206455402730989779423177023450588030905067401122709863565105607495828398364105878169848967030480708805215802925837713408&lt;/span&gt;.0000

&lt;span class="nv"&gt;TSC&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;21411847472916&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;rapl-read&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://web.eece.maine.edu/~vweaver/projects/rapl/index.html"&gt;http://web.eece.maine.edu/~vweaver/projects/rapl/index.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;There are currently &lt;em&gt;three&lt;/em&gt; ways to read RAPL results using the Linux kernel:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Reading the files under &lt;code&gt;/sys/class/powercap/intel-rapl/intel-rapl:0&lt;/code&gt; using the powercap interface. This requires no special permissions, and was introduced in Linux 3.13&lt;/li&gt;
&lt;li&gt;Using the perf_event interface with Linux 3.14 or newer. This requires root or a paranoid less than 1 (as do all system wide measurements with -a) &lt;code&gt;sudo perf stat -a -e "power/energy-cores/" /bin/ls&lt;/code&gt; Available events can be found via &lt;code&gt;perf list&lt;/code&gt; or under&lt;code&gt;/sys/bus/event_source/devices/power/events/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Using raw-access to the underlying MSRs under &lt;code&gt;/dev/msr&lt;/code&gt;. This requires root.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Not that you cannot get readings for individual processes, the results are for the entire CPU socket. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# chih @ archlinux in ~/PMU/uarch-configure/rapl-read on git:master x [14:41:53] &lt;/span&gt;
$ ./rapl-read -s 

RAPL &lt;span class="nb"&gt;read&lt;/span&gt; -- use -s &lt;span class="k"&gt;for&lt;/span&gt; sysfs, -p &lt;span class="k"&gt;for&lt;/span&gt; perf_event, -m &lt;span class="k"&gt;for&lt;/span&gt; msr

Found Skylake Processor &lt;span class="nb"&gt;type&lt;/span&gt;
        &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;, &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;, &lt;span class="m"&gt;2&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;, &lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;, 
        Detected &lt;span class="m"&gt;4&lt;/span&gt; cores in &lt;span class="m"&gt;1&lt;/span&gt; packages


Trying sysfs powercap interface to gather results

        Sleeping &lt;span class="m"&gt;1&lt;/span&gt; second

        Package &lt;span class="m"&gt;0&lt;/span&gt;
                package-0       : &lt;span class="m"&gt;1&lt;/span&gt;.606746J
                core    : &lt;span class="m"&gt;0&lt;/span&gt;.327941J
                uncore  : &lt;span class="m"&gt;0&lt;/span&gt;.040039J
                dram    : &lt;span class="m"&gt;0&lt;/span&gt;.481933J
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# chih @ archlinux in ~/PMU/uarch-configure/rapl-read on git:master x [14:42:28] C:127&lt;/span&gt;
$ sudo ./rapl-read -p 

RAPL &lt;span class="nb"&gt;read&lt;/span&gt; -- use -s &lt;span class="k"&gt;for&lt;/span&gt; sysfs, -p &lt;span class="k"&gt;for&lt;/span&gt; perf_event, -m &lt;span class="k"&gt;for&lt;/span&gt; msr

Found Skylake Processor &lt;span class="nb"&gt;type&lt;/span&gt;
        &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;, &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;, &lt;span class="m"&gt;2&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;, &lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;, 
        Detected &lt;span class="m"&gt;4&lt;/span&gt; cores in &lt;span class="m"&gt;1&lt;/span&gt; packages


Trying perf_event interface to gather results

        &lt;span class="nv"&gt;Event&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;energy-cores &lt;span class="nv"&gt;Config&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="nv"&gt;scale&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;.32831e-10 &lt;span class="nv"&gt;units&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;Joules 
        &lt;span class="nv"&gt;Event&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;energy-gpu &lt;span class="nv"&gt;Config&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt; &lt;span class="nv"&gt;scale&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;.32831e-10 &lt;span class="nv"&gt;units&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;Joules 
        &lt;span class="nv"&gt;Event&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;energy-pkg &lt;span class="nv"&gt;Config&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt; &lt;span class="nv"&gt;scale&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;.32831e-10 &lt;span class="nv"&gt;units&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;Joules 
        &lt;span class="nv"&gt;Event&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;energy-ram &lt;span class="nv"&gt;Config&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="nv"&gt;scale&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;.32831e-10 &lt;span class="nv"&gt;units&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;Joules 
        &lt;span class="nv"&gt;Event&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;energy-psys &lt;span class="nv"&gt;Config&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;5&lt;/span&gt; &lt;span class="nv"&gt;scale&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;.32831e-10 &lt;span class="nv"&gt;units&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;Joules 

        Sleeping &lt;span class="m"&gt;1&lt;/span&gt; second

        Package &lt;span class="m"&gt;0&lt;/span&gt;:
                energy-cores Energy Consumed: &lt;span class="m"&gt;0&lt;/span&gt;.364807 Joules
                energy-gpu Energy Consumed: &lt;span class="m"&gt;0&lt;/span&gt;.079407 Joules
                energy-pkg Energy Consumed: &lt;span class="m"&gt;1&lt;/span&gt;.690308 Joules
                energy-ram Energy Consumed: &lt;span class="m"&gt;0&lt;/span&gt;.502747 Joules
                energy-psys Energy Consumed: &lt;span class="m"&gt;5&lt;/span&gt;.918152 Joules
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# chih @ archlinux in ~/PMU/uarch-configure/rapl-read on git:master x [14:43:02] &lt;/span&gt;
$ sudo ./rapl-read -m

RAPL &lt;span class="nb"&gt;read&lt;/span&gt; -- use -s &lt;span class="k"&gt;for&lt;/span&gt; sysfs, -p &lt;span class="k"&gt;for&lt;/span&gt; perf_event, -m &lt;span class="k"&gt;for&lt;/span&gt; msr

Found Skylake Processor &lt;span class="nb"&gt;type&lt;/span&gt;
        &lt;span class="m"&gt;0&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;, &lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;, &lt;span class="m"&gt;2&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;, &lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;, 
        Detected &lt;span class="m"&gt;4&lt;/span&gt; cores in &lt;span class="m"&gt;1&lt;/span&gt; packages


Trying /dev/msr interface to gather results

        Listing paramaters &lt;span class="k"&gt;for&lt;/span&gt; package &lt;span class="c1"&gt;#0&lt;/span&gt;
                Power &lt;span class="nv"&gt;units&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;.125W
                CPU Energy &lt;span class="nv"&gt;units&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;.00006104J
                DRAM Energy &lt;span class="nv"&gt;units&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;.00006104J
                Time &lt;span class="nv"&gt;units&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;.00097656s

                Package thermal spec: &lt;span class="m"&gt;15&lt;/span&gt;.000W
                Package minimum power: &lt;span class="m"&gt;0&lt;/span&gt;.000W
                Package maximum power: &lt;span class="m"&gt;0&lt;/span&gt;.000W
                Package maximum &lt;span class="nb"&gt;time&lt;/span&gt; window: &lt;span class="m"&gt;0&lt;/span&gt;.000000s
                Package power limits are unlocked
                Package power limit &lt;span class="c1"&gt;#1: 25.000W for 0.107422s (enabled, clamped)&lt;/span&gt;
                Package power limit &lt;span class="c1"&gt;#2: 25.000W for 0.032227s (enabled, not_clamped)&lt;/span&gt;


        Sleeping &lt;span class="m"&gt;1&lt;/span&gt; second

        Package &lt;span class="m"&gt;0&lt;/span&gt;:
                Package energy: &lt;span class="m"&gt;1&lt;/span&gt;.657654J
                PowerPlane0 &lt;span class="o"&gt;(&lt;/span&gt;cores&lt;span class="o"&gt;)&lt;/span&gt;: &lt;span class="m"&gt;0&lt;/span&gt;.353638J

Note: the energy measurements can overflow in 60s or so
      so try to sample the counters more often than that.
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;rapl_basic&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# chih @ archlinux in ~/PMU/papi-5.5.1/src [21:38:11] &lt;/span&gt;
$ ./configure --with-components&lt;span class="o"&gt;=&lt;/span&gt;rapl &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; make &lt;span class="c1"&gt;# compile papi&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# chih @ archlinux in ~/PMU/papi-5.5.1/src/components/rapl/tests [21:39:09] &lt;/span&gt;
$ sudo ./rapl_basic
Trying all RAPL events
Found rapl component at cid &lt;span class="m"&gt;2&lt;/span&gt;

Starting measurements...

Sleeping &lt;span class="m"&gt;1&lt;/span&gt; second...

Stopping measurements, took &lt;span class="m"&gt;1&lt;/span&gt;.000s, gathering results...

Scaled energy measurements:
rapl:::PACKAGE_ENERGY:PACKAGE0              &lt;span class="m"&gt;1&lt;/span&gt;.150513 J  &lt;span class="o"&gt;(&lt;/span&gt;Average Power &lt;span class="m"&gt;1&lt;/span&gt;.2W&lt;span class="o"&gt;)&lt;/span&gt;
rapl:::DRAM_ENERGY:PACKAGE0                 &lt;span class="m"&gt;0&lt;/span&gt;.640137 J  &lt;span class="o"&gt;(&lt;/span&gt;Average Power &lt;span class="m"&gt;0&lt;/span&gt;.6W&lt;span class="o"&gt;)&lt;/span&gt;
rapl:::PP0_ENERGY:PACKAGE0                  &lt;span class="m"&gt;0&lt;/span&gt;.379883 J  &lt;span class="o"&gt;(&lt;/span&gt;Average Power &lt;span class="m"&gt;0&lt;/span&gt;.4W&lt;span class="o"&gt;)&lt;/span&gt;

Energy measurement counts:
rapl:::PACKAGE_ENERGY_CNT:PACKAGE0             &lt;span class="m"&gt;18850&lt;/span&gt;    0x0049a2
rapl:::DRAM_ENERGY_CNT:PACKAGE0                &lt;span class="m"&gt;10488&lt;/span&gt;    0x0028f8
rapl:::PP0_ENERGY_CNT:PACKAGE0                  &lt;span class="m"&gt;6223&lt;/span&gt;    0x00184f

Scaled Fixed values:
rapl:::THERMAL_SPEC:PACKAGE0                  &lt;span class="m"&gt;15&lt;/span&gt;.000 W
rapl:::MINIMUM_POWER:PACKAGE0                  &lt;span class="m"&gt;0&lt;/span&gt;.000 W
rapl:::MAXIMUM_POWER:PACKAGE0                  &lt;span class="m"&gt;0&lt;/span&gt;.000 W
rapl:::MAXIMUM_TIME_WINDOW:PACKAGE0            &lt;span class="m"&gt;0&lt;/span&gt;.000 s

Fixed value counts:
rapl:::THERMAL_SPEC_CNT:PACKAGE0                 &lt;span class="m"&gt;120&lt;/span&gt;    0x000078
rapl:::MINIMUM_POWER_CNT:PACKAGE0                  &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;00000000&lt;/span&gt;
rapl:::MAXIMUM_POWER_CNT:PACKAGE0                  &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;00000000&lt;/span&gt;
rapl:::MAXIMUM_TIME_WINDOW_CNT:PACKAGE0            &lt;span class="m"&gt;0&lt;/span&gt;    &lt;span class="m"&gt;00000000&lt;/span&gt;
rapl_basic.c                           PASSED
&lt;/pre&gt;&lt;/div&gt;</content><category term="linux"></category><category term="intel"></category><category term="CPU"></category><category term="power"></category><category term="kernel"></category><category term="rapl"></category></entry><entry><title>Ubuntu 16.04 下 CPU 频率与功耗关系</title><link href="https://blog.chih.me/power-with-different-cpufreq.html" rel="alternate"></link><published>2016-12-25T00:00:00+08:00</published><updated>2016-12-25T00:00:00+08:00</updated><author><name>chih</name></author><id>tag:blog.chih.me,2016-12-25:/power-with-different-cpufreq.html</id><summary type="html">&lt;h3&gt;硬件环境&lt;/h3&gt;
&lt;p&gt;实验服务器搭载两颗 Intel E5645 处理器，24块 SAS+SATA 机械硬盘。E5645 为 6 核处理器，并支持超线程技术（Intel® Hyper-Threading Technology），服务器共 24 个逻辑核，基本时钟频率为 2.40 GHz 。&lt;/p&gt;
&lt;h3&gt;软件环境&lt;/h3&gt;
&lt;p&gt;Ubuntu Server 16.04.1 LTS&lt;/p&gt;
&lt;h2&gt;CPU 频率驱动程序与工具&lt;/h2&gt;
&lt;p&gt;操作系统通过CPU调频可以根据负载动态调节CPU工作频率，达到省电的目的。这个过程可以自动进行，也可以由用户空间(userspace)程序手动调节。Linux 内核实现了CPU 调频，该驱动被称为 CPUfreq， 从 3.4 内核开始，内核会自动载入相应的内核模块，默认的频率调频器 …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;硬件环境&lt;/h3&gt;
&lt;p&gt;实验服务器搭载两颗 Intel E5645 处理器，24块 SAS+SATA 机械硬盘。E5645 为 6 核处理器，并支持超线程技术（Intel® Hyper-Threading Technology），服务器共 24 个逻辑核，基本时钟频率为 2.40 GHz 。&lt;/p&gt;
&lt;h3&gt;软件环境&lt;/h3&gt;
&lt;p&gt;Ubuntu Server 16.04.1 LTS&lt;/p&gt;
&lt;h2&gt;CPU 频率驱动程序与工具&lt;/h2&gt;
&lt;p&gt;操作系统通过CPU调频可以根据负载动态调节CPU工作频率，达到省电的目的。这个过程可以自动进行，也可以由用户空间(userspace)程序手动调节。Linux 内核实现了CPU 调频，该驱动被称为 CPUfreq， 从 3.4 内核开始，内核会自动载入相应的内核模块，默认的频率调频器 &lt;strong&gt;ondemand&lt;/strong&gt; 会被启动（ Intel  Sandy Bridge 架构后 CPU 的功率驱动程序为 P-State，默认调频器为 powersave ）。用户调频工具有 cpufrequtils、  cpupower 等，这里使用 cpufrequtils 。&lt;/p&gt;
&lt;p&gt;安装 &lt;code&gt;cpufrequtils&lt;/code&gt; 包。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# apt install cpufrequtils&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;cpufrequtils 包包含以下三个工具，其中 &lt;strong&gt;cpufreq-info&lt;/strong&gt; 用于查看cpu的相关信息，&lt;strong&gt;cpufreq-set&lt;/strong&gt; 用于修改CPU的频率配置，&lt;strong&gt;cpufreq-aperf&lt;/strong&gt; 用于计算一段时间内的平均频率。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/usr/bin/cpufreq-info
/usr/bin/cpufreq-set
/usr/bin/cpufreq-aperf
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;cpufreq-info&lt;/strong&gt; 获得的信息包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;dirver&lt;/code&gt;: 实用的cpufreq内核驱动&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hardware limits&lt;/code&gt;: 设定的cpu频率范围&lt;/li&gt;
&lt;li&gt;&lt;code&gt;available frequency steps&lt;/code&gt;: 可选的cpu频率&lt;/li&gt;
&lt;li&gt;&lt;code&gt;available cpufreq governors&lt;/code&gt;: 可选的cpu频率调速器:&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;调速器&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;ondemand&lt;/td&gt;
&lt;td&gt;按需快速动态调整CPU频率， 一有cpu计算量的任务，就会立即达到最大频率运行，等执行完毕就立即回到最低频率（阙值为 95%）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;performance&lt;/td&gt;
&lt;td&gt;运行于最大频率&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conservative&lt;/td&gt;
&lt;td&gt;按需快速动态调整CPU频率， 一有cpu计算量的任务，就会立即达到最大频率运行，等执行完毕就立即回到最低频率（阙值为 75%）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;powersave&lt;/td&gt;
&lt;td&gt;运行于最小频率&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;userspace&lt;/td&gt;
&lt;td&gt;运行于用户指定的频率&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;current CPU frequency&lt;/code&gt;: 当前的CPU频率&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cpufreq stats&lt;/code&gt;: 统计cpu在每个频率下的工作时间&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这些信息也可以手动在sysfs文件中查看，位置为 &lt;code&gt;/sys/devices/system/cpu/cpuX/cpufreq/&lt;/code&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;chih@archlinux:/sys/devices/system/cpu/cpu0/cpufreq$ ls  
affected_cpus               related_cpus                   scaling_max_freq  
bios_limit                  scaling_available_frequencies  scaling_min_freq  
cpuinfo_cur_freq            scaling_available_governors    scaling_setspeed  
cpuinfo_max_freq            scaling_cur_freq               stats  
cpuinfo_min_freq            scaling_driver  
cpuinfo_transition_latency  scaling_governor 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;以上为CPU0的一些内核文件，前缀 cpuinfo 代表的是 cpu 硬件上支持的频率，而 scaling 前缀代表的是可以通过 CPUFreq 系统用软件进行调节时所支持的频率。cpuinfo_cur_freq 代表通过硬件实际上读到的频率值，而 scaling_cur_freq 则是软件当前的设置值，scaling_available_frequencies 表示当前软件支持的频率值，scaling_available_governors 表示当前软件支持的调频器，scaling_governor 表示当前使用的调频器，scaling_min_freq 与 scaling_max_freq 表示软件设置的最低频率与最高频率。scaling_set_speed 表示手动设置的特定频率。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;cpufreq-set&lt;/strong&gt; 允许用户手动设置CPU运行频率，相应的选项如下所示：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;-c --cpu&lt;/strong&gt; &lt;CPU&gt;
  number of CPU where cpufreq settings shall be modified.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;-d --min&lt;/strong&gt; &lt;FREQ&gt;
  new minimum CPU frequency the governor may select.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;-u --max&lt;/strong&gt; &lt;FREQ&gt;
  new maximum CPU frequency the governor may select.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;-g --governor&lt;/strong&gt; &lt;GOV&gt;
  new cpufreq governor.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;-f --freq&lt;/strong&gt; &lt;FREQ&gt;
  specific frequency to be set. Requires userspace governor to be available and loaded.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;-r --related&lt;/strong&gt;
  modify all hardware-related CPUs at the same time&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;-h --help&lt;/strong&gt;
  Prints out the help screen.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因为服务器上核数比较多，可通过以下名为&lt;code&gt;cpufreq-set-all&lt;/code&gt;的shell脚本方便的设置全部CPU核。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="ch"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; i in &lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;..23&lt;span class="o"&gt;}&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
    cpufreq-set -c &lt;span class="nv"&gt;$i&lt;/span&gt; &lt;span class="nv"&gt;$@&lt;/span&gt; 
&lt;span class="k"&gt;done&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;-f&lt;/strong&gt; 选项要求使用 &lt;code&gt;userspace&lt;/code&gt; 调频器，使用下面的命令把所有CPU核的调频器都设置为 userspace 。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# cpufreq-set-all -g userspace&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;手动设定CPU的运行频率，注意，频率值必须是 &lt;code&gt;scaling_available_frequencies&lt;/code&gt;中列出的。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# cpufreq-set-all -f 2.0Ghz&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;负载&lt;/h3&gt;
&lt;p&gt;由于服务器无图形界面，使用了stress作为负载，stress 可以进行综合（内存占用、磁盘 IO）压力测试，可以反映典型用途下的服务器负载情况。&lt;/p&gt;
&lt;p&gt;安装 stress&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# aptitude install stress&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;产生24个cpu进程，对应服务器的总核数，可以确保100%跑满服务器CPU全部负载。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# stress -c 24&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;结果&lt;/h2&gt;
&lt;p&gt;如视频 1600Mhz.mp4、2000Mhz.mp4、2400Mhz.mp4 所示，实验选取了 1.6Ghz、2.0Ghz、2.4Ghz 三组CPU工作频率，对应的服务器整机功率如下表所示：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="center"&gt;CPU频率&lt;/th&gt;
&lt;th align="center"&gt;CPU满载整机功率&lt;/th&gt;
&lt;th align="center"&gt;CPU空载整机功率&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="center"&gt;1.6Ghz&lt;/td&gt;
&lt;td align="center"&gt;575W&lt;/td&gt;
&lt;td align="center"&gt;507W&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;2.0Ghz&lt;/td&gt;
&lt;td align="center"&gt;612W&lt;/td&gt;
&lt;td align="center"&gt;519W&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center"&gt;2.4Ghz&lt;/td&gt;
&lt;td align="center"&gt;652W&lt;/td&gt;
&lt;td align="center"&gt;507W&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;这里的功耗是整机功耗，受磁盘、主板等的功耗影响，其实可以通过 &lt;code&gt;RAPL&lt;/code&gt; 单独读取 CPU 的功耗。&lt;/p&gt;</content><category term="linux"></category><category term="cpufreq"></category><category term="CPU"></category><category term="power"></category></entry><entry><title>使用redsocks把shadowsocks转为全局代理</title><link href="https://blog.chih.me/global-proxy-within-redsocks-and-shadowsocks.html" rel="alternate"></link><published>2016-11-21T00:00:00+08:00</published><updated>2016-11-21T00:00:00+08:00</updated><author><name>chih</name></author><id>tag:blog.chih.me,2016-11-21:/global-proxy-within-redsocks-and-shadowsocks.html</id><summary type="html">&lt;h2&gt;前言&lt;/h2&gt;
&lt;p&gt;shadowsocks是个非常棒的翻墙代理，它可以在本地提供一个socks5端口供软件使用代理。比如启动chrome的时候加上&lt;code&gt;--proxy-server="socks5://myproxy:1080"&lt;/code&gt;这条参数就可以让chrome走代理；然而，有些软件不支持设置代理的功能。所以有时候，我们需要一个全局代理的环境，使用VPN是一个通常的选择，不过一般购买的VPN的速度不如shadowsocks，同时，VPN更容易受到GFW的干扰。为什么不把正在使用的shadowsocks利用起来作为一个全局代理呢？&lt;/p&gt;
&lt;p&gt;本文介绍了一种利用&lt;a href="https://github.com/darkk/redsocks"&gt;redsocks&lt;/a&gt;与iptables实现全局代理的方法，其基本原理如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;iptables的规则将所有tcp包转发到redsocks打开的本地端口&lt;/li&gt;
&lt;li&gt;redsocks接收tcp包并转发给shadowsocks打开的本地socks端口&lt;/li&gt;
&lt;li&gt;shadowsocks将接收的包转发给远端的代理服务器&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;由于使用了redsocks与iptables，因此本文的方法仅适用于Linux。&lt;/p&gt;
&lt;h2&gt;安装&lt;/h2&gt;
&lt;p&gt;由于使用的是Arch Linux，我直接通过AUR安装&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ yaourt redsocks
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;通过&lt;code&gt;yaourt&lt;/code&gt;搜索redsocks包，然后选择你要安装的包的序号就可以进行安装了。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;注意：下文中的配置文件的路径全部基于Arch Linux，如果你用的不是Arch Linux，请根据自己的情况更改。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;其他发行版可以通过各自的包管理器或者下载源码&lt;a href="https://github.com/darkk/redsocks/blob/master/README"&gt;安装&lt;/a&gt;。&lt;/p&gt;
&lt;h2&gt;配置&lt;/h2&gt;
&lt;h3&gt;配置redsocks&lt;/h3&gt;
&lt;p&gt;我在包提供的原有配置的基础上进行了一些修改，主要是把 &lt;code&gt;redsocks …&lt;/code&gt;&lt;/p&gt;</summary><content type="html">&lt;h2&gt;前言&lt;/h2&gt;
&lt;p&gt;shadowsocks是个非常棒的翻墙代理，它可以在本地提供一个socks5端口供软件使用代理。比如启动chrome的时候加上&lt;code&gt;--proxy-server="socks5://myproxy:1080"&lt;/code&gt;这条参数就可以让chrome走代理；然而，有些软件不支持设置代理的功能。所以有时候，我们需要一个全局代理的环境，使用VPN是一个通常的选择，不过一般购买的VPN的速度不如shadowsocks，同时，VPN更容易受到GFW的干扰。为什么不把正在使用的shadowsocks利用起来作为一个全局代理呢？&lt;/p&gt;
&lt;p&gt;本文介绍了一种利用&lt;a href="https://github.com/darkk/redsocks"&gt;redsocks&lt;/a&gt;与iptables实现全局代理的方法，其基本原理如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;iptables的规则将所有tcp包转发到redsocks打开的本地端口&lt;/li&gt;
&lt;li&gt;redsocks接收tcp包并转发给shadowsocks打开的本地socks端口&lt;/li&gt;
&lt;li&gt;shadowsocks将接收的包转发给远端的代理服务器&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;由于使用了redsocks与iptables，因此本文的方法仅适用于Linux。&lt;/p&gt;
&lt;h2&gt;安装&lt;/h2&gt;
&lt;p&gt;由于使用的是Arch Linux，我直接通过AUR安装&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ yaourt redsocks
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;通过&lt;code&gt;yaourt&lt;/code&gt;搜索redsocks包，然后选择你要安装的包的序号就可以进行安装了。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;注意：下文中的配置文件的路径全部基于Arch Linux，如果你用的不是Arch Linux，请根据自己的情况更改。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;其他发行版可以通过各自的包管理器或者下载源码&lt;a href="https://github.com/darkk/redsocks/blob/master/README"&gt;安装&lt;/a&gt;。&lt;/p&gt;
&lt;h2&gt;配置&lt;/h2&gt;
&lt;h3&gt;配置redsocks&lt;/h3&gt;
&lt;p&gt;我在包提供的原有配置的基础上进行了一些修改，主要是把 &lt;code&gt;redsocks -&amp;gt; port&lt;/code&gt; 修改为shadowsocks的本地端口(1080)，另外，由于只需要转发tcp流量，我把 &lt;code&gt;redudp&lt;/code&gt; 和 &lt;code&gt;dnstc&lt;/code&gt; 段的配置全部注释了。注意 &lt;code&gt;redsocks -&amp;gt; local_port&lt;/code&gt; 配置的端口是用来接收iptables传来的流量用的，设置为一个不会和别的程序冲突的端口，但要保证和iptables规则里的端口对应。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ vim /etc/redsocks.conf
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;base &lt;span class="o"&gt;{&lt;/span&gt;
    // debug: connection progress &lt;span class="p"&gt;&amp;amp;&lt;/span&gt; client list on SIGUSR1
    &lt;span class="nv"&gt;log_debug&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; off&lt;span class="p"&gt;;&lt;/span&gt;

    // info: start and end of client session
    &lt;span class="nv"&gt;log_info&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; off&lt;span class="p"&gt;;&lt;/span&gt;

    /* possible &lt;span class="sb"&gt;`&lt;/span&gt;log&lt;span class="s1"&gt;&amp;#39; values are:&lt;/span&gt;
&lt;span class="s1"&gt;     *   stderr&lt;/span&gt;
&lt;span class="s1"&gt;     *   &amp;quot;file:/path/to/file&amp;quot;&lt;/span&gt;
&lt;span class="s1"&gt;     *   syslog:FACILITY  facility is any of &amp;quot;daemon&amp;quot;, &amp;quot;local0&amp;quot;...&amp;quot;local7&amp;quot;&lt;/span&gt;
&lt;span class="s1"&gt;     */&lt;/span&gt;
&lt;span class="s1"&gt;    // log = stderr;&lt;/span&gt;
&lt;span class="s1"&gt;    // log = &amp;quot;file:/path/to/file&amp;quot;;&lt;/span&gt;
&lt;span class="s1"&gt;    log = &amp;quot;syslog:daemon&amp;quot;;&lt;/span&gt;

&lt;span class="s1"&gt;    // detach from console&lt;/span&gt;
&lt;span class="s1"&gt;    daemon = on;&lt;/span&gt;

&lt;span class="s1"&gt;    /* Change uid, gid and root directory, these options require root&lt;/span&gt;
&lt;span class="s1"&gt;     * privilegies on startup.&lt;/span&gt;
&lt;span class="s1"&gt;     * Note, your chroot may requre /etc/localtime if you write log to syslog.&lt;/span&gt;
&lt;span class="s1"&gt;     * Log is opened before chroot &amp;amp; uid changing.&lt;/span&gt;
&lt;span class="s1"&gt;     */&lt;/span&gt;
&lt;span class="s1"&gt;    user = redsocks;&lt;/span&gt;
&lt;span class="s1"&gt;    group = redsocks;&lt;/span&gt;
&lt;span class="s1"&gt;    // chroot = &amp;quot;/var/chroot&amp;quot;;&lt;/span&gt;

&lt;span class="s1"&gt;    /* possible `redirector&amp;#39;&lt;/span&gt; values are:
     *   iptables   - &lt;span class="k"&gt;for&lt;/span&gt; Linux
     *   ipf        - &lt;span class="k"&gt;for&lt;/span&gt; FreeBSD
     *   pf         - &lt;span class="k"&gt;for&lt;/span&gt; OpenBSD
     *   generic    - some generic redirector that MAY work
     */
    &lt;span class="nv"&gt;redirector&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; iptables&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="o"&gt;}&lt;/span&gt;

redsocks &lt;span class="o"&gt;{&lt;/span&gt;
    /* &lt;span class="sb"&gt;`&lt;/span&gt;local_ip&lt;span class="s1"&gt;&amp;#39; defaults to 127.0.0.1 for security reasons,&lt;/span&gt;
&lt;span class="s1"&gt;     * use 0.0.0.0 if you want to listen on every interface.&lt;/span&gt;
&lt;span class="s1"&gt;     * `local_*&amp;#39;&lt;/span&gt; are used as port to redirect to.
     */
    &lt;span class="nv"&gt;local_ip&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;127&lt;/span&gt;.0.0.1&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="nv"&gt;local_port&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;31338&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

    // listen&lt;span class="o"&gt;()&lt;/span&gt; queue length. Default value is SOMAXCONN and it should be
    // good enough &lt;span class="k"&gt;for&lt;/span&gt; most of us.
    // &lt;span class="nv"&gt;listenq&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;128&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; // SOMAXCONN equals &lt;span class="m"&gt;128&lt;/span&gt; on my Linux box.

    // &lt;span class="sb"&gt;`&lt;/span&gt;max_accept_backoff&lt;span class="sb"&gt;`&lt;/span&gt; is a delay to retry &lt;span class="sb"&gt;`&lt;/span&gt;accept&lt;span class="o"&gt;()&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt; after accept
    // failure &lt;span class="o"&gt;(&lt;/span&gt;e.g. due to lack of file descriptors&lt;span class="o"&gt;)&lt;/span&gt;. It&lt;span class="s1"&gt;&amp;#39;s measured in&lt;/span&gt;
&lt;span class="s1"&gt;    // milliseconds and maximal value is 65535. `min_accept_backoff` is&lt;/span&gt;
&lt;span class="s1"&gt;    // used as initial backoff value and as a damper for `accept() after&lt;/span&gt;
&lt;span class="s1"&gt;    // close()` logic.&lt;/span&gt;
&lt;span class="s1"&gt;    // min_accept_backoff = 100;&lt;/span&gt;
&lt;span class="s1"&gt;    // max_accept_backoff = 60000;&lt;/span&gt;

&lt;span class="s1"&gt;    // `ip&amp;#39;&lt;/span&gt; and &lt;span class="sb"&gt;`&lt;/span&gt;port&lt;span class="s1"&gt;&amp;#39; are IP and tcp-port of proxy-server&lt;/span&gt;
&lt;span class="s1"&gt;    // You can also use hostname instead of IP, only one (random)&lt;/span&gt;
&lt;span class="s1"&gt;    // address of multihomed host will be used.&lt;/span&gt;
&lt;span class="s1"&gt;    ip = 127.0.0.1;&lt;/span&gt;
&lt;span class="s1"&gt;    // 修改为shadosocks的本地端口&lt;/span&gt;
&lt;span class="s1"&gt;    port = 1080;&lt;/span&gt;


&lt;span class="s1"&gt;    // known types: socks4, socks5, http-connect, http-relay&lt;/span&gt;
&lt;span class="s1"&gt;    type = socks5;&lt;/span&gt;

&lt;span class="s1"&gt;    // login = &amp;quot;foobar&amp;quot;;&lt;/span&gt;
&lt;span class="s1"&gt;    // password = &amp;quot;baz&amp;quot;;&lt;/span&gt;
&lt;span class="s1"&gt;}&lt;/span&gt;

&lt;span class="s1"&gt;//redudp {&lt;/span&gt;
&lt;span class="s1"&gt;    // `local_ip&amp;#39;&lt;/span&gt; should not be &lt;span class="m"&gt;0&lt;/span&gt;.0.0.0 as it&lt;span class="s1"&gt;&amp;#39;s also used for outgoing&lt;/span&gt;
&lt;span class="s1"&gt;    // packets that are sent as replies - and it should be fixed&lt;/span&gt;
&lt;span class="s1"&gt;    // if we want NAT to work properly.&lt;/span&gt;
&lt;span class="s1"&gt;    //local_ip = 127.0.0.1;&lt;/span&gt;
&lt;span class="s1"&gt;    //local_port = 10053;&lt;/span&gt;

&lt;span class="s1"&gt;    // `ip&amp;#39;&lt;/span&gt; and &lt;span class="sb"&gt;`&lt;/span&gt;port&lt;span class="s1"&gt;&amp;#39; of socks5 proxy server.&lt;/span&gt;
&lt;span class="s1"&gt;    //ip = 127.0.0.1;&lt;/span&gt;
&lt;span class="s1"&gt;    //port = 1080;&lt;/span&gt;

&lt;span class="s1"&gt;    // login = username;&lt;/span&gt;
&lt;span class="s1"&gt;    // password = pazzw0rd;&lt;/span&gt;

&lt;span class="s1"&gt;    // kernel does not give us this information, so we have to duplicate it&lt;/span&gt;
&lt;span class="s1"&gt;    // in both iptables rules and configuration file.  By the way, you can&lt;/span&gt;
&lt;span class="s1"&gt;    // set `local_ip&amp;#39;&lt;/span&gt; to &lt;span class="m"&gt;127&lt;/span&gt;.45.67.89 &lt;span class="k"&gt;if&lt;/span&gt; you need more than &lt;span class="m"&gt;65535&lt;/span&gt; ports to
    // forward &lt;span class="p"&gt;;&lt;/span&gt;-&lt;span class="o"&gt;)&lt;/span&gt;
    // This limitation may be relaxed in future versions using contrack-tools.
    //dest_ip &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;8&lt;/span&gt;.8.8.8&lt;span class="p"&gt;;&lt;/span&gt;
    //dest_port &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;53&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

    //udp_timeout &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;30&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    //udp_timeout_stream &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;180&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
//&lt;span class="o"&gt;}&lt;/span&gt;

//dnstc &lt;span class="o"&gt;{&lt;/span&gt;
    // fake and really dumb DNS server that returns &lt;span class="s2"&gt;&amp;quot;truncated answer&amp;quot;&lt;/span&gt; to
    // every query via UDP, RFC-compliant resolver should repeat same query
    // via TCP in this &lt;span class="k"&gt;case&lt;/span&gt;.
//  &lt;span class="nv"&gt;local_ip&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;127&lt;/span&gt;.0.0.1&lt;span class="p"&gt;;&lt;/span&gt;
//  &lt;span class="nv"&gt;local_port&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="m"&gt;5300&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
//&lt;span class="o"&gt;}&lt;/span&gt;

// you can add more &lt;span class="sb"&gt;`&lt;/span&gt;redsocks&lt;span class="s1"&gt;&amp;#39; and `redudp&amp;#39;&lt;/span&gt; sections &lt;span class="k"&gt;if&lt;/span&gt; you need.
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;iptables规则&lt;/h3&gt;
&lt;p&gt;也是在包提供的原有配置的基础上进行了一些修改，唯一的修改只是增加了这一条&lt;/p&gt;
&lt;p&gt;&lt;code&gt;-A REDSOCKS -d proxy_server_ip -j RETURN&lt;/code&gt;，使代理自己不要再被重定向，不然就无限循环了。。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ vim /etc/iptables/redsocks.rules
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# Transparent SOCKS proxy&lt;/span&gt;
&lt;span class="c1"&gt;# See: http://darkk.net.ru/redsocks/&lt;/span&gt;

*nat
:PREROUTING ACCEPT &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;:0&lt;span class="o"&gt;]&lt;/span&gt;
:INPUT ACCEPT &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;:0&lt;span class="o"&gt;]&lt;/span&gt;
:OUTPUT ACCEPT &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;:0&lt;span class="o"&gt;]&lt;/span&gt;
:POSTROUTING ACCEPT &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;:0&lt;span class="o"&gt;]&lt;/span&gt;
:REDSOCKS - &lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;:0&lt;span class="o"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# Redirect all output through redsocks&lt;/span&gt;
-A OUTPUT -p tcp -j REDSOCKS

&lt;span class="c1"&gt;# Whitelist LANs and some other reserved addresses.&lt;/span&gt;
&lt;span class="c1"&gt;# https://en.wikipedia.org/wiki/Reserved_IP_addresses#Reserved_IPv4_addresses&lt;/span&gt;
-A REDSOCKS -d &lt;span class="m"&gt;0&lt;/span&gt;.0.0.0/8 -j RETURN
-A REDSOCKS -d &lt;span class="m"&gt;10&lt;/span&gt;.0.0.0/8 -j RETURN
-A REDSOCKS -d &lt;span class="m"&gt;127&lt;/span&gt;.0.0.0/8 -j RETURN
-A REDSOCKS -d &lt;span class="m"&gt;169&lt;/span&gt;.254.0.0/16 -j RETURN
-A REDSOCKS -d &lt;span class="m"&gt;172&lt;/span&gt;.16.0.0/12 -j RETURN
-A REDSOCKS -d &lt;span class="m"&gt;192&lt;/span&gt;.168.0.0/16 -j RETURN
-A REDSOCKS -d &lt;span class="m"&gt;224&lt;/span&gt;.0.0.0/4 -j RETURN
-A REDSOCKS -d &lt;span class="m"&gt;240&lt;/span&gt;.0.0.0/4 -j RETURN
&lt;span class="c1"&gt;# import shadowsocks server ip&lt;/span&gt;
&lt;span class="c1"&gt;#-A REDSOCKS -d xxx.xxx.xxx.xxx -j RETURN&lt;/span&gt;
&lt;span class="c1"&gt;# shadowsocks server port&lt;/span&gt;
-A REDSOCKS -p tcp --dport xxxxx -j RETURN

&lt;span class="c1"&gt;# Redirect everything else to redsocks port&lt;/span&gt;
-A REDSOCKS -p tcp -j REDIRECT --to-ports &lt;span class="m"&gt;31338&lt;/span&gt;

COMMIT
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;运行&lt;/h2&gt;
&lt;p&gt;开启redsocks和iptables服务，并让它们开机自启:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo systemctl start  redsocks.service iptables.service
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo systemctl &lt;span class="nb"&gt;enable&lt;/span&gt;  redsocks.service iptables.service
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;当你需要进入全局代理时，简单地导入&lt;code&gt;redsocks.rules&lt;/code&gt;就行:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo iptables-restore &amp;lt; /etc/iptables/redsocks.rules
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;当你需要退出全局代理环境，只需要清空iptables规则，redsocks可以让他一直运行:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo /usr/lib/systemd/scripts/iptables-flush
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;一些人可能是自己编译源码进行安装的，这些Arch Linux软件包内的&lt;a href="https://aur.archlinux.org/cgit/aur.git/tree/?h=redsocks-git"&gt;默认配置和运行脚本&lt;/a&gt;可能对你有所帮助。&lt;/p&gt;
&lt;h2&gt;高级配置&lt;/h2&gt;
&lt;p&gt;由于我只在极少数特殊情况下才会用到全局代理，所以DNS防污染，国内ip白名单等都没有弄，有需要的可以研究下以下几个技术：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;dnsmasq&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;pdnsd&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;chnroutes&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ChinaDNS&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pcap_DNSProxy&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</content><category term="Arch Linux"></category><category term="Linux"></category><category term="redsocks"></category><category term="iptables"></category><category term="shadowsocks"></category><category term="代理"></category></entry><entry><title>Hadoop 安装笔记</title><link href="https://blog.chih.me/hadoop-install.html" rel="alternate"></link><published>2016-11-17T00:00:00+08:00</published><updated>2016-11-17T00:00:00+08:00</updated><author><name>chih</name></author><id>tag:blog.chih.me,2016-11-17:/hadoop-install.html</id><summary type="html">&lt;h2&gt;The building blocks of Hadoop&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;NameNode&lt;/li&gt;
&lt;li&gt;DataNode&lt;/li&gt;
&lt;li&gt;Secondary NameNode&lt;/li&gt;
&lt;li&gt;~~JobTracker~~&lt;/li&gt;
&lt;li&gt;~~TaskTracker~~&lt;/li&gt;
&lt;li&gt;ResourceManager&lt;/li&gt;
&lt;li&gt;NodeManager&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="Screenshot_20161117_185744" src="images/Screenshot_20161117_185744.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot_20161117_190357" src="images/Screenshot_20161117_190357.png"&gt;&lt;/p&gt;
&lt;h3&gt;NameNode&lt;/h3&gt;
&lt;p&gt;NameNode主要是用来保存HDFS的&lt;strong&gt;元数据&lt;/strong&gt;信息，比如命名空间信息，块信息等。当它运行的时候，这些信息是存在内存中的。但是这些信息也可以持久化到磁盘上。没有Namenode，HDFS就不能工作。事实上，如果运行namenode的机器坏掉的话，系统中的文件将会完全丢失，因为没有其他方法能够将位于不同datanode上的文件块(blocks)重建文件。因此，Hadoop存在单点故障。为了解决单点故障，Hadoop提供了两套机制：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;第一种方式是将持久化存 储在本地硬盘的文件系统元数据备份。Hadoop可以通过配置来让Namenode将他的持久化状态文件写到不同的文件系统中。一般是镜像到网络文件系统或单独的磁盘中。&lt;/li&gt;
&lt;li&gt;第二种方式是运行一个辅助的Namenode(Secondary Namenode)。下面会具体说明。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;DataNode&lt;/h3&gt;
&lt;p&gt;Datanode是文件系统的工作节点，他们根据客户端或者是namenode的调度存储和检索数据，并且定期向namenode发送他们所存储的块(block)的&lt;strong&gt;列表&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;集群中的每个服务器都运 …&lt;/p&gt;</summary><content type="html">&lt;h2&gt;The building blocks of Hadoop&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;NameNode&lt;/li&gt;
&lt;li&gt;DataNode&lt;/li&gt;
&lt;li&gt;Secondary NameNode&lt;/li&gt;
&lt;li&gt;~~JobTracker~~&lt;/li&gt;
&lt;li&gt;~~TaskTracker~~&lt;/li&gt;
&lt;li&gt;ResourceManager&lt;/li&gt;
&lt;li&gt;NodeManager&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="Screenshot_20161117_185744" src="images/Screenshot_20161117_185744.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot_20161117_190357" src="images/Screenshot_20161117_190357.png"&gt;&lt;/p&gt;
&lt;h3&gt;NameNode&lt;/h3&gt;
&lt;p&gt;NameNode主要是用来保存HDFS的&lt;strong&gt;元数据&lt;/strong&gt;信息，比如命名空间信息，块信息等。当它运行的时候，这些信息是存在内存中的。但是这些信息也可以持久化到磁盘上。没有Namenode，HDFS就不能工作。事实上，如果运行namenode的机器坏掉的话，系统中的文件将会完全丢失，因为没有其他方法能够将位于不同datanode上的文件块(blocks)重建文件。因此，Hadoop存在单点故障。为了解决单点故障，Hadoop提供了两套机制：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;第一种方式是将持久化存 储在本地硬盘的文件系统元数据备份。Hadoop可以通过配置来让Namenode将他的持久化状态文件写到不同的文件系统中。一般是镜像到网络文件系统或单独的磁盘中。&lt;/li&gt;
&lt;li&gt;第二种方式是运行一个辅助的Namenode(Secondary Namenode)。下面会具体说明。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;DataNode&lt;/h3&gt;
&lt;p&gt;Datanode是文件系统的工作节点，他们根据客户端或者是namenode的调度存储和检索数据，并且定期向namenode发送他们所存储的块(block)的&lt;strong&gt;列表&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;集群中的每个服务器都运 行一个DataNode后台程序，这个后台程序负责把HDFS数据块读写到本地的文件系统。当需要通过客户端读/写某个 数据时，先由NameNode告诉客户端去哪个DataNode进行具体的读/写操作，然后，&lt;strong&gt;客户端直接&lt;/strong&gt;与这个DataNode服务器上的后台程序进行通信，并且对相关的数据块进行读/写操作。&lt;/p&gt;
&lt;p&gt;数据会以多个副本的形式存在于多个DataNode中。因此，DataNode不存在单点故障。&lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot_20161117_181939" src="images/Screenshot_20161117_181939.png"&gt;&lt;/p&gt;
&lt;h3&gt;Secondary NameNode&lt;/h3&gt;
&lt;p&gt;~~Secondary NameNode不是NameNode的备份。它是一个用来监控HDFS状态的&lt;strong&gt;辅助后台程序&lt;/strong&gt;。Secondary  NameNode不同于NameNode，它不接受或者记录任何实时的数据变化，但是，它会与NameNode进行通信，周期性的合并fsimage和edits日志，保持edits文件大小在一个限定的范围内，并定期地保存HDFS元数据的快照。~~&lt;/p&gt;
&lt;p&gt;SNN的作用 现在 （Hadoop2.x）可以被两个节点替换CheckpointNode和BackupNode。
CheckpointNode可以理解为与Secondary NameNode的作用一致。
BackupNode：NameNode的完全备份。&lt;/p&gt;
&lt;h3&gt;JobTracker &amp;amp; TaskTracker&lt;/h3&gt;
&lt;p&gt;JobTracker后台程序用来连接应用程序与Hadoop。用户代码提交到集群以后，由JobTracker决定哪个文件将被处理，并且为不同的&lt;strong&gt;task&lt;/strong&gt;分配节点。同时，它还监控所有的task，一旦某个task失败了，JobTracker就会自动重新开启这个task。&lt;/p&gt;
&lt;p&gt;TaskTracker与负责存储数据的DataNode相结合，其处理结构上也遵循主/从架构。JobTracker位于主节点，统领 MapReduce工作；而TaskTrackers位于从节点，独立管理各自的task。每个TaskTracker负责独立执行具体的task，而 JobTracker负责分配task。虽然每个从节点仅有一个唯一的一个TaskTracker，但是每个TaskTracker可以产生多个java 虚拟机（JVM），用于&lt;strong&gt;并行&lt;/strong&gt;处理多个map以及reduce任务。TaskTracker的一个重要职责就是与JobTracker交互。如果 JobTracker无法准时地获取TaskTracker提交的信息，JobTracker就判定TaskTracker已经崩溃，并将任务分配给其他 节点处理。&lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot_20161117_182155" src="images/Screenshot_20161117_182155.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot_20161117_182220" src="images/Screenshot_20161117_182220.png"&gt;&lt;/p&gt;
&lt;h3&gt;ResourceManager &amp;amp; NodeManager&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ResourceManager：负责整个集群的资源管理和调度，将各个资源部分（计算、内存、带宽等）精心安排给基础 NodeManager（YARN 的每节点代理）&lt;/li&gt;
&lt;li&gt;处理客户端请求&lt;/li&gt;
&lt;li&gt;启动或监控ApplicationMaster&lt;/li&gt;
&lt;li&gt;监控NodeManager&lt;/li&gt;
&lt;li&gt;资源的分配与调度&lt;/li&gt;
&lt;li&gt;ApplicationMaster：负责应用程序相关事务，比如任务调度、任务监控和容错等，负责协调来自 ResourceManager 的资源，并通过 NodeManager 监视容器的执行和资源使用（CPU、内存等的资源分配）&lt;/li&gt;
&lt;li&gt;负责数据的切分&lt;/li&gt;
&lt;li&gt;为应用程序申请资源并分配给内部的任务&lt;/li&gt;
&lt;li&gt;任务的监控与容错&lt;/li&gt;
&lt;li&gt;NodeManager： NodeManager管理YARN集群中的每个节点。NodeManager 提供针对集群中每个节点的服务，从监督对一个容器的终生管理到监视资源和跟踪节点健康。&lt;/li&gt;
&lt;li&gt;管理单个节点上的资源&lt;/li&gt;
&lt;li&gt;处理来自ResourceManager的命令&lt;/li&gt;
&lt;li&gt;处理来自ApplicationMaster的命令&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hadoop的master和slave分别运行在不同的服务器中，其中hadoop-master中运行NameNode和ResourceManager，hadoop-slave中运行DataNode和NodeManager。NameNode和DataNode是Hadoop分布式文件系统HDFS的组件，负责储存输入以及输出数据，而ResourceManager和NodeManager是Hadoop集群资源管理系统YARN的组件，负责CPU和内存资源的调度。 &lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot_20161106_200858" src="images/Screenshot_20161106_200858.png"&gt;&lt;/p&gt;
&lt;h2&gt;Running Hadoop&lt;/h2&gt;
&lt;h3&gt;Local (standalone) mode&lt;/h3&gt;
&lt;p&gt;With empty configuration files, Hadoop will run completely on the local machine.Because there’s no need to communicate with other nodes, the standalone mode doesn't use HDFS, nor will it launch any of the Hadoop daemons.&lt;/p&gt;
&lt;h3&gt;Pseudo-distributed mode&lt;/h3&gt;
&lt;p&gt;running Hadoop in a “cluster of one”  with all daemons running on a single machine.&lt;/p&gt;
&lt;h3&gt;Fully distributed mode&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;master—The master node of the cluster and host of the NameNode and Job-Tracker daemons&lt;/li&gt;
&lt;li&gt;backup—The server that hosts the Secondary NameNode daemon&lt;/li&gt;
&lt;li&gt;hadoop1, hadoop2, hadoop3, ...—The slave boxes of the cluster running both DataNode and TaskTracker daemons&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;About Java&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Version 2.7 and later of Apache Hadoop requires Java 7. It is built and tested on both OpenJDK and Oracle (&lt;a href="https://wiki.apache.org/hadoop/HotSpot"&gt;HotSpot&lt;/a&gt;)'s JDK/JRE. Earlier versions (2.6 and earlier) support Java 6. &lt;/p&gt;
&lt;p&gt;OpenJDK has been used to qualify Hadoop 2.2 -and the rest of the Hortonworks bundle- on RHEL6. No problems were noted. &lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;基于虚拟机搭建Hadoop集群&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;基于平台：Ubuntu server 16.04&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;准备虚拟机&lt;/h3&gt;
&lt;p&gt;使用Virtualbox安装ubuntu，为了便于多虚拟机之间、宿主机与虚拟机之间连接，增加一张使用&lt;code&gt;Host-only&lt;/code&gt;的虚拟网卡。&lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot_20161116_144933" src="images/Screenshot_20161116_144933.png"&gt;&lt;/p&gt;
&lt;h3&gt;手动安装教程&lt;/h3&gt;
&lt;p&gt;参见 https://www.digitalocean.com/community/tutorials/how-to-install-hadoop-in-stand-alone-mode-on-ubuntu-16-04&lt;/p&gt;
&lt;h3&gt;单节点脚本安装&lt;/h3&gt;
&lt;p&gt;使用以下脚本安装，脚本测试过的环境为ubuntu server 16.04。&lt;/p&gt;
&lt;p&gt;https://github.com/chih7/hadoop_install&lt;/p&gt;
&lt;h3&gt;分布式运行&lt;/h3&gt;
&lt;p&gt;直接从单机安装的virtualbox虚拟机clone了两台一样的机器，确保ip如脚本配置：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;MASTER_IP="192.168.56.101"
SLAVE_IP1="192.168.56.102"
SLAVE_IP2="192.168.56.103"&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;进入了hadoop-master的/root目录，直接运行&lt;code&gt;start-hadoop.sh&lt;/code&gt;脚本即可。&lt;/p&gt;
&lt;h2&gt;基于Docker搭建Hadoop集群&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;标准的交付件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="01-docker-container" src="images/01-docker-container.jpg"&gt;&lt;/p&gt;
&lt;h3&gt;优势&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;存储驱动-层叠镜像模型&lt;/li&gt;
&lt;li&gt;以应用为中心的云计算新模式-以容器为标准交付件&lt;/li&gt;
&lt;li&gt;版本控制-对接代码仓库，自动化测试和构建&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="uScreenshot_20161110_120920" src="images/Screenshot_20161110_120920.png"&gt;&lt;/p&gt;
&lt;h3&gt;安装过程&lt;/h3&gt;
&lt;h4&gt;3节点Hadoop集群搭建步骤&lt;/h4&gt;
&lt;h5&gt;pull docker image&lt;/h5&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo docker pull kiwenlau/hadoop:1.0
&lt;/pre&gt;&lt;/div&gt;


&lt;h5&gt;clone github repository&lt;/h5&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;git clone https://github.com/kiwenlau/hadoop-cluster-docker
&lt;/pre&gt;&lt;/div&gt;


&lt;h5&gt;create hadoop network&lt;/h5&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo docker network create --driver=bridge hadoop
&lt;/pre&gt;&lt;/div&gt;


&lt;h5&gt;start container&lt;/h5&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;cd hadoop-cluster-docker
sudo ./start-container.sh
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;output:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;start hadoop-master container...
start hadoop-slave1 container...
start hadoop-slave2 container...
root@hadoop-master:~# 
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;start 3 containers with 1 master and 2 slaves&lt;/li&gt;
&lt;li&gt;you will get into the /root directory of hadoop-master container&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ docker info  
Containers: &lt;span class="m"&gt;3&lt;/span&gt;
 Running: &lt;span class="m"&gt;3&lt;/span&gt;
 Paused: &lt;span class="m"&gt;0&lt;/span&gt;
 Stopped: &lt;span class="m"&gt;0&lt;/span&gt;
Images: &lt;span class="m"&gt;1&lt;/span&gt;
...
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;查看docker的运行信息，可以看到基于一个镜像，运行了三个容器实例。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo du -chs ./docker/ 
&lt;span class="m"&gt;1&lt;/span&gt;.7G    ./docker/
&lt;span class="m"&gt;1&lt;/span&gt;.7G    total
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;查看整个docker集群的磁盘占用，全部只有3.3GB，可见基于层叠镜像模型，docker大大减少了磁盘占用。&lt;/p&gt;
&lt;h5&gt;start hadoop&lt;/h5&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;./start-hadoop.sh
&lt;/pre&gt;&lt;/div&gt;


&lt;h5&gt;run wordcount&lt;/h5&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;./run-wordcount.sh
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;output&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;input file1.txt:
Hello Hadoop

input file2.txt:
Hello Docker

wordcount output:
Docker    1
Hadoop    1
Hello    2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hadoop网页管理地址:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NameNode: &lt;a href="http://127.0.0.1:50070/"&gt;http://127.0.0.1:50070/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ResourceManager: &lt;a href="http://127.0.0.1:8088/"&gt;http://127.0.0.1:8088/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;127.0.0.1&lt;/code&gt;为运行容器的主机的IP。&lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot_20161107_133024" src="images/Screenshot_20161107_133024.png"&gt;&lt;/p&gt;
&lt;h4&gt;N节点Hadoop集群搭建步骤&lt;/h4&gt;
&lt;h5&gt;先准备3节点Hadoop集群&lt;/h5&gt;
&lt;h5&gt;重新构建Docker镜像&lt;/h5&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo ./resize-cluster.sh 5
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;指定任意N，增加slaves节点的数量&lt;/li&gt;
&lt;/ul&gt;
&lt;h5&gt;启动Docker容器&lt;/h5&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;sudo ./start-container.sh 5
&lt;/pre&gt;&lt;/div&gt;


&lt;ul&gt;
&lt;li&gt;与第2步中的N保持一致。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;参考： https://github.com/kiwenlau/hadoop-cluster-docker&lt;/p&gt;
&lt;h3&gt;Docker集群&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Kubernetes  &lt;/li&gt;
&lt;li&gt;Docker Swarm &lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;基于云的hadoop集群&lt;/h2&gt;
&lt;h3&gt;青云&lt;/h3&gt;
&lt;p&gt;https://www.qingcloud.com/hadoop&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.qingcloud.com/hadoop#hdfs"&gt;集成 Yarn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.qingcloud.com/hadoop#scaling"&gt;在线伸缩&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.qingcloud.com/hadoop#monitor"&gt;实时监控&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.qingcloud.com/hadoop#alarm"&gt;监控告警&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;价格&lt;/h4&gt;
&lt;p&gt;&lt;img alt="Screenshot_20161107_210119" src="images/Screenshot_20161107_210119.png"&gt;&lt;/p&gt;
&lt;h3&gt;Azure中国&lt;/h3&gt;
&lt;p&gt;https://www.azure.cn/home/features/hdinsight/&lt;/p&gt;
&lt;p&gt;国内首家100%基于 Apache Hadoop 的云服务&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;按需扩展至 PB 级别&lt;/li&gt;
&lt;li&gt;处理非结构化和半结构化数据&lt;/li&gt;
&lt;li&gt;在 Java、.NET 等环境中开发&lt;/li&gt;
&lt;li&gt;无需购买和维护硬件&lt;/li&gt;
&lt;li&gt;仅为您使用的服务付费&lt;/li&gt;
&lt;li&gt;在几分钟内创建 Hadoop 群集&lt;/li&gt;
&lt;li&gt;在 Excel 中直观呈现您的 Hadoop 数据&lt;/li&gt;
&lt;li&gt;轻松集成本地 Hadoop 群集&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;价格&lt;/h4&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;实例&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;内核数&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;内存数&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;磁盘大小&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;每节点价格&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;A1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1.75GB&lt;/td&gt;
&lt;td&gt;70GB&lt;/td&gt;
&lt;td&gt;￥0.51 /小时（约合￥379.44 /月）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;A2&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;3.5GB&lt;/td&gt;
&lt;td&gt;135GB&lt;/td&gt;
&lt;td&gt;￥1.01 /小时（约合￥751.44 /月）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;A3&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;7GB&lt;/td&gt;
&lt;td&gt;285GB&lt;/td&gt;
&lt;td&gt;￥2.03 /小时（约合￥1,510.32 /月）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;A4&lt;/td&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;14GB&lt;/td&gt;
&lt;td&gt;605GB&lt;/td&gt;
&lt;td&gt;￥4.05 /小时（约合￥3,013.20 /月）&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;AWS中国&lt;/h3&gt;
&lt;p&gt;https://aws.amazon.com/cn/elasticmapreduce/&lt;/p&gt;
&lt;p&gt;Amazon EMR 简化了大数据的处理，提供的托管 &lt;a href="https://aws.amazon.com/cn/elasticmapreduce/details/hadoop/"&gt;Hadoop&lt;/a&gt; 框架可以让您轻松、快速、经济高效地在多个动态可扩展的 Amazon EC2 实例之间分发和处理大量数据。您还可以运行其他常用的分发框架（例如 Amazon EMR 中的 Spark 和 Presto）与其他 AWS 数据存储服务（例如 Amazon S3 和 Amazon DynamoDB）中的数据进行互动。&lt;/p&gt;</content><category term="linux"></category><category term="Hadoop"></category><category term="Java， Big Data"></category></entry><entry><title>使用LuCI的RPC接口修改openwrt配置</title><link href="https://blog.chih.me/chang-openwtr-ppoe-password.html" rel="alternate"></link><published>2016-10-17T00:00:00+08:00</published><updated>2016-10-17T00:00:00+08:00</updated><author><name>chih</name></author><id>tag:blog.chih.me,2016-10-17:/chang-openwtr-ppoe-password.html</id><summary type="html">&lt;p&gt;简单来说，本文整理了一些&lt;code&gt;openwrt&lt;/code&gt;的RPC接口，用来自动修改pppoe的密码，并重启网络。为什么要弄这些玩意呢，因为浙江高校中普遍使用的蛋疼的闪讯——两三天换个动态密码，时不时给你断个网！使用这些API的是一个Android应用，它在用户按下一个按键后自动向电信发送一条获取密码的短信，然后获取返回的短信，解析其中的闪讯动态密码，通过&lt;code&gt;openwrt&lt;/code&gt;的RPC接口修改密码并重启网络，这样，只需要一次按按钮的操作，就能恢复网络，又可以愉快的玩耍啦。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/openwrt/openwrt"&gt;openwrt&lt;/a&gt; 我就不多介绍了，玩路由器的都知道；&lt;a href="https://wiki.openwrt.org/doc/techref/uci"&gt;UCI&lt;/a&gt;是&lt;code&gt;openwrt&lt;/code&gt;提供的一套统一的配置接口，可以用以配置整台&lt;code&gt;openwrt&lt;/code&gt;设备；而&lt;a href="https://wiki.openwrt.org/doc/techref/luci"&gt;LuCI&lt;/a&gt;是一个基于Lua语言开发的、包装了底层UCI接口的易于使用的Web用户接口。LuCI也提供了一种基于JSON格式的RPC机制来访问其内部的库。&lt;/p&gt;
&lt;p&gt;LuCI的RPC接口的地址为 &lt;strong&gt;/cgi-bin/luci/rpc/LIBRARY&lt;/strong&gt;，其中LIBRARY代表按功能区分的几个库，分别为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;auth&lt;/strong&gt; - 基于token的认证库&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;uci&lt;/strong&gt; - UCI统一配置接口的映射&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;fs&lt;/strong&gt; -  文件操作&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;sys …&lt;/strong&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;简单来说，本文整理了一些&lt;code&gt;openwrt&lt;/code&gt;的RPC接口，用来自动修改pppoe的密码，并重启网络。为什么要弄这些玩意呢，因为浙江高校中普遍使用的蛋疼的闪讯——两三天换个动态密码，时不时给你断个网！使用这些API的是一个Android应用，它在用户按下一个按键后自动向电信发送一条获取密码的短信，然后获取返回的短信，解析其中的闪讯动态密码，通过&lt;code&gt;openwrt&lt;/code&gt;的RPC接口修改密码并重启网络，这样，只需要一次按按钮的操作，就能恢复网络，又可以愉快的玩耍啦。&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/openwrt/openwrt"&gt;openwrt&lt;/a&gt; 我就不多介绍了，玩路由器的都知道；&lt;a href="https://wiki.openwrt.org/doc/techref/uci"&gt;UCI&lt;/a&gt;是&lt;code&gt;openwrt&lt;/code&gt;提供的一套统一的配置接口，可以用以配置整台&lt;code&gt;openwrt&lt;/code&gt;设备；而&lt;a href="https://wiki.openwrt.org/doc/techref/luci"&gt;LuCI&lt;/a&gt;是一个基于Lua语言开发的、包装了底层UCI接口的易于使用的Web用户接口。LuCI也提供了一种基于JSON格式的RPC机制来访问其内部的库。&lt;/p&gt;
&lt;p&gt;LuCI的RPC接口的地址为 &lt;strong&gt;/cgi-bin/luci/rpc/LIBRARY&lt;/strong&gt;，其中LIBRARY代表按功能区分的几个库，分别为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;auth&lt;/strong&gt; - 基于token的认证库&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;uci&lt;/strong&gt; - UCI统一配置接口的映射&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;fs&lt;/strong&gt; -  文件操作&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;sys&lt;/strong&gt; - 提供了一些系统通用功能&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ipkg&lt;/strong&gt; - ipk包的管理&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面以具体的操作演示其中一些库的使用，文中未用到的库可自行查询&lt;a href="https://htmlpreview.github.io/?https://raw.githubusercontent.com/openwrt/luci/master/documentation/api/index.html"&gt;API文档&lt;/a&gt; 。&lt;/p&gt;
&lt;h2&gt;修改pppoe密码流程&lt;/h2&gt;
&lt;p&gt;下面的请求都使用&lt;code&gt;curl&lt;/code&gt;作为HTTP客户端。&lt;/p&gt;
&lt;h3&gt;获取token&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ curl -i -X POST -d &lt;span class="s1"&gt;&amp;#39;{&amp;quot;method&amp;quot;:&amp;quot;login&amp;quot;,&amp;quot;params&amp;quot;:[&amp;quot;root&amp;quot;,&amp;quot;admin&amp;quot;]}&amp;#39;&lt;/span&gt; http://192.168.1.1/cgi-bin/luci/rpc/auth

HTTP/1.1 &lt;span class="m"&gt;200&lt;/span&gt; OK
Connection: close
Transfer-Encoding: chunked
Content-Type: application/json
Set-Cookie: &lt;span class="nv"&gt;sysauth&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;f807d8dc25e82d2d457c0d2f1ee27ce7&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nv"&gt;path&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/
Cache-Control: no-cache
Expires: &lt;span class="m"&gt;0&lt;/span&gt;

&lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;id&amp;quot;&lt;/span&gt;:null,&lt;span class="s2"&gt;&amp;quot;result&amp;quot;&lt;/span&gt;:&lt;span class="s2"&gt;&amp;quot;f807d8dc25e82d2d457c0d2f1ee27ce7&amp;quot;&lt;/span&gt;,&lt;span class="s2"&gt;&amp;quot;error&amp;quot;&lt;/span&gt;:null&lt;span class="o"&gt;}&lt;/span&gt;%   
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;以POST形式向&lt;code&gt;/cgi-bin/luci/rpc/auth&lt;/code&gt;地址发送格式为&lt;code&gt;{"method":"login","params":["root","admin"]}&lt;/code&gt;的登录请求，其中参数&lt;code&gt;params&lt;/code&gt;为路由器的帐号密码，路由器返回json，其中result的值就是token，在这里是f807d8dc25e82d2d457c0d2f1ee27ce7。&lt;/p&gt;
&lt;h3&gt;设置pppoe密码&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ curl -i -X POST -d &lt;span class="s1"&gt;&amp;#39;{&amp;quot;method&amp;quot;:&amp;quot;set&amp;quot;, &amp;quot;params&amp;quot;:[&amp;quot;network&amp;quot;, &amp;quot;wan&amp;quot;, &amp;quot;password&amp;quot;, &amp;quot;123456&amp;quot;]}&amp;#39;&lt;/span&gt; http://192.168.1.1/cgi-bin/luci/rpc/uci&lt;span class="se"&gt;\?&lt;/span&gt;auth&lt;span class="se"&gt;\=&lt;/span&gt;f807d8dc25e82d2d457c0d2f1ee27ce7

HTTP/1.1 &lt;span class="m"&gt;200&lt;/span&gt; OK
Connection: close
Transfer-Encoding: chunked
Content-Type: application/json
Cache-Control: no-cache
Expires: &lt;span class="m"&gt;0&lt;/span&gt;

&lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;id&amp;quot;&lt;/span&gt;:null,&lt;span class="s2"&gt;&amp;quot;result&amp;quot;&lt;/span&gt;:true,&lt;span class="s2"&gt;&amp;quot;error&amp;quot;&lt;/span&gt;:null&lt;span class="o"&gt;}&lt;/span&gt;%    
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;上面的POST请求向&lt;code&gt;cgi-bin/luci/rpc/uci&lt;/code&gt;这个地址发送&lt;code&gt;set&lt;/code&gt;方法，参数格式如下所示：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;config: UCI config&lt;/li&gt;
&lt;li&gt;section: UCI section name&lt;/li&gt;
&lt;li&gt;option: UCI option or UCI section type&lt;/li&gt;
&lt;li&gt;value: UCI value or nothing if you want to create a section&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这里 &lt;code&gt;params":["network", "wan", "password", "123456"]&lt;/code&gt;的参数即代表修改network-&amp;gt;wan-&amp;gt;password的值为123456。注意带上你的token，不然请求将返回403错误码。&lt;/p&gt;
&lt;h3&gt;获取pppoe密码&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ curl -i -X POST -d &lt;span class="s1"&gt;&amp;#39;{&amp;quot;method&amp;quot;:&amp;quot;get&amp;quot;, &amp;quot;params&amp;quot;:[&amp;quot;network&amp;quot;, &amp;quot;wan&amp;quot;, &amp;quot;password&amp;quot;]}&amp;#39;&lt;/span&gt; http://192.168.1.1/cgi-bin/luci/rpc/uci&lt;span class="se"&gt;\?&lt;/span&gt;auth&lt;span class="se"&gt;\=&lt;/span&gt;f807d8dc25e82d2d457c0d2f1ee27ce7

HTTP/1.1 &lt;span class="m"&gt;200&lt;/span&gt; OK
Connection: close
Transfer-Encoding: chunked
Content-Type: application/json
Cache-Control: no-cache
Expires: &lt;span class="m"&gt;0&lt;/span&gt;

&lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;id&amp;quot;&lt;/span&gt;:null,&lt;span class="s2"&gt;&amp;quot;result&amp;quot;&lt;/span&gt;:&lt;span class="s2"&gt;&amp;quot;123456&amp;quot;&lt;/span&gt;,&lt;span class="s2"&gt;&amp;quot;error&amp;quot;&lt;/span&gt;:null&lt;span class="o"&gt;}&lt;/span&gt;%   
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;有&lt;code&gt;set&lt;/code&gt;方式，当然也有&lt;code&gt;get&lt;/code&gt;方法，可以用以取得配置的值。&lt;/p&gt;
&lt;h3&gt;提交修改&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ curl -i -X POST -d &lt;span class="s1"&gt;&amp;#39;{&amp;quot;method&amp;quot;:&amp;quot;commit&amp;quot;, &amp;quot;params&amp;quot;:[&amp;quot;network&amp;quot;]}&amp;#39;&lt;/span&gt; http://192.168.1.1/cgi-bin/luci/rpc/uci&lt;span class="se"&gt;\?&lt;/span&gt;auth&lt;span class="se"&gt;\=&lt;/span&gt;f807d8dc25e82d2d457c0d2f1ee27ce7  

HTTP/1.1 &lt;span class="m"&gt;200&lt;/span&gt; OK
Connection: close
Transfer-Encoding: chunked
Content-Type: application/json
Cache-Control: no-cache
Expires: &lt;span class="m"&gt;0&lt;/span&gt;

&lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;id&amp;quot;&lt;/span&gt;:null,&lt;span class="s2"&gt;&amp;quot;result&amp;quot;&lt;/span&gt;:true,&lt;span class="s2"&gt;&amp;quot;error&amp;quot;&lt;/span&gt;:null&lt;span class="o"&gt;}&lt;/span&gt;%   
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;注意，前面的&lt;code&gt;set&lt;/code&gt;方法只改变了内存中配置的值，而 &lt;code&gt;uci&lt;/code&gt;库中的&lt;code&gt;commit&lt;/code&gt;即相当于把更改写入到配置文件。想让配置生效，这一步是不缺少的。&lt;/p&gt;
&lt;h3&gt;重启网络&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ curl -i -X POST -d &lt;span class="s1"&gt;&amp;#39;{&amp;quot;method&amp;quot;:&amp;quot;exec&amp;quot;, &amp;quot;params&amp;quot;:[&amp;quot;/etc/init.d/network restart&amp;quot;]}&amp;#39;&lt;/span&gt; http://192.168.1.1/cgi-bin/luci/rpc/sys&lt;span class="se"&gt;\?&lt;/span&gt;auth&lt;span class="se"&gt;\=&lt;/span&gt;f807d8dc25e82d2d457c0d2f1ee27ce7

HTTP/1.1 &lt;span class="m"&gt;200&lt;/span&gt; OK
Connection: close
Transfer-Encoding: chunked
Content-Type: application/json
Cache-Control: no-cache
Expires: &lt;span class="m"&gt;0&lt;/span&gt;

&lt;span class="o"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;id&amp;quot;&lt;/span&gt;:null,&lt;span class="s2"&gt;&amp;quot;result&amp;quot;&lt;/span&gt;:&lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;,&lt;span class="s2"&gt;&amp;quot;error&amp;quot;&lt;/span&gt;:null&lt;span class="o"&gt;}&lt;/span&gt;%  
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;访问&lt;code&gt;/cgi-bin/luci/rpc/sys&lt;/code&gt;地址可以使用&lt;code&gt;sys&lt;/code&gt;库各种方法。大致有以下几种：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;a href="http://htmlpreview.github.io/?http://raw.githubusercontent.com/openwrt/luci/master/documentation/api/modules/luci.sys.html#call"&gt;call&lt;/a&gt; (...)&lt;/th&gt;
&lt;th align="left"&gt;Execute a given shell command and return the error code&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://htmlpreview.github.io/?http://raw.githubusercontent.com/openwrt/luci/master/documentation/api/modules/luci.sys.html#dmesg"&gt;dmesg&lt;/a&gt; ()&lt;/td&gt;
&lt;td align="left"&gt;Retrieves the output of the "dmesg" command.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://htmlpreview.github.io/?http://raw.githubusercontent.com/openwrt/luci/master/documentation/api/modules/luci.sys.html#exec"&gt;exec&lt;/a&gt; (command)&lt;/td&gt;
&lt;td align="left"&gt;Execute a given shell command and capture its standard output&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://htmlpreview.github.io/?http://raw.githubusercontent.com/openwrt/luci/master/documentation/api/modules/luci.sys.html#getenv"&gt;getenv&lt;/a&gt; (var)&lt;/td&gt;
&lt;td align="left"&gt;Retrieve environment variables.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://htmlpreview.github.io/?http://raw.githubusercontent.com/openwrt/luci/master/documentation/api/modules/luci.sys.html#hostname"&gt;hostname&lt;/a&gt; (String)&lt;/td&gt;
&lt;td align="left"&gt;Get or set the current hostname.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://htmlpreview.github.io/?http://raw.githubusercontent.com/openwrt/luci/master/documentation/api/modules/luci.sys.html#httpget"&gt;httpget&lt;/a&gt; (url, stream, target)&lt;/td&gt;
&lt;td align="left"&gt;Returns the contents of a documented referred by an URL.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://htmlpreview.github.io/?http://raw.githubusercontent.com/openwrt/luci/master/documentation/api/modules/luci.sys.html#mounts"&gt;mounts&lt;/a&gt; ()&lt;/td&gt;
&lt;td align="left"&gt;Retrieve information about currently mounted file systems.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://htmlpreview.github.io/?http://raw.githubusercontent.com/openwrt/luci/master/documentation/api/modules/luci.sys.html#reboot"&gt;reboot&lt;/a&gt; ()&lt;/td&gt;
&lt;td align="left"&gt;Initiate a system reboot.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://htmlpreview.github.io/?http://raw.githubusercontent.com/openwrt/luci/master/documentation/api/modules/luci.sys.html#syslog"&gt;syslog&lt;/a&gt; ()&lt;/td&gt;
&lt;td align="left"&gt;Retrieves the output of the "logread" command.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://htmlpreview.github.io/?http://raw.githubusercontent.com/openwrt/luci/master/documentation/api/modules/luci.sys.html#uniqueid"&gt;uniqueid&lt;/a&gt; (bytes)&lt;/td&gt;
&lt;td align="left"&gt;Generates a random id with specified length.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="http://htmlpreview.github.io/?http://raw.githubusercontent.com/openwrt/luci/master/documentation/api/modules/luci.sys.html#uptime"&gt;uptime&lt;/a&gt; ()&lt;/td&gt;
&lt;td align="left"&gt;Returns the current system uptime stats.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;code&gt;sys&lt;/code&gt;库中&lt;code&gt;exec&lt;/code&gt;方法可以执行系统命令，这里我们通过&lt;code&gt;/etc/init.d/network restart&lt;/code&gt;命令重启网络，让配置生效。&lt;/p&gt;
&lt;h2&gt;Android端&lt;/h2&gt;
&lt;p&gt;需要RPC接口基本都介绍完了，接下来就是使用接口了，Android需要完成以下任务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;界面显示&lt;/li&gt;
&lt;li&gt;给电信发送请求密码的短信&lt;/li&gt;
&lt;li&gt;获取电信返回的电信&lt;/li&gt;
&lt;li&gt;解析出短信中的密码&lt;/li&gt;
&lt;li&gt;调用openwrt的RPC接口修改密码&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Android端目前基本已经可以用了，相关代码后续会开源出来。&lt;/p&gt;
&lt;h2&gt;参考&lt;/h2&gt;
&lt;p&gt;Documentation - &lt;a href="http://luci.subsignal.org/trac/wiki/Documentation/JsonRpcHowTo"&gt;http://luci.subsignal.org/trac/wiki/Documentation/JsonRpcHowTo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://htmlpreview.github.io/?https://raw.githubusercontent.com/openwrt/luci/master/documentation/api/index.html"&gt;LuCI API文档&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://blog.csdn.net/jt6562/article/details/21399897"&gt;LuCI的RPC接口使用方法详解&lt;/a&gt;&lt;/p&gt;</content><category term="linux"></category><category term="openwrt"></category><category term="android"></category><category term="luci"></category><category term="rpc"></category></entry><entry><title>使用Python求解分隙ALOHA最大效率</title><link href="https://blog.chih.me/use-SymPy-get-max-effectiveness-of-ALOHA.html" rel="alternate"></link><published>2016-10-08T00:00:00+08:00</published><updated>2016-10-08T00:00:00+08:00</updated><author><name>chih</name></author><id>tag:blog.chih.me,2016-10-08:/use-SymPy-get-max-effectiveness-of-ALOHA.html</id><summary type="html">&lt;p&gt;SymPy是一个符号计算的Python库，SymPy支持符号计算、高精度计算、模式匹配、绘图、解方程、微积分、组合数学、离散数学、几何学、概率与统计、物理学等方面的功能。下面我将基于它求解以下两个问题。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;当有N个活跃节点的时候，分隙ALOHA的效率为 &lt;span class="math"&gt;\(N p (1 - p)^{N - 1}\)&lt;/span&gt; ，找出使这个表达式最大化的&lt;code&gt;p&lt;/code&gt;值。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;采用 &lt;code&gt;1&lt;/code&gt; 中的p值，计算当 &lt;code&gt;N&lt;/code&gt; 趋近于无穷时分隙ALOHA的效率。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sympy&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;首先导入sympy库，方便起见，导入了所有内容。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Symbol&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;N&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Symbol&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;p&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;在SymPy中，数学符号是Symbol类的对象，要明确声明符号变量，我们新建了&lt;code&gt;N&lt;/code&gt;与&lt;code&gt;p&lt;/code&gt;符号 …&lt;/p&gt;</summary><content type="html">&lt;p&gt;SymPy是一个符号计算的Python库，SymPy支持符号计算、高精度计算、模式匹配、绘图、解方程、微积分、组合数学、离散数学、几何学、概率与统计、物理学等方面的功能。下面我将基于它求解以下两个问题。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;当有N个活跃节点的时候，分隙ALOHA的效率为 &lt;span class="math"&gt;\(N p (1 - p)^{N - 1}\)&lt;/span&gt; ，找出使这个表达式最大化的&lt;code&gt;p&lt;/code&gt;值。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;采用 &lt;code&gt;1&lt;/code&gt; 中的p值，计算当 &lt;code&gt;N&lt;/code&gt; 趋近于无穷时分隙ALOHA的效率。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sympy&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;首先导入sympy库，方便起见，导入了所有内容。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Symbol&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;N&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Symbol&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;p&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;在SymPy中，数学符号是Symbol类的对象，要明确声明符号变量，我们新建了&lt;code&gt;N&lt;/code&gt;与&lt;code&gt;p&lt;/code&gt;符号。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;定义公式 &lt;span class="math"&gt;\(N p (1 - p)^{N - 1}\)&lt;/span&gt; 为&lt;code&gt;e&lt;/code&gt;。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;e1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;diff&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;使用&lt;code&gt;diff(func, var)&lt;/code&gt;函数计算函数&lt;code&gt;e&lt;/code&gt;对&lt;code&gt;p&lt;/code&gt;的微分。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;solve&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[1/N]
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;使用&lt;code&gt;solve(func， var)&lt;/code&gt;函数求解当&lt;code&gt;e1=0&lt;/code&gt;时p的值，为 &lt;span class="math"&gt;\(\frac{1}{N}\)&lt;/span&gt; 可知，使 &lt;span class="math"&gt;\(N p (1 - p)^{N - 1}\)&lt;/span&gt; 最大化的&lt;code&gt;p&lt;/code&gt;值为 &lt;span class="math"&gt;\(\frac{1}{N}\)&lt;/span&gt; &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;将 &lt;span class="math"&gt;\(p = \frac{1}{N}\)&lt;/span&gt; 代入原表达式。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;limit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;oo&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;exp(-1)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;使用&lt;code&gt;limit(function, variable, point)&lt;/code&gt;函数求解当N趋向无穷大时， 表达式e的极限，即为 &lt;span class="math"&gt;\(\frac{1}{e}\)&lt;/span&gt; 所以，当 N 趋近于无穷时分隙ALOHA的效率为 &lt;span class="math"&gt;\(\frac{1}{e}\)&lt;/span&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content><category term="Python"></category><category term="SymPy"></category><category term="ALOHA"></category><category term="math"></category></entry><entry><title>无题</title><link href="https://blog.chih.me/64.html" rel="alternate"></link><published>2015-06-01T00:00:00+08:00</published><updated>2015-06-01T00:00:00+08:00</updated><author><name>chih</name></author><id>tag:blog.chih.me,2015-06-01:/64.html</id><summary type="html">&lt;p&gt;“鲜活的生命，悄无声息地消失。他们的死，既不壮烈，也不浪漫，当时无人知晓，今后或许也不会再被提起。但只要仍有人记得，他们的死便并非毫无意义。这也是卡萝尔•莫莉拍摄这部记录片并制作游戏的目的。人，不能永远消失。他们的故事，应让世人知晓。”&lt;/p&gt;
&lt;p&gt;“‘我们的人性，由我们对待同胞的行为界定。’1961年诺贝尔文学奖得主伊沃•安德里奇写道。卡萝尔为乔伊丝留下一部电影，玛格丽特为乔伊丝留下一个网站。而更多的人，从这个世界消失，没人悼念他们，没人为他们感到抱歉，甚至没人知道他们曾经存在过。今时今日，我们又能为他们做些什么?”&lt;/p&gt;
&lt;p&gt;-EOF-&lt;/p&gt;</summary><content type="html">&lt;p&gt;“鲜活的生命，悄无声息地消失。他们的死，既不壮烈，也不浪漫，当时无人知晓，今后或许也不会再被提起。但只要仍有人记得，他们的死便并非毫无意义。这也是卡萝尔•莫莉拍摄这部记录片并制作游戏的目的。人，不能永远消失。他们的故事，应让世人知晓。”&lt;/p&gt;
&lt;p&gt;“‘我们的人性，由我们对待同胞的行为界定。’1961年诺贝尔文学奖得主伊沃•安德里奇写道。卡萝尔为乔伊丝留下一部电影，玛格丽特为乔伊丝留下一个网站。而更多的人，从这个世界消失，没人悼念他们，没人为他们感到抱歉，甚至没人知道他们曾经存在过。今时今日，我们又能为他们做些什么?”&lt;/p&gt;
&lt;p&gt;-EOF-&lt;/p&gt;</content><category term="64"></category></entry><entry><title>我的硬盘不可能这么空~aria2篇</title><link href="https://blog.chih.me/download-use-aria2.html" rel="alternate"></link><published>2015-03-31T00:00:00+08:00</published><updated>2015-03-31T00:00:00+08:00</updated><author><name>chih</name></author><id>tag:blog.chih.me,2015-03-31:/download-use-aria2.html</id><summary type="html">&lt;p&gt;对于单纯的Aria2程序来说，它是一个轻量级、支持多种协议的命令行下载工具。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;支持的协议包括HTTP(S), FTP, BitTorrent, Metalink&lt;/li&gt;
&lt;li&gt;aria2可以并发的进行下载，并尝试将下载带宽利用率最大化&lt;/li&gt;
&lt;li&gt;分片与续传，自动中止并替换慢的线程&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;看到命令行可能有人会想:“恩，又是那种强大到用起来要查手册写命令的玩意”。其实不然，由于aria2 支持 JSON-RPC和XML-RPC远程调用，可以通过web前端或客户端方便地进行管理。&lt;/p&gt;
&lt;h3&gt;安装&lt;/h3&gt;
&lt;p&gt;在Linux下，可以很方便地通过包管理进行安装，比如Arch Linux&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo pacman -S aria2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;如果是Windows，可以下载编译好的二进制文件，放在&lt;code&gt;C:\WINDOWS\system32&lt;/code&gt;目录下，就可以通过&lt;code&gt;aria2c&lt;/code&gt;命令执行程序了&lt;/p&gt;
&lt;p&gt;可以直接运行命令进行下载:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;HTTP下载&lt;/p&gt;
&lt;p&gt;$ aria2c http://example.org/test.bin&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;从两个源同时下载&lt;/p&gt;
&lt;p&gt;$ aria2c http …&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;对于单纯的Aria2程序来说，它是一个轻量级、支持多种协议的命令行下载工具。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;支持的协议包括HTTP(S), FTP, BitTorrent, Metalink&lt;/li&gt;
&lt;li&gt;aria2可以并发的进行下载，并尝试将下载带宽利用率最大化&lt;/li&gt;
&lt;li&gt;分片与续传，自动中止并替换慢的线程&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;看到命令行可能有人会想:“恩，又是那种强大到用起来要查手册写命令的玩意”。其实不然，由于aria2 支持 JSON-RPC和XML-RPC远程调用，可以通过web前端或客户端方便地进行管理。&lt;/p&gt;
&lt;h3&gt;安装&lt;/h3&gt;
&lt;p&gt;在Linux下，可以很方便地通过包管理进行安装，比如Arch Linux&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo pacman -S aria2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;如果是Windows，可以下载编译好的二进制文件，放在&lt;code&gt;C:\WINDOWS\system32&lt;/code&gt;目录下，就可以通过&lt;code&gt;aria2c&lt;/code&gt;命令执行程序了&lt;/p&gt;
&lt;p&gt;可以直接运行命令进行下载:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;HTTP下载&lt;/p&gt;
&lt;p&gt;$ aria2c http://example.org/test.bin&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;从两个源同时下载&lt;/p&gt;
&lt;p&gt;$ aria2c http://example.org/test.bin ftp://example.org/test.bin&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;用种子下载&lt;/p&gt;
&lt;p&gt;$ aria2c http://example.org/test.torrent&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;用磁力链下载&lt;/p&gt;
&lt;p&gt;$ aria2c 'magnet:?xt=urn:btih:248D0A1CD08284299DE78D5C1ED359BB46717D8C'&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;配置&lt;/h3&gt;
&lt;p&gt;每次下载都要打命令太麻烦，可以通过配置文件开启rpc server模式并启用图形界面，让它自动等待下载任务、自动下载、暂停或续传。
以下的配置文件参考YAAW作者的&lt;a href="http://blog.binux.me/2012/12/aria2-examples/"&gt;配置示例&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;参数 --dir --input-file --save-session 根据实际情况修改路径&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;#允许rpc
enable-rpc=true
#允许所有来源, web界面跨域权限需要
rpc-allow-origin-all=true
#允许非外部访问
rpc-listen-all=true
#RPC端口, 仅当默认端口被占用时修改
#rpc-listen-port=6800
#最大同时下载数(任务数), 路由建议值: 3
max-concurrent-downloads=5
#断点续传
continue=true
#同服务器连接数
max-connection-per-server=5
#最小文件分片大小, 下载线程数上限取决于能分出多少片, 对于小文件重要
min-split-size=10M
#单文件最大线程数, 路由建议值: 5
split=10
#下载速度限制
max-overall-download-limit=0
#单文件速度限制
max-download-limit=0
#上传速度限制
max-overall-upload-limit=0
#单文件速度限制
max-upload-limit=0
#断开速度过慢的连接
#lowest-speed-limit=0
#验证用，需要1.16.1之后的release版本
#referer=*
input-file=/home/USER/.config/aria2_web/session.lock
save-session=/home/USER/.config/aria2_web/session.lock
#文件保存路径, 默认为当前启动位置
dir=/home/chih/Downloads
#文件缓存, 使用内置的文件缓存, 如果你不相信Linux内核文件缓存和磁盘内置缓存时使用, 需要1.16及以上版本
#disk-cache=0
#另一种Linux文件缓存方式, 使用前确保您使用的内核支持此选项, 需要1.15及以上版本(?)
#enable-mmap=true
#文件预分配, 能有效降低文件碎片, 提高磁盘性能. 缺点是预分配时间较长
#所需时间 none &amp;lt; falloc ? trunc &amp;lt;&amp;lt; prealloc, falloc和trunc需要文件系统和内核支持
file-allocation=prealloc
#启用本地节点查找
bt-enable-lpd=true
#添加额外的tracker
#bt-tracker=&amp;lt;URI&amp;gt;,…
#单种子最大连接数
#bt-max-peers=55
#强制加密, 防迅雷必备
#bt-require-crypto=true
#当下载的文件是一个种子(以.torrent结尾)时, 自动下载BT
follow-torrent=true
#BT监听端口, 当端口屏蔽时使用
#listen-port=6881-6999
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;我把配置文件放在了&lt;code&gt;~/.config/aria2_web&lt;/code&gt;目录下&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ mkdir -p ~/.config/aria2_web
$ vim ~/.config/aria2_web/aria2.conf
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;同时在目录下创建会话文件，未完成任务会保存在这里&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ touch ~/.config/aria2_web/session.lock
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;好了，可以通过&lt;code&gt;aria2c  --conf-path=~ /.config/aria2_web/aria2.conf&lt;/code&gt;进行配置文件的测试。&lt;/p&gt;
&lt;h3&gt;进程管理&lt;/h3&gt;
&lt;p&gt;现在我希望可以让aria2自动开启，并可以方便地进行进程管理，我使用了&lt;strong&gt;systemd&lt;/strong&gt;，当然，&lt;strong&gt;supervisor&lt;/strong&gt;也是可以达到类似效果。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ vim ~/.config/systemd/user/aria2.service
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;内容可以是这样:(感谢jahiyw指出错误:  systemctl --user 的启动脚本应该把 WantedBy 设置成 default.target，而不是 multi-user.target，因为以 --user 方式启动不存在 multi-user.target，所以，systemctl --user enable 了之后，永远都不会自动启动)&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;[Unit]&lt;/span&gt;
&lt;span class="na"&gt;Description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;Aria2 Service&lt;/span&gt;
&lt;span class="na"&gt;After&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;network.target&lt;/span&gt;

&lt;span class="k"&gt;[Service]&lt;/span&gt;
&lt;span class="na"&gt;ExecStart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/usr/bin/aria2c  --conf-path=%h/.config/aria2_web/aria2.conf&lt;/span&gt;

&lt;span class="k"&gt;[Install]&lt;/span&gt;
&lt;span class="na"&gt;WantedBy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;default.target&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;通过以下命令管理:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ systemctl --user start aria2
$ systemctl --user stop aria2
$ systemctl --user restart aria2
$ systemctl --user status aria2
$ systemctl --user &lt;span class="nb"&gt;enable&lt;/span&gt; aria2
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;注意: &lt;code&gt;--user&lt;/code&gt;这个选项不要忘了，也不需要&lt;code&gt;sudo&lt;/code&gt;，在这里用的是systemd给用户生成的systemd实例，具体可以见&lt;a href="https://wiki.archlinux.org/index.php/Systemd/User"&gt;这里&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;YAAW&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://github.com/binux/yaaw"&gt;YAAW&lt;/a&gt;是Binux写的一个Aria2 Web管理前端，直接用web服务器（Nginx, Apache）搭就是了，如果用的是上面的aria2配置，直接访问YAAW就可以管理aria2了。&lt;/p&gt;
&lt;p&gt;附上我的Nginx配置:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;server {
    listen       80;
    server_name  yaaw.site;

    location / {
        root   /opt/yaaw;
        index  index.html index.htm;
    }
    error_page   500 502 503 504  /50x.html;
    location = /50x.html {
        root   /usr/share/nginx/html;
    }
}
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;一些支持导出到aria2 RPC的chrome扩展&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://chrome.google.com/webstore/detail/thunderlixianassistant/eehlmkfpnagoieibahhcghphdbjcdmen"&gt;迅雷离线&lt;/a&gt;
&lt;a href="https://github.com/acgotaku/BaiduExporter"&gt;百度网盘&lt;/a&gt;
&lt;a href="https://chrome.google.com/webstore/detail/115exporter/ojafklbojgenkohhdgdjeaepnbjffdjf"&gt;115网盘&lt;/a&gt;&lt;/p&gt;</content><category term="linux"></category><category term="下载"></category><category term="aria2"></category><category term="systemd"></category></entry><entry><title>Arch Linux 修复grub2 引导过程中的花屏</title><link href="https://blog.chih.me/fixbug-grub2-in-archlinux.html" rel="alternate"></link><published>2015-03-15T00:00:00+08:00</published><updated>2015-03-15T00:00:00+08:00</updated><author><name>chih</name></author><id>tag:blog.chih.me,2015-03-15:/fixbug-grub2-in-archlinux.html</id><summary type="html">&lt;p&gt;前几天 &lt;code&gt;opensuse 13.2&lt;/code&gt; 被我强关了几次，结果用 &lt;code&gt;XFS&lt;/code&gt; 挂载的 &lt;code&gt;/home&lt;/code&gt; 每次都丢文件， 这样实在是让人难以安心，再加上opensuse 的一些操作始终感觉有些麻烦，官方仓库的软件也少。种种不便之处， 让我想起以前用 &lt;code&gt;Arch Linux&lt;/code&gt;时的舒心，于是备份重装。所有的文件系统用了 &lt;code&gt;Ext4&lt;/code&gt;(opensuse 上的&lt;code&gt;Btrfs&lt;/code&gt;的确先进，但很多功能我也没怎么去用)。&lt;/p&gt;
&lt;p&gt;​&lt;code&gt;Arch Linux&lt;/code&gt;的安装过程先略去不表。安装基本系统和&lt;code&gt;KDE&lt;/code&gt;都没有发现问题，但安装完基本系统重启的时候就发现有个小问题了喵。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;从BIOS自检完成到桌面启动直接的那段过程中屏幕一直都是花的，就是那种黑白电视机雪花屏的样子。
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这只是一个小问题，反正进入桌面之后就没影响了，但对于强迫症患者真是太难受了啊! 于是去Google找解决方案，翻了几页之后还真的被我找到类似的问题了—— &lt;a href="https://forum.suse.org.cn/viewtopic.php?f=2&amp;amp;t=2365"&gt;https://forum.suse.org.cn/viewtopic.php?f=2 …&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;前几天 &lt;code&gt;opensuse 13.2&lt;/code&gt; 被我强关了几次，结果用 &lt;code&gt;XFS&lt;/code&gt; 挂载的 &lt;code&gt;/home&lt;/code&gt; 每次都丢文件， 这样实在是让人难以安心，再加上opensuse 的一些操作始终感觉有些麻烦，官方仓库的软件也少。种种不便之处， 让我想起以前用 &lt;code&gt;Arch Linux&lt;/code&gt;时的舒心，于是备份重装。所有的文件系统用了 &lt;code&gt;Ext4&lt;/code&gt;(opensuse 上的&lt;code&gt;Btrfs&lt;/code&gt;的确先进，但很多功能我也没怎么去用)。&lt;/p&gt;
&lt;p&gt;​&lt;code&gt;Arch Linux&lt;/code&gt;的安装过程先略去不表。安装基本系统和&lt;code&gt;KDE&lt;/code&gt;都没有发现问题，但安装完基本系统重启的时候就发现有个小问题了喵。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;从BIOS自检完成到桌面启动直接的那段过程中屏幕一直都是花的，就是那种黑白电视机雪花屏的样子。
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这只是一个小问题，反正进入桌面之后就没影响了，但对于强迫症患者真是太难受了啊! 于是去Google找解决方案，翻了几页之后还真的被我找到类似的问题了—— &lt;a href="https://forum.suse.org.cn/viewtopic.php?f=2&amp;amp;t=2365"&gt;https://forum.suse.org.cn/viewtopic.php?f=2&amp;amp;t=2365&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;安装了 openSUSE，第一次用，以前都是 Debian；
目前是 KDE 桌面，IBM T400 Intel 集显 2G 内存；
我的问题是开机引导的页面是花屏，像是小时候的黑白电视机差一点点就收到信号的花屏，直接回车会进入系统，进入系统后一切正常；有和我情况一样的 suser 么？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;然后根据苏姐的回答，来到了&lt;code&gt;opensuse&lt;/code&gt;的官方文档
——&lt;a href="https://activedoc.opensuse.org/book/opensuse-reference/chapter-10-the-boot-loader-grub2"&gt;https://activedoc.opensuse.org/book/opensuse-reference/chapter-10-the-boot-loader-grub2&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;GRUB_GFXMODE&lt;/strong&gt;
The resolution used for the gfxterm graphical terminal. Note that you can only use modes supported by your graphics card (VBE). The default is ‘auto’, which tries to select a preferred resolution. You can display the screen resolutions available to GRUB2 by typing vbeinfo in the GRUB2 command line. The command line is accessed by typing c when the GRUB2 boot menu screen is displayed.
You can also specify a color bit depth by appending it to the resolution setting, for example GRUB_GFXMODE=1280x1024x24.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;OK，差不多有答案了，看我来试试看，修改&lt;code&gt;grub&lt;/code&gt;配置文件:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# vim /etc/default/grub
&lt;/pre&gt;&lt;/div&gt;


&lt;blockquote&gt;
&lt;p&gt;GRUB_GFXMODE=1440x900&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;修改GRUB配置文件&lt;code&gt;/etc/default/grub&lt;/code&gt; 和&lt;code&gt;/etc/grub.d/*&lt;/code&gt;后不要忘记重新生成GRUB2所需的配置文件&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# sudo grub-mkconfig -o /boot/grub/grub.cfg
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;满怀信心，重启。恩。。。还是失败，和之前的问题一模一样。&lt;/p&gt;
&lt;p&gt;那再改改吧，把分辨率降低一些——&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;GRUB_GFXMODE=800x600&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这样就可以了，&lt;code&gt;GRUB&lt;/code&gt;完美的出现在屏幕上了。&lt;/p&gt;
&lt;p&gt;-EOF-&lt;/p&gt;</content><category term="linux"></category><category term="grub2"></category></entry><entry><title>为MineCraft启动器挂上代理</title><link href="https://blog.chih.me/socks-for-minecraft.html" rel="alternate"></link><published>2015-03-14T00:00:00+08:00</published><updated>2015-03-14T00:00:00+08:00</updated><author><name>chih</name></author><id>tag:blog.chih.me,2015-03-14:/socks-for-minecraft.html</id><summary type="html">&lt;p&gt;&lt;code&gt;MineCraft&lt;/code&gt;官方启动器在启动的时候会从以下地址获取更新:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;https://s3.amazonaws.com/Minecraft.Download/launcher/launcher.pack.lzma
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;如你所见，用的是Amazon EC2，Amazon AWS云服务，这两个服务在国内都是部分被屏蔽的。&lt;/p&gt;
&lt;p&gt;但是如果你有shadowsocks等socks代理的话是可以给&lt;code&gt;MineCraft&lt;/code&gt;挂上代理的，虽然官方启动器并未提供代理设置。&lt;/p&gt;
&lt;p&gt;我在这里用的是&lt;code&gt;java&lt;/code&gt;提供的代理选项:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ java -DsocksProxyHost&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;127&lt;/span&gt;.0.0.1 -DsocksProxyPort&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1080&lt;/span&gt; -jar ~/.minecraft/Minecraft.jar
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这样子打开&lt;code&gt;MineCraft&lt;/code&gt;启动器就可以很快的登录、更新、下游戏了。但需要注意的是你通过启动器打开&lt;code&gt;Minecraft&lt;/code&gt;游戏本体之后，游戏是不走代理的。&lt;/p&gt;
&lt;p&gt;-EOF-&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;code&gt;MineCraft&lt;/code&gt;官方启动器在启动的时候会从以下地址获取更新:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;https://s3.amazonaws.com/Minecraft.Download/launcher/launcher.pack.lzma
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;如你所见，用的是Amazon EC2，Amazon AWS云服务，这两个服务在国内都是部分被屏蔽的。&lt;/p&gt;
&lt;p&gt;但是如果你有shadowsocks等socks代理的话是可以给&lt;code&gt;MineCraft&lt;/code&gt;挂上代理的，虽然官方启动器并未提供代理设置。&lt;/p&gt;
&lt;p&gt;我在这里用的是&lt;code&gt;java&lt;/code&gt;提供的代理选项:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ java -DsocksProxyHost&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;127&lt;/span&gt;.0.0.1 -DsocksProxyPort&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1080&lt;/span&gt; -jar ~/.minecraft/Minecraft.jar
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;这样子打开&lt;code&gt;MineCraft&lt;/code&gt;启动器就可以很快的登录、更新、下游戏了。但需要注意的是你通过启动器打开&lt;code&gt;Minecraft&lt;/code&gt;游戏本体之后，游戏是不走代理的。&lt;/p&gt;
&lt;p&gt;-EOF-&lt;/p&gt;</content><category term="linux"></category><category term="Java"></category><category term="Minecraft"></category><category term="shadowsocks"></category><category term="代理"></category></entry><entry><title>在openSUSE上编译WizNote(为知笔记)</title><link href="https://blog.chih.me/Compiler-WizNote-in-openSUSE.html" rel="alternate"></link><published>2015-03-11T00:00:00+08:00</published><updated>2015-03-11T00:00:00+08:00</updated><author><name>chih</name></author><id>tag:blog.chih.me,2015-03-11:/Compiler-WizNote-in-openSUSE.html</id><summary type="html">&lt;p&gt;&lt;code&gt;Wiznote&lt;/code&gt;--为知笔记是一款优秀的全平台云笔记客户端，当初我从Windows切换到纯Linux平台的时候，就同时把我的在线笔记从&lt;code&gt;Evernote&lt;/code&gt;切换到了&lt;code&gt;WizNote&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;openSUSE&lt;/code&gt;的个人仓库里其实是有&lt;code&gt;WizNote&lt;/code&gt;的
&lt;a href="https://build.opensuse.org/package/show?project=home%3Agmg137&amp;amp;package=WizNote"&gt;https://build.opensuse.org/package/show?project=home%3Agmg137&amp;amp;package=WizNote&lt;/a&gt;， 但它并不是最新版本。所以我打算自己编译一个最新版自用，同时因为是自用，直接源码编译安装了，并没有打包。如果需要在&lt;code&gt;openSUSE&lt;/code&gt;下打包，可以参照苏姐的视频教学&lt;a href="http://www.bilibili.com/video/av688454"&gt;http://www.bilibili.com/video/av688454&lt;/a&gt;。&lt;/p&gt;
&lt;h2&gt;获取源码&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;从github 上面 clone 为知笔记客户端源码到本地&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ git clone https://github.com/WizTeam/WizQTClient.git …&lt;/pre&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ul&gt;</summary><content type="html">&lt;p&gt;&lt;code&gt;Wiznote&lt;/code&gt;--为知笔记是一款优秀的全平台云笔记客户端，当初我从Windows切换到纯Linux平台的时候，就同时把我的在线笔记从&lt;code&gt;Evernote&lt;/code&gt;切换到了&lt;code&gt;WizNote&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;openSUSE&lt;/code&gt;的个人仓库里其实是有&lt;code&gt;WizNote&lt;/code&gt;的
&lt;a href="https://build.opensuse.org/package/show?project=home%3Agmg137&amp;amp;package=WizNote"&gt;https://build.opensuse.org/package/show?project=home%3Agmg137&amp;amp;package=WizNote&lt;/a&gt;， 但它并不是最新版本。所以我打算自己编译一个最新版自用，同时因为是自用，直接源码编译安装了，并没有打包。如果需要在&lt;code&gt;openSUSE&lt;/code&gt;下打包，可以参照苏姐的视频教学&lt;a href="http://www.bilibili.com/video/av688454"&gt;http://www.bilibili.com/video/av688454&lt;/a&gt;。&lt;/p&gt;
&lt;h2&gt;获取源码&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;从github 上面 clone 为知笔记客户端源码到本地&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ git clone https://github.com/WizTeam/WizQTClient.git
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;checkout到你想要的版本&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ git checkout v2.1.15
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;准备编译环境&lt;/h2&gt;
&lt;h3&gt;安装依赖&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# zypper in fdupes hicolor-icon-theme update-desktop-files boost-devel cmake chrpath
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;安装Qt5&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# zypper in libqt5-qtbase-devel libqt5-qttools-devel libQt5WebKit5-devel libQt5WebKitWidgets-devel
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;编译安装&lt;/h2&gt;
&lt;h3&gt;生成Makefile&lt;/h3&gt;
&lt;p&gt;创建一个build目录&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ &lt;span class="nb"&gt;cd&lt;/span&gt; ./WizQTClient
$ mkdir build
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;用&lt;code&gt;cmake&lt;/code&gt;生成Makefile&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ &lt;span class="nb"&gt;cd&lt;/span&gt; build
$ cmake &lt;span class="se"&gt;\&lt;/span&gt;
-DWIZNOTE_USE_QT5&lt;span class="o"&gt;=&lt;/span&gt;YES &lt;span class="se"&gt;\&lt;/span&gt;
-DCMAKE_INSTALL_PREFIX&lt;span class="o"&gt;=&lt;/span&gt;/usr &lt;span class="se"&gt;\&lt;/span&gt;
-DCMAKE_BUILD_TYPE&lt;span class="o"&gt;=&lt;/span&gt;Release &lt;span class="se"&gt;\&lt;/span&gt;
../WizQTClient
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;编译安装&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ make -jx
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;x为你cpu核数，并行编译，加快速度。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo make install
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;执行&lt;code&gt;make install&lt;/code&gt;安装到系统目录时需root权限。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;参考资料&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://projects.archlinux.org/svntogit/community.git/tree/trunk/PKGBUILD?h=packages/wiznote"&gt;https://projects.archlinux.org/svntogit/community.git/tree/trunk/PKGBUILD?h=packages/wiznote&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://build.opensuse.org/package/view_file/home:gmg137/WizNote/WizNote.spec?expand=1"&gt;https://build.opensuse.org/package/view_file/home:gmg137/WizNote/WizNote.spec?expand=1&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><category term="linux"></category><category term="Qt5"></category><category term="openSUSE"></category><category term="编译"></category><category term="WizNote"></category></entry><entry><title>解决在opensuse下virtualbox无法挂载主机USB设备的问题</title><link href="https://blog.chih.me/use-USB-in-virtualbox-at-openSUSE.html" rel="alternate"></link><published>2015-03-02T00:00:00+08:00</published><updated>2015-03-02T00:00:00+08:00</updated><author><name>chih</name></author><id>tag:blog.chih.me,2015-03-02:/use-USB-in-virtualbox-at-openSUSE.html</id><summary type="html">&lt;p&gt;因为要用&lt;code&gt;virtualbox&lt;/code&gt;中的&lt;code&gt;Windows&lt;/code&gt;虚拟机设置G602的可编程键，所以需要把G602的USB无线接收器挂载到虚拟机上，结果发现&lt;code&gt;virtualbox&lt;/code&gt;右下角USB设备那里尽管有&lt;code&gt;logitech USB Receiver&lt;/code&gt;这个选项，但它是灰色的，无法选中。&lt;/p&gt;
&lt;p&gt;因为已经确认当前用户已经加入&lt;code&gt;vboxusers&lt;/code&gt;组、并已经安装&lt;code&gt;Oracle Extensions&lt;/code&gt;扩展包，那么问题应该从其他方向寻找。&lt;/p&gt;
&lt;p&gt;在Google了一段时间后，终于在openSUSE论坛找到了&lt;a href="https://forum.suse.org.cn/viewtopic.php?f=13&amp;amp;t=3130"&gt;解决方法&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;源中的包，/usr/lib/udev/rules.d/60-vboxdrv.rules 里面有 4 行规则被用 # 号注释掉了，有安全隐患。把那 4 行注释打开应该就可以了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;找到那四行并取消注释就可以了:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;SUBSYSTEM=="usb_device", ACTION=="add", RUN+="/usr/share …&lt;/li&gt;&lt;/ul&gt;&lt;/blockquote&gt;</summary><content type="html">&lt;p&gt;因为要用&lt;code&gt;virtualbox&lt;/code&gt;中的&lt;code&gt;Windows&lt;/code&gt;虚拟机设置G602的可编程键，所以需要把G602的USB无线接收器挂载到虚拟机上，结果发现&lt;code&gt;virtualbox&lt;/code&gt;右下角USB设备那里尽管有&lt;code&gt;logitech USB Receiver&lt;/code&gt;这个选项，但它是灰色的，无法选中。&lt;/p&gt;
&lt;p&gt;因为已经确认当前用户已经加入&lt;code&gt;vboxusers&lt;/code&gt;组、并已经安装&lt;code&gt;Oracle Extensions&lt;/code&gt;扩展包，那么问题应该从其他方向寻找。&lt;/p&gt;
&lt;p&gt;在Google了一段时间后，终于在openSUSE论坛找到了&lt;a href="https://forum.suse.org.cn/viewtopic.php?f=13&amp;amp;t=3130"&gt;解决方法&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;源中的包，/usr/lib/udev/rules.d/60-vboxdrv.rules 里面有 4 行规则被用 # 号注释掉了，有安全隐患。把那 4 行注释打开应该就可以了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;找到那四行并取消注释就可以了:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;SUBSYSTEM=="usb_device", ACTION=="add", RUN+="/usr/share/virtualbox/VBoxCreateUSBNode.sh $major $minor $attr{bDeviceClass} vboxusers"&lt;/li&gt;
&lt;li&gt;SUBSYSTEM=="usb", ACTION=="add", ENV{DEVTYPE}=="usb_device", RUN+="/usr/share/virtualbox/VBoxCreateUSBNode.sh $major $minor $attr{bDeviceClass} vboxusers"&lt;/li&gt;
&lt;li&gt;SUBSYSTEM=="usb_device", ACTION=="remove", RUN+="/usr/share/virtualbox/VBoxCreateUSBNode.sh --remove $major $minor"&lt;/li&gt;
&lt;li&gt;SUBSYSTEM=="usb", ACTION=="remove", ENV{DEVTYPE}=="usb_device", RUN+="/usr/share/virtualbox/VBoxCreateUSBNode.sh --remove $major $minor"&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;闲话几句:&lt;code&gt;Linux&lt;/code&gt;就这点不方便，各个发行版有自己的打包方式，结果在使用上总是有细微差别。每次换一个发行版总要折腾一些莫名其妙的问题。&lt;/p&gt;</content><category term="linux"></category><category term="virtualbox"></category><category term="openSUSE"></category><category term="USB"></category></entry><entry><title>在实时计算框架Storm集群上运行Storm-Starter例子</title><link href="https://blog.chih.me/storm-starter.html" rel="alternate"></link><published>2015-02-22T00:00:00+08:00</published><updated>2015-02-22T00:00:00+08:00</updated><author><name>chih</name></author><id>tag:blog.chih.me,2015-02-22:/storm-starter.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;官方文档待翻译，个人实践在下面&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1&gt;Example Storm Topologies&lt;/h1&gt;
&lt;p&gt;Learn to use Storm!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Table of Contents&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#getting-started"&gt;Getting started&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#maven"&gt;Using storm-starter with Maven&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#intellij-idea"&gt;Using storm-starter with IntelliJ IDEA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a name="getting-started"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Getting started&lt;/h1&gt;
&lt;h2&gt;Prerequisites&lt;/h2&gt;
&lt;p&gt;First, you need &lt;code&gt;java&lt;/code&gt; and &lt;code&gt;git&lt;/code&gt; installed and in your user's &lt;code&gt;PATH&lt;/code&gt;.  Also, two of the examples in storm-starter
require Python and Ruby.&lt;/p&gt;
&lt;p&gt;Next …&lt;/p&gt;</summary><content type="html">&lt;blockquote&gt;
&lt;p&gt;官方文档待翻译，个人实践在下面&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1&gt;Example Storm Topologies&lt;/h1&gt;
&lt;p&gt;Learn to use Storm!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Table of Contents&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#getting-started"&gt;Getting started&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#maven"&gt;Using storm-starter with Maven&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#intellij-idea"&gt;Using storm-starter with IntelliJ IDEA&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a name="getting-started"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Getting started&lt;/h1&gt;
&lt;h2&gt;Prerequisites&lt;/h2&gt;
&lt;p&gt;First, you need &lt;code&gt;java&lt;/code&gt; and &lt;code&gt;git&lt;/code&gt; installed and in your user's &lt;code&gt;PATH&lt;/code&gt;.  Also, two of the examples in storm-starter
require Python and Ruby.&lt;/p&gt;
&lt;p&gt;Next, make sure you have the storm-starter code available on your machine.  Git/GitHub beginners may want to use the
following command to download the latest storm-starter code and change to the new directory that contains the downloaded
code.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ git clone git://github.com/apache/incubator-storm.git &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nb"&gt;cd&lt;/span&gt; incubator-storm/examples/storm-starter
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;storm-starter overview&lt;/h2&gt;
&lt;p&gt;storm-starter contains a variety of examples of using Storm.  If this is your first time working with Storm, check out
these topologies first:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="src/jvm/storm/starter/ExclamationTopology.java"&gt;ExclamationTopology&lt;/a&gt;:  Basic topology written in all Java&lt;/li&gt;
&lt;li&gt;&lt;a href="src/jvm/storm/starter/WordCountTopology.java"&gt;WordCountTopology&lt;/a&gt;:  Basic topology that makes use of multilang by
   implementing one bolt in Python&lt;/li&gt;
&lt;li&gt;&lt;a href="src/jvm/storm/starter/ReachTopology.java"&gt;ReachTopology&lt;/a&gt;: Example of complex DRPC on top of Storm&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;After you have familiarized yourself with these topologies, take a look at the other topopologies in
&lt;a href="src/jvm/storm/starter/"&gt;src/jvm/storm/starter/&lt;/a&gt; such as &lt;a href="src/jvm/storm/starter/RollingTopWords.java"&gt;RollingTopWords&lt;/a&gt;
for more advanced implementations.&lt;/p&gt;
&lt;p&gt;If you want to learn more about how Storm works, please head over to the
&lt;a href="http://storm.incubator.apache.org"&gt;Storm project page&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a name="maven"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Using storm-starter with Maven&lt;/h1&gt;
&lt;h2&gt;Install Maven&lt;/h2&gt;
&lt;p&gt;Install &lt;a href="http://maven.apache.org/"&gt;Maven&lt;/a&gt; (preferably version 3.x) by following
the &lt;a href="http://maven.apache.org/download.cgi"&gt;Maven installation instructions&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Build and install Storm jars locally&lt;/h2&gt;
&lt;p&gt;If you are using the latest development version of Storm, e.g. by having cloned the Storm git repository,
then you must first perform a local build of Storm itself.  Otherwise you will run into Maven errors such as
"Could not resolve dependencies for project &lt;code&gt;org.apache.storm:storm-starter:&amp;lt;storm-version&amp;gt;-SNAPSHOT&lt;/code&gt;".&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# Must be run from the top-level directory of the Storm code repository
$ mvn clean install -DskipTests=true
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This command will build Storm locally and install its jar files to your user's &lt;code&gt;$HOME/.m2/repository/&lt;/code&gt;.  When you run
the Maven command to build and run storm-starter (see below), Maven will then be able to find the corresponding version
of Storm in this local Maven repository at &lt;code&gt;$HOME/.m2/repository&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;Running topologies with Maven&lt;/h2&gt;
&lt;p&gt;storm-starter topologies can be run with the maven-exec-plugin. For example, to
compile and run &lt;code&gt;WordCountTopology&lt;/code&gt; in local mode, use the command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ mvn compile exec:java -Dstorm.topology&lt;span class="o"&gt;=&lt;/span&gt;storm.starter.WordCountTopology
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You can also run clojure topologies with Maven:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ mvn compile exec:java -Dstorm.topology&lt;span class="o"&gt;=&lt;/span&gt;storm.starter.clj.word_count
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In Windows parameter should be quoted, like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ mvn compile exec:java &lt;span class="s2"&gt;&amp;quot;-Dstorm.topology=storm.starter.clj.word_count&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Packaging storm-starter for use on a Storm cluster&lt;/h2&gt;
&lt;p&gt;You can package a jar suitable for submitting to a Storm cluster with the command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ mvn package
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This will package your code and all the non-Storm dependencies into a single "uberjar" at the path
&lt;code&gt;target/storm-starter-{version}-jar-with-dependencies.jar&lt;/code&gt;.&lt;/p&gt;
&lt;h2&gt;Running unit tests&lt;/h2&gt;
&lt;p&gt;Use the following Maven command to run the unit tests that ship with storm-starter.  Unfortunately &lt;code&gt;lein test&lt;/code&gt; does not
yet run the included unit tests.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ mvn &lt;span class="nb"&gt;test&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;a name="intellij-idea"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Using storm-starter with IntelliJ IDEA&lt;/h1&gt;
&lt;h2&gt;Importing storm-starter as a project in IDEA&lt;/h2&gt;
&lt;p&gt;The following instructions will import storm-starter as a new project in IntelliJ IDEA.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Open &lt;em&gt;File &amp;gt; Import Project...&lt;/em&gt; and navigate to the storm-starter directory of your storm clone (e.g.
  &lt;code&gt;~/git/incubator-storm/examples/storm-starter&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;Select &lt;em&gt;Import project from external model&lt;/em&gt;, select "Maven", and click &lt;em&gt;Next&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;In the following screen, enable the checkbox &lt;em&gt;Import Maven projects automatically&lt;/em&gt;.  Leave all other values at their
  defaults.  Click &lt;em&gt;Next&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Click &lt;em&gt;Next&lt;/em&gt; on the following screen about selecting Maven projects to import.&lt;/li&gt;
&lt;li&gt;Select the JDK to be used by IDEA for storm-starter, then click &lt;em&gt;Next&lt;/em&gt;.&lt;ul&gt;
&lt;li&gt;At the time of this writing you should use JDK 6.&lt;/li&gt;
&lt;li&gt;It is strongly recommended to use Sun/Oracle JDK 6 rather than OpenJDK 6.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;You may now optionally change the name of the project in IDEA.  The default name suggested by IDEA is "storm-starter".
  Click &lt;em&gt;Finish&lt;/em&gt; once you are done.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h1&gt;个人实践&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;默认通过sudo -s 进入root环境&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;安装环境 git ，maven&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# apt-get install git maven
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;通过git clone 项目&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# git clone git://github.com/apache/incubator-storm.git
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="3-1" src="https://blog.chih.me/images/3-1.png"&gt;&lt;/p&gt;
&lt;h3&gt;进入项目目录&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# cd incubator-storm/examples/storm-starter
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;编译&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# mvn compile
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="3-2" src="https://blog.chih.me/images/3-2.png"&gt;&lt;/p&gt;
&lt;p&gt;第一次出现错误，去google了一下，找到一种办法&lt;/p&gt;
&lt;p&gt;&lt;img alt="3-8" src="https://blog.chih.me/images/3-8.png"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不使用最新的代码而使用apache-storm-0.9.2-incubating中的例子，这是我们在安装storm时下载的
进入apache-storm-0.9.2-incubating/examples/storm-starter&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;执行&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# mvn compile
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="3-3" src="https://blog.chih.me/images/3-3.png"&gt;&lt;/p&gt;
&lt;p&gt;成功!&lt;/p&gt;
&lt;h3&gt;打包所有的依赖&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# mvn package
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="3-4" src="https://blog.chih.me/images/3-4.png"&gt;&lt;/p&gt;
&lt;p&gt;进入target目录，可以看到&lt;code&gt;storm-starter-0.9.2-incubating-jar-with-dependencies.jar&lt;/code&gt;&lt;/p&gt;
&lt;h3&gt;提交到storm(以WordCountTopology为例)&lt;/h3&gt;
&lt;p&gt;在nimbus上运行&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# ./bin/storm jar storm-starter-0.9.2-incubating-jar-with-dependencies.jar  storm.starter.WordCountTopology test
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;可以看到console的输出，当然可以在storm ui的http上查看topology状态。例子已经被提交到集群。&lt;/p&gt;
&lt;p&gt;&lt;img alt="3-6" src="https://blog.chih.me/images/3-6.png"&gt;&lt;/p&gt;</content><category term="linux"></category><category term="Storm"></category><category term="大数据"></category><category term="实时计算"></category></entry><entry><title>实时计算框架Storm集群搭建</title><link href="https://blog.chih.me/Setting-up-a-Storm-Cluster-in-3-machines.html" rel="alternate"></link><published>2015-02-20T00:00:00+08:00</published><updated>2015-02-20T00:00:00+08:00</updated><author><name>chih</name></author><id>tag:blog.chih.me,2015-02-20:/Setting-up-a-Storm-Cluster-in-3-machines.html</id><summary type="html">&lt;h3&gt;首先对三台ubuntu14.04进行任务分配:&lt;/h3&gt;
&lt;p&gt;&lt;img alt="4-1" src="https://blog.chih.me/images/4-1.jpg"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;nimbus：
ip：192.168.56.102&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;zookeeper：
ip：192.168.56.102；192.168.56.103；192.168.56.104&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;supervisor：
ip：192.168.56.103 192.168.56.104&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此三台虚拟机分别用作Storm集群中的&lt;code&gt;nimbus&lt;/code&gt;节点、&lt;code&gt;Zookeeper&lt;/code&gt;集群（一台机器开多个zookeeper进程，当然也可以多台机器）、&lt;code&gt;supervisor&lt;/code&gt;节点。&lt;/p&gt;
&lt;p&gt;在这里我为方便起见 直接从单机安装的virtualbox虚拟机clone了三台一样的机器进行配置，每台上的配置过程见&lt;a href="https://blog.chih.me/Setting-up-a-Storm-Cluster.html"&gt;实时计算框架Storm本地模式搭建&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;下面针对每一个节点进行具体的配置&lt;/h3&gt;
&lt;p&gt;&lt;img alt="4-2" src="https://blog.chih.me/images/4-2.png"&gt;&lt;/p&gt;
&lt;h4&gt;搭建一个Zookeeper集群&lt;/h4&gt;
&lt;p&gt;三台机器同时作为&lt;code&gt;zookeeper&lt;/code&gt;集群 …&lt;/p&gt;</summary><content type="html">&lt;h3&gt;首先对三台ubuntu14.04进行任务分配:&lt;/h3&gt;
&lt;p&gt;&lt;img alt="4-1" src="https://blog.chih.me/images/4-1.jpg"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;nimbus：
ip：192.168.56.102&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;zookeeper：
ip：192.168.56.102；192.168.56.103；192.168.56.104&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;supervisor：
ip：192.168.56.103 192.168.56.104&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此三台虚拟机分别用作Storm集群中的&lt;code&gt;nimbus&lt;/code&gt;节点、&lt;code&gt;Zookeeper&lt;/code&gt;集群（一台机器开多个zookeeper进程，当然也可以多台机器）、&lt;code&gt;supervisor&lt;/code&gt;节点。&lt;/p&gt;
&lt;p&gt;在这里我为方便起见 直接从单机安装的virtualbox虚拟机clone了三台一样的机器进行配置，每台上的配置过程见&lt;a href="https://blog.chih.me/Setting-up-a-Storm-Cluster.html"&gt;实时计算框架Storm本地模式搭建&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;下面针对每一个节点进行具体的配置&lt;/h3&gt;
&lt;p&gt;&lt;img alt="4-2" src="https://blog.chih.me/images/4-2.png"&gt;&lt;/p&gt;
&lt;h4&gt;搭建一个Zookeeper集群&lt;/h4&gt;
&lt;p&gt;三台机器同时作为&lt;code&gt;zookeeper&lt;/code&gt;集群。&lt;/p&gt;
&lt;p&gt;对机器均修改&lt;code&gt;conf/zoo.cfg&lt;/code&gt;（可以直接将zoo_sample.cfg重命名为zoo.cfg）&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# The number of milliseconds of each tick
tickTime=2000
# The number of ticks that the initial
# synchronization phase can take
initLimit=10
# The number of ticks that can pass between
# sending a request and getting an acknowledgement
syncLimit=5
# the directory where the snapshot is stored.
# do not use /tmp for storage, /tmp here is just
# example sakes.
dataDir=/var/zookeeper
# the port at which the clients will connect
clientPort=2181
server.1=192.168.56.102:2888:3888
server.2=192.168.56.103:2888:3888
server.3=192.168.56.104:2888:3888
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;最后三行是ip:port:port的形式，&lt;code&gt;Zookeeper&lt;/code&gt;需要2个端口通信。有多少台机器就写多少个server.X=ip:port:port。X从1到255。&lt;/p&gt;
&lt;p&gt;&lt;img alt="4-3" src="https://blog.chih.me/images/4-3.png"&gt;&lt;/p&gt;
&lt;h4&gt;接下来设置myid&lt;/h4&gt;
&lt;p&gt;在设置的&lt;code&gt;dataDir&lt;/code&gt;目录下新建myid文件，如上面设置的/var/zookeeper目录下。
myid文件中只有一行数字，即与zoo.cfg设置的主机与id对应的id，
(默认每台机器通过&lt;code&gt;sudo -s&lt;/code&gt; 进入root环境， 缺失的目录通过&lt;code&gt;mkdir&lt;/code&gt; 补全)&lt;/p&gt;
&lt;p&gt;在 192.168.56.102 上执行：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# echo 1 &amp;gt;/var/zookeeper/myid
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;在 192.168.56.103 上执行：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# echo 2 &amp;gt; /var/zookeeper/myid
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;在 192.168.56.104 上执行：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# echo 3 &amp;gt; /var/zookeeper/myid
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;最后启动集群的ZooKeeper&lt;/p&gt;
&lt;p&gt;对每台机器均执行&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ bin/zkServer start
$ zkServer.sh status
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;查看状态&lt;/p&gt;
&lt;p&gt;&lt;img alt="4-4" src="https://blog.chih.me/images/4-4.png"&gt;&lt;/p&gt;
&lt;p&gt;保证server节点的zookeeper服务全部启动好&lt;/p&gt;
&lt;p&gt;&lt;img alt="4-5" src="https://blog.chih.me/images/4-5.png"&gt;&lt;/p&gt;
&lt;h4&gt;在nimbus、supervisor节点安装依赖包（jdk，python）&lt;/h4&gt;
&lt;h4&gt;下载并解压Storm到nimbus、supervisor节点&lt;/h4&gt;
&lt;h4&gt;修改nimbus、supervisor节点的配置文件（storm.yaml），每台机器相同配置。&lt;/h4&gt;
&lt;p&gt;Storm的配置文件位于storm主目录下的&lt;code&gt;conf/storm.yaml&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;storm.zookeeper.servers&lt;/code&gt;：指定zookeeper集群中的主机列表。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;nimbus.host&lt;/code&gt;:指定nimbus节点对应的主机。
配置如下：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;storm.zookeeper.servers:
      - &amp;quot;192.168.56.102&amp;quot;
      - &amp;quot;192.168.56.103&amp;quot;
      - &amp;quot;192.168.56.104&amp;quot;

nimbus.host: &amp;quot;192.168.56.102&amp;quot;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="4-6" src="https://blog.chih.me/images/4-6.png"&gt;
 &lt;code&gt;supervisor.slots.ports&lt;/code&gt;:对于每个supervisor节点，需要指定一些端口，来运行相应数目的JVM进程。下面的配置开发了四个端口，即在supervisor节点上运行了四个JVM进程（4个worker、此处涉及到Storm中的并行化机制）。&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;supervisor.slots.ports:

- 6700

- 6701

- 6702

- 6703
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;注：nimbus节点和supervisor节点上的storm.yaml均需要配置。&lt;/p&gt;
&lt;h4&gt;使用storm脚本启动守护进程（包括nimbus、supervisor、ui）&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;nimbus：在nimbus节点上运行&lt;code&gt;storm nimbus&lt;/code&gt;命令 192.168.56.102&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;supervisor：在supervisor节点上运行&lt;code&gt;storm supervisor&lt;/code&gt;命令 103 104&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ui：在nimbus上重新开个console，运行&lt;code&gt;storm ui&lt;/code&gt;命令，并访问&lt;a href="http://192.168.56.102:8088"&gt;http://192.168.56.102:8088&lt;/a&gt;，出现如下界面则表明集群搭建成功：&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="4-7" src="https://blog.chih.me/images/4-7.png"&gt;&lt;/p&gt;</content><category term="linux"></category><category term="Storm"></category><category term="大数据"></category><category term="实时计算"></category></entry><entry><title>实时计算框架Storm本地模式搭建</title><link href="https://blog.chih.me/Setting-up-a-Storm-Cluster.html" rel="alternate"></link><published>2015-02-02T00:00:00+08:00</published><updated>2015-02-02T00:00:00+08:00</updated><author><name>chih</name></author><id>tag:blog.chih.me,2015-02-02:/Setting-up-a-Storm-Cluster.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;平台：Ubuntu14.04&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;安装依赖&lt;/h2&gt;
&lt;p&gt;通过ubuntu自带的软件包管理器安装java环境。
安装Java：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo apt-get install openjdk-7-jdk
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;检查是否安装完成:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ java -version
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="1-1" src="https://blog.chih.me/images/1-1.png"&gt;&lt;/p&gt;
&lt;p&gt;检查python版本:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ python -V
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="1-2" src="https://blog.chih.me/images/1-2.png"&gt;&lt;/p&gt;
&lt;h2&gt;安装ZooKeeper&lt;/h2&gt;
&lt;p&gt;为了避免每次获取超级权限重复输入sudo
临时进入超级用户:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo -s
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;使用&lt;code&gt;ctrl+d&lt;/code&gt;退出&lt;/p&gt;
&lt;p&gt;定位目录:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# cd /usr/local/src
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;从阿里的源下载:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# wget http://mirrors.aliyun.com/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="1-3" src="https://blog.chih.me/images/1-3.png"&gt;&lt;/p&gt;
&lt;p&gt;使用命令解压:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# tar -xzvf zookeeper-3 …&lt;/pre&gt;&lt;/div&gt;</summary><content type="html">&lt;blockquote&gt;
&lt;p&gt;平台：Ubuntu14.04&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;安装依赖&lt;/h2&gt;
&lt;p&gt;通过ubuntu自带的软件包管理器安装java环境。
安装Java：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo apt-get install openjdk-7-jdk
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;检查是否安装完成:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ java -version
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="1-1" src="https://blog.chih.me/images/1-1.png"&gt;&lt;/p&gt;
&lt;p&gt;检查python版本:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ python -V
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="1-2" src="https://blog.chih.me/images/1-2.png"&gt;&lt;/p&gt;
&lt;h2&gt;安装ZooKeeper&lt;/h2&gt;
&lt;p&gt;为了避免每次获取超级权限重复输入sudo
临时进入超级用户:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo -s
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;使用&lt;code&gt;ctrl+d&lt;/code&gt;退出&lt;/p&gt;
&lt;p&gt;定位目录:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# cd /usr/local/src
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;从阿里的源下载:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# wget http://mirrors.aliyun.com/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="1-3" src="https://blog.chih.me/images/1-3.png"&gt;&lt;/p&gt;
&lt;p&gt;使用命令解压:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# tar -xzvf zookeeper-3.4.6.tar.gz
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;进入解压后的目录：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# cd zookeeper-3.4.6
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="1-4" src="https://blog.chih.me/images/1-4.png"&gt;&lt;/p&gt;
&lt;p&gt;从配置文件模板复制一份配置文件，这里无需修改：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# cp conf/zoo_sample.cfg conf/zoo.cfg
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;环境变量：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# export ZOOKEEPER_HOME=/usr/local/src/zookeeper-3.4.6
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;环境变量：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# export PATH=$ZOOKEEPER_HOME/bin:$PATH
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;启动服务器:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# ./bin/zkServer.sh start
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;测试:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# ./bin/zkCli.sh -server 127.0.0.1:2181
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;安装Storm&lt;/h2&gt;
&lt;p&gt;定位目录:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# cd /usr/local/src
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;下载（从阿里的源下载0.9.2版本）:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# wget http://mirrors.aliyun.com/apache/storm/apache-storm-0.9.2-incubating/apache-storm-0.9.2-incubating.tar.gz
# tar -xzvf apache-storm-0.9.2-incubating.tar.gz
# cd ./apache-storm-0.9.2-incubating/
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="1-5" src="https://blog.chih.me/images/1-5.png"&gt;&lt;/p&gt;
&lt;p&gt;配置storm.yaml:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# vim ./conf/storm.yaml
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;(这里我使用vim，也可以使用如何文件编辑器，复制以下内容到文件，原先的内容全部注释）&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;storm.zookeeper.servers:
      - &amp;quot;localhost&amp;quot;
nimbus.host: &amp;quot;localhost&amp;quot;
storm.local.dir : &amp;quot;/var/storm&amp;quot;
ui.port : 8080
storm.messaging.transport: &amp;quot;backtype.storm.messaging.netty.Context&amp;quot; #--指定传输协议
storm.messaging.netty.server_worker_threads: 1   #--指定netty服务器工作线程数量
storm.messaging.netty.client_worker_threads: 1   #--指定netty客户端工作线程数量
storm.messaging.netty.buffer_size: 5242880    #--指定netty缓存大小
storm.messaging.netty.max_retries: 100   #--指定最大重试次数
storm.messaging.netty.max_wait_ms: 1000  #--指定最大等待时间（毫秒）
storm.messaging.netty.min_wait_ms: 100   #--指定最小等待时间（毫秒）
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="1-6" src="https://blog.chih.me/images/1-6.png"&gt;&lt;/p&gt;
&lt;p&gt;后台（通过命令后加&amp;amp;使进程后台执行，标准输出全部进入黑洞/dev/null）启动Storm服务：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# ./bin/storm nimbus &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
# ./bin/storm supervisor&amp;gt;/dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
# ./bin/storm ui &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
# ./bin/storm logviewer &amp;gt; /dev/null 2&amp;gt;&amp;amp;1 &amp;amp;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;访问ip:port即可进入Storm UI&lt;/p&gt;
&lt;p&gt;&lt;img alt="1-7" src="https://blog.chih.me/images/1-7.png"&gt;&lt;/p&gt;
&lt;p&gt;-EOF-&lt;/p&gt;</content><category term="linux"></category><category term="Storm"></category><category term="大数据"></category><category term="实时计算"></category></entry><entry><title>ubuntu突然出现打开系统设置慢 sudo时出现无法解析主机的解决办法</title><link href="https://blog.chih.me/ubuntutu-ran-chu-xian-da-kai-xi-tong-she-zhi-man-sudoshi-chu-xian-wu-fa-jie-xi-zhu-ji-de-jie-jue-ban-fa.html" rel="alternate"></link><published>2014-04-06T00:00:00+08:00</published><updated>2014-04-06T00:00:00+08:00</updated><author><name>chih</name></author><id>tag:blog.chih.me,2014-04-06:/ubuntutu-ran-chu-xian-da-kai-xi-tong-she-zhi-man-sudoshi-chu-xian-wu-fa-jie-xi-zhu-ji-de-jie-jue-ban-fa.html</id><summary type="html">&lt;p&gt;突然间发现我的&lt;code&gt;ubuntu12.04&lt;/code&gt;打开系统设置变得非常慢，正不知如何解决的时候。发现sudo时出现“无法解析的主机 XXXX" 的提示。马上就联想到不久前改过hosts，原来是主机名无法解析了，这样问题就好解决了&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo vim /etc/hosts
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;加入以下行&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;127.0.0.1       （你现在的主机名）
127.0.1.1       （你现在的主机名）
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;之后 打开系统设置就非常快了&lt;/p&gt;</summary><content type="html">&lt;p&gt;突然间发现我的&lt;code&gt;ubuntu12.04&lt;/code&gt;打开系统设置变得非常慢，正不知如何解决的时候。发现sudo时出现“无法解析的主机 XXXX" 的提示。马上就联想到不久前改过hosts，原来是主机名无法解析了，这样问题就好解决了&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ sudo vim /etc/hosts
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;加入以下行&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;127.0.0.1       （你现在的主机名）
127.0.1.1       （你现在的主机名）
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;之后 打开系统设置就非常快了&lt;/p&gt;</content><category term="Hosts"></category><category term="ubuntu"></category><category term="linux"></category></entry><entry><title>virtualbox主机访问虚拟机</title><link href="https://blog.chih.me/virtualboxzhu-ji-fang-wen-xu-ni-ji.html" rel="alternate"></link><published>2014-03-02T00:00:00+08:00</published><updated>2014-03-02T00:00:00+08:00</updated><author><name>chih</name></author><id>tag:blog.chih.me,2014-03-02:/virtualboxzhu-ji-fang-wen-xu-ni-ji.html</id><summary type="html">&lt;p&gt;在&lt;code&gt;virtualbox&lt;/code&gt;中，如果选择默认的网卡设置，也就是网络地址转换(NAT)，是不能让宿主机访问到虚拟机的，如果想让两者相互连通，可以在保留默认的&lt;code&gt;NAT&lt;/code&gt;网卡的基础上增加一张&lt;code&gt;Host-Only&lt;/code&gt;的网卡。&lt;/p&gt;
&lt;p&gt;&lt;img alt="NAT" src="https://blog.chih.me/images/58081e7f-677a-47f9-8fc5-a7ec0435e7b1.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Host-Only" src="https://blog.chih.me/images/7695d614d15ad02edfd564e4b32810fc.png"&gt;&lt;/p&gt;
&lt;p&gt;需要注意的是，如果你的宿主机是Linux的话，安装virtualbox后是没有一张Host-Only的网卡的，你需要在virtualbox的设置里添加这张网卡。&lt;/p&gt;
&lt;p&gt;&lt;img alt="add-Host-Only" src="https://blog.chih.me/images/snapshot2.png"&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;在&lt;code&gt;virtualbox&lt;/code&gt;中，如果选择默认的网卡设置，也就是网络地址转换(NAT)，是不能让宿主机访问到虚拟机的，如果想让两者相互连通，可以在保留默认的&lt;code&gt;NAT&lt;/code&gt;网卡的基础上增加一张&lt;code&gt;Host-Only&lt;/code&gt;的网卡。&lt;/p&gt;
&lt;p&gt;&lt;img alt="NAT" src="https://blog.chih.me/images/58081e7f-677a-47f9-8fc5-a7ec0435e7b1.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Host-Only" src="https://blog.chih.me/images/7695d614d15ad02edfd564e4b32810fc.png"&gt;&lt;/p&gt;
&lt;p&gt;需要注意的是，如果你的宿主机是Linux的话，安装virtualbox后是没有一张Host-Only的网卡的，你需要在virtualbox的设置里添加这张网卡。&lt;/p&gt;
&lt;p&gt;&lt;img alt="add-Host-Only" src="https://blog.chih.me/images/snapshot2.png"&gt;&lt;/p&gt;</content><category term="Hosts"></category><category term="virtualbox"></category><category term="linux"></category><category term="网络"></category></entry><entry><title>VMware中使easy install失效</title><link href="https://blog.chih.me/disable-easy-install-in-vmware.html" rel="alternate"></link><published>2012-09-05T00:00:00+08:00</published><updated>2012-09-05T00:00:00+08:00</updated><author><name>chih</name></author><id>tag:blog.chih.me,2012-09-05:/disable-easy-install-in-vmware.html</id><summary type="html">&lt;p&gt;用Typcial或custom方式安装虚拟机时，会出现Easy Install，使得安装过程自动进行，但这种自动的安装会有一些问题，比如装Linux时的分区，ubuntu的中文支持也会有问题。
更多的，对于像我这种学生来说，虚拟机有很大的作用是用来学习系统的安装的，这时Easy Install就显得多余了，那我们要怎么取消Easy Install呢？下面是一种不错的方法。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;用Typcial或custom方式进入虚拟机的安装。&lt;/li&gt;
&lt;li&gt;出现Easy Install Information时，可以随便填写，这个在后来的实际安装过程中是用不着的。&lt;/li&gt;
&lt;li&gt;按你的需要配置虚拟机&lt;/li&gt;
&lt;li&gt;在Ready to Create Virtual Machine页中，需要把Power on this virtual machine after creation前的勾去掉，Finish&lt;/li&gt;
&lt;li&gt;接下来配置你刚刚创建的虚拟机。&lt;/li&gt;
&lt;li&gt;把使用autoinst.iso的CD/DVD这个硬件直接remove或选为Auto detect，同样更改Floppy这个硬件，OK&lt;/li&gt;
&lt;li&gt;现在启动虚拟机安装系统时就不会进入Easy Install了。&lt;/li&gt;
&lt;/ol&gt;</summary><content type="html">&lt;p&gt;用Typcial或custom方式安装虚拟机时，会出现Easy Install，使得安装过程自动进行，但这种自动的安装会有一些问题，比如装Linux时的分区，ubuntu的中文支持也会有问题。
更多的，对于像我这种学生来说，虚拟机有很大的作用是用来学习系统的安装的，这时Easy Install就显得多余了，那我们要怎么取消Easy Install呢？下面是一种不错的方法。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;用Typcial或custom方式进入虚拟机的安装。&lt;/li&gt;
&lt;li&gt;出现Easy Install Information时，可以随便填写，这个在后来的实际安装过程中是用不着的。&lt;/li&gt;
&lt;li&gt;按你的需要配置虚拟机&lt;/li&gt;
&lt;li&gt;在Ready to Create Virtual Machine页中，需要把Power on this virtual machine after creation前的勾去掉，Finish&lt;/li&gt;
&lt;li&gt;接下来配置你刚刚创建的虚拟机。&lt;/li&gt;
&lt;li&gt;把使用autoinst.iso的CD/DVD这个硬件直接remove或选为Auto detect，同样更改Floppy这个硬件，OK&lt;/li&gt;
&lt;li&gt;现在启动虚拟机安装系统时就不会进入Easy Install了。&lt;/li&gt;
&lt;/ol&gt;</content><category term="VMware"></category><category term="linux"></category><category term="虚拟机"></category></entry></feed>